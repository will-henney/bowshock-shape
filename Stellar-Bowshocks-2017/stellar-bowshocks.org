* Bowshocks around moving OB and RSG stars

** Comments on paper by Struck 2020
+ Struck:2020a
+ Has some interesting stuff on the inner shock, but there are various strangenesses
+ Outer i-front
  + They say it is R-type, but they also talk about a shock, which is strange
  + Also, they have the i-front being wilkinoid, which makes no sense since it is not a momentum balance surface
+ Collisional mean-free path
  + Their eq (2) does not have the coulomb logarithm, so only includes large-angle scattering
  + So it should be shorter by a factor of \ln \Lambda \approx 20
+ Weibel zone *most important*
  + Instead of a wind shock they have an instability zone, where "weibel filaments" form
  + One problem with this is that it only seems to occur for a quasi-parallel field, whereas we expect field to be quasi-perpendicular
  + Mpst importantly, they are wrong about the wind particles being able to "penetrate" the turbulent layer
    + As is stated clearly in Caprioli:2014a, the vast majority of the wind protons are thermalized in the shock
      + This occurs over scale of order 1000 skin depths
      + Also, the Weibel instability is the wind interacting with itself: incident stream and reflected stream
    + A small fraction (0.0001 to 0.001) of the particles are accelerated to non-thermal energies E > 4 E_shock
      + They develop a power law distribution f(E) \sim E^-1.5 in non-relativistic regime (E^-2 relativistic)
      + It takes a bit further to fully develop the power law - 7000 skin depths
      + Also takes about 2000 ion cyclotron times in time-dependent shock simulation
      + Acceleration is diffusive shock acceleration (DSA)
    + Although the fraction of DSA non-thermal protons is small, their energy is substantial
      + Typically 10% of the shock energy (Caprioli:2014a, Fig 3)
      + But only efficient for quasi-parallel shocks (\theta < 45 deg)
      + And only a mild dependence on Mach number (for M > 5 at least)
    + There is also Shock Drift Acceleration (SDA)
      + This operates in quasi-perpendicular shocks
      + But it does not generate a high-energy "non-thermal" power law tail
      + Instead, it gives a "suprathermal" population, which is quasi-Gaussian with T \approx 2.2 T_shock
      + Note that "suprathermal" and "nonthermal" are different things here
    + Note however, that pre-existing turbulence in the upstream wind *could* cause DSA in the quasi-perpendicular case so long as \delta B / B ~ 1
  + I am not sure how they get around the argument in 4.1.3 of our Paper III
    + That proton Larmor radius is order 1e10 cm, so wind protons can't possibly penetrate across the tangential discontinuity into the ISM and heat the dust
    + They cite Caprioli:2004a to say that Weibel zone thickness is about 1000 c / \omega_p
    + Plasma frequency \omega_p = sqrt(4 \pi n e^2 / m) = 1316 rad/s for protons if n = 1 pcc
      + For electrons it is 56.4 kHz
    + So skin depth is c / \omega_p = 2.27e7 cm, scaling as 1/sqrt(n)
    + Cyclotron frequency is \omega_c = e B_0 / m c = 0.009579 Hz for B = 1 \mu G for protons
      + larmor radius for V = 2000 km/s is 2.088e+10 cm
      + electron cyclotron frequency is 17.6 Hz
    + Alfven speed is c \omega_c / \omega_p = B_0 / sqrt(4 \pi n m) = 2.2 km/s times (B (\mu{}G) / sqrt(n (pcc)))
      + The paper uses n = 0.1, B = 3 so that it is more like 20 km/s
    + Larmor radius divided by skin depth is V \omega_p / \omega_c c = V / v_A = M_A
  + Possibly, a highly turbulent field in the H II region could allow the shocked wind protons to leak in
  + A much better paper (than Struck) is del-Valle:2018a
    + They are mainly concerned with high-energy electrons produced by DSA, which then give rise to synchrotron and (by interacting with IR photons emitted by bowshock) inverse Compton gamma rays
    + But they also mention
      : The hadronic component in the SED is completely negligible; protons diffuse and advect into the ISM almost without losing energy.
    + Note that these are relativistic: GeV to TeV energies
    + Whereas wind protons have 20 keV
    + So they quickly diffuse out of nebula

+ Bubble nebula
  : This structure is suggestive of a broader diffusive mixing region. If the bubble is a diffusive Weibel zone, then we do not need projection effects to account for it. We simply observe (a thicker shell than that of a shock) through a larger column density at the edges, regardless of projection angle.
  + This is clearly wrong - by the bubble they mean the [O III] shell
  + It can't be the weibel zone, since that would have far too low a density 

** New note for version 2 of Paper IV
[2020-02-06 Thu 10:48]

*** The extremes of the distributions
+ To what extent are they real, and to what extent are they artefacts of the fitting procedure? 
+ High alatude sources (in the upwards spur):
  + K274 has \Pi, \Lambda+, \Lambda- = 1.5, 2.2, 3.1
    + The high \Lambda is genuine, seems to be an oscillation in the wings for \theta > 60
    + But \Pi might be higher if fitted to peak brightness only
  + K132 has same \Pi, \Lambda as K274
    + But in this case, it is spurious
    + There is an unrelated clump that affects one side
  + K125 has  \Pi, \Lambda+, \Lambda- = 1.4, 1.8, 2.5
    + So not quite so extreme
    + The \Lambda's look genuine, but again the \Pi could be higher if fit to peak only
  + K248 has \Pi, \Lambda+, \Lambda- = 0.95, 1.5, 2.3
    + Very asymmetrical, possibly two sources superimposed
    + The \Pi could easily be larger
  + K230 is close to K125 in diagram: \Pi, \Lambda+, \Lambda- = 1.35, 1.7, 2.6
    + Again the \Lambda's are legitimate
    + But \Pi could be bigger, making it more like K635
    + It has far-wings that are visible into the tail

** Nature of arcs around O stars
+ There is some question whether they are really bow shocks, or are instead dust waves.
  + Example of the latter is 
** Previous work on theory of projected shapes
*** Cox et al 2012
+ Have a reasonably sane discussion of the projection of the /Wilkinoid/ shape
+ Consider R_0 and R_90
  + 
** Observations of O star bow shocks 
+ Use Kobulnicky (2016), who have 709 objects!
+ Best observations are 24 micron Spitzer MIPSGAL images
*** Catalog of Kobulnicky bow shocks 
+ [[file:OB/Kobulnicky2016/table1.dat]]
*** How to get the images of OB bow shocks
+ Loop through the table and do searches on the coordinates
  + Follow the API described at http://irsa.ipac.caltech.edu/applications/Atlas/AtlasProgramInterface.html
  + The example given for MIPSGAL is
    + http://irsa.ipac.caltech.edu/cgi-bin/Atlas/nph-atlas?mission=MIPSGAL&locstr=NGC+6631&regSize=12.5&covers=on&mode=PI
    + But we would be best off using coordinates
    + As in =&locstr=17h18m57s+60d21m12s=
  + We could probably use the =requests= python library for that
    + It looks very easy to use
    + Relevant example code from the [[http://docs.python-requests.org/en/master/user/quickstart/][documentation]]
      #+BEGIN_SRC python
        payload = {'key1': 'value1', 'key2': 'value2'}
        r = requests.get('http://httpbin.org/get', params=payload)
      #+END_SRC
  + This gives an XML file that will contain a line like this
    #+BEGIN_SRC xml
      <result status="ok">
      <description>
      <collection>MIPSGAL</collection>
      <ra>276.813000</ra>
      <dec>-12.020000</dec>
      <regSize>12.500000</regSize>
      <radius>6.250000</radius>
      <radunits>degrees</radunits>
      </description>
      <coverageMap>
      <resultHtml>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/index.html
      </resultHtml>
      <resultMap>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/region.jpg
      </resultMap>
      <resultFits>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/background_IRAS_ISSA_12micron.fits
      </resultFits>
      </coverageMap>
      <summary>
      <counts>
      <imagesN>12</imagesN>
      <sourcesN>0</sourcesN>
      <spectraN>0</spectraN>
      </counts>
      <downloadScript>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/wget_data.bat
      </downloadScript>
      <dataTag>ADS/IRSA.Atlas#2017/0303/205546_3307</dataTag>
      </summary>
      <images>
      <counts>12</counts>
      <metadata>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/images.tbl
      </metadata>
      <metadataVOtable>
      http://irsa.ipac.caltech.edu:443/workspace/TMP_KlWKfI_2014/Atlas/NGC__6631_3307.v0001/images.xml
      </metadataVOtable>
      </images>
      </result>
    #+END_SRC
  + Then you can grab for example the =wwget_data.bat= file
    + Although the url is bad, since it should be https instead of http
  + And that will give you something like this
    #+BEGIN_SRC sh 
      #!/bin/sh
      #
      # To run as an executable on a unix platform, do the following:
      # chmod 775 wget_data.bat
      # ./wget_data.bat
      #
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/compcubes/MG0200n005_024_compcube.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/compcubes/MG0190n005_024_compcube.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/residual/residual_MG0190n005_024_all.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/residual/residual_MG0200n005_024_all.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_maskcube_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_maskcube_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_std_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_std_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0190n005_covg_024.fits"
      wget -x "https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL/images/mosaics24/MG0200n005_covg_024.fits"

    #+END_SRC
  + Alternatively, the images.xml table has the list of FITS images and associated metadata as a VOTable
  + Or the images.tbl has it as a simple table
  + Either should be readable with astropy
**** Download all the MIPS 24 micron images
:PROPERTIES:
:ID:       37783AC4-74A2-48EC-AE19-006509FEA4F5
:END:
#+BEGIN_SRC sh
mkdir -pv OB/MipsGal
#+END_SRC

#+BEGIN_SRC python :eval no :tangle mipsgal-image-stamps.py
  import os
  import sys
  import requests
  import xmltodict
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  from astropy.wcs import WCS
  import astropy.units as u
  import astropy.coordinates as coord

  SST_URL = 'http://irsa.ipac.caltech.edu/cgi-bin/Atlas/nph-atlas'
  mipsgal_params = {
      'mission': 'MIPSGAL',
      'mode': 'PI',
      'regSize': '0.01',
      'covers': 'on',
  }
  IMG_URL_ROOT = 'https://irsa.ipac.caltech.edu:443/data/SPITZER/MIPSGAL'

  SOURCE_DIR = 'OB/Kobulnicky2016'
  source_table = Table.read(
      os.path.join(SOURCE_DIR, 'table1.dat'),
      format='ascii.cds',
      readme=os.path.join(SOURCE_DIR, 'ReadMe')
  )

  OUTPUT_IMAGE_DIR = 'OB/MipsGal'
  IMAGE_SIZE_DEGREES = 4.0/60.0           


  def skycoord_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{data['DE-']}{data['DEd']} {data['DEm']} {data['DEs']}"
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))

  try:
      k1 = int(sys.argv[1])
  except:
      k1 = None
  try:
      k2 = int(sys.argv[2])
  except:
      k2 = None

  # Loop over all sources in the table
  for source_data in source_table[k1-1:k2]:
      print(source_data["Seq", "Name", "Alias", "R0"])
      # Make a SkyCoord object
      c = skycoord_from_table_row(source_data)
      # Perform a search around the specified coordinates
      r = requests.get(SST_URL,
                       params={**mipsgal_params, 'locstr': c.to_string()})

      # Extract the URL of the table of images (if present)
      try:
          img_tbl_url = xmltodict.parse(r.content)['result']['images']['metadata']
      except KeyError:
          # Probably a source without Spitzer observations
          continue
      # Need to switch to https and grab the file
      r2 = requests.get(img_tbl_url.replace('http:', 'https:'))
      # We need to remove the first line from the table so that it can be parsed
      table_lines = r2.content.decode().split('\n')[1:]
      # Then read it in as another astropy table
      img_table = Table.read(table_lines, format='ascii')

      # Select out all the images that are mosaic science images
      mosaic_images = {}
      for img_row in img_table:
          fname = img_row['fname']
          m_id = fname.split('/')[-1].split('_')[0]
          if img_row['file_type'] == 'science' and 'mosaics24' in fname:
              mosaic_images[m_id] = os.path.join(IMG_URL_ROOT, fname)


      # Expand the image size for bigger bows
      expand = 1.0
      for threshold in 40.0, 80.0, 160.0:
          if source_data["R0"] > threshold:
              expand *= 2


      # Now make postage stamps of all the selected images
      for m_id in mosaic_images:
          hdu = fits.open(mosaic_images[m_id])[0]
          w = WCS(hdu)
          # pixel coord of source
          i0, j0 = np.round(c.to_pixel(w))
          # find pixel limits of cut-out image window around source
          xpix_scale, ypix_scale = np.abs(w.wcs.cdelt)
          di = np.round(0.5*IMAGE_SIZE_DEGREES*expand/xpix_scale)
          dj = np.round(0.5*IMAGE_SIZE_DEGREES*expand/ypix_scale)
          win = slice(int(j0 - dj), int(j0 + dj)), slice(int(i0 - di), int(i0 + di))
          # Construct a new HDU
          hdr_win = w.slice(win).to_header()
          for k in 'Seq', 'Name', 'R0', 'PA':
              hdr_win[k] = source_data[k]
          hdr_win['MIPSGAL'] = m_id
          hdr_win['ORIGURL'] = mosaic_images[m_id]
          imwin = fits.PrimaryHDU(
              data=hdu.data[win],
              header=hdr_win)
          # Construct a suitable file name
          imid = f"{source_data['Seq']:04d}-{source_data['Name']}-{m_id}"
          imfn = os.path.join(OUTPUT_IMAGE_DIR, f'{imid}.fits')
          imwin.writeto(imfn, overwrite=True)
#+END_SRC
**** DONE [2/2] Larger fields of view for larger bow shocks
CLOSED: [2020-02-14 Fri 12:09]
+ Current FOV is 4 arcmin = 240 arcsec
+ We really need to go out to at least 3 x radius, probably better 5 x radius
***** DONE Identify the large bow shocks
CLOSED: [2020-02-14 Fri 11:01]
+ Larger than 40 arcsec, which gets all the ones that get a bit too close to their box
+ This is calculated in jupyter notebook
  + [[file:Find-big-MIPSGAL-bows.ipynb]]
  + [[file:Find-big-MIPSGAL-bows.py]]
+ There are 21 potential MIPSGAL sources in all (there are others, but they are WISE only)
+ Many have missing fits files, which is worrying
  + See last column in table below
  + Two of them have two FITS files
  + I suspect that this is because they are WISE-only, because they are off the Galactic plane
+ Of the ones that remain, most have R0 < 80, so 2x window is enough, while two have 80 < R0 < 150, so 4x window for them
  + Full list: 111, 292, 308, 442, 489, 509, 534, 542, 595, 676, 677, 707

| Seq | Name              | Alias    |    R0 | Rating | Comment            | FITS |
|-----+-------------------+----------+-------+--------+--------------------+------|
|  13 | G006.2812+23.5877 | Zeta Oph | 299.0 |      0 | --                 |      |
|  39 | G013.4900+01.6618 | --       |  73.0 |      0 | --                 |      |
|  54 | G015.0813-00.6570 | HD165319 |  95.0 |      0 | Missing            |      |
|  66 | G016.9848+01.7482 | --       |  61.0 |      0 | Missing            |      |
| 111 | G024.2512+00.7906 | --       |  58.0 |      4 | --                 |    1 |
| 292 | G056.5717-00.8290 | --       |  43.0 |      5 | Asymmetric         |    1 |
| 308 | G061.5950-00.6887 | --       |  45.7 |      0 | Fit failed         |    1 |
| 310 | G061.8355+02.9452 | --       |  40.5 |      0 | Missing            |      |
| 431 | G302.4232+03.1730 | DY Cru   | 245.0 |      0 | Missing            |      |
| 432 | G302.4623+03.1796 | Beta Cru | 245.0 |      0 | Missing            |      |
| 442 | G305.7952+00.1583 | --       |  40.5 |      5 | --                 |    1 |
| 489 | G311.1657+00.0448 | --       |  41.0 |      5 | --                 |    2 |
| 509 | G315.3719+00.6043 | --       |  67.0 |      3 | --                 |    1 |
| 534 | G319.7182-00.7290 | --       | 109.0 |      2 | Bow shock too big! |    1 |
| 542 | G322.1986+00.5183 | --       | 144.0 |      2 | Bow shock too big! |    1 |
| 595 | G333.3665-00.4112 | --       |  40.6 |      5 | --                 |    1 |
| 662 | G347.1413+02.3800 | HD153426 |  65.0 |      0 | Missing            |      |
| 676 | G349.8858+00.1258 | --       |  42.0 |      2 | Rc a bit too small |    1 |
| 677 | G350.0056-00.4521 | --       |  41.0 |      3 | Double shell       |    1 |
| 679 | G350.0969+22.4904 | HD143275 | 318.0 |      0 | Missing            |      |
| 707 | G359.4811+00.2780 | --       |  44.0 |      0 | Fit failed         |    2 |




***** DONE Download larger field
CLOSED: [2020-02-14 Fri 12:09]
+ This was done in an eshell
  #+begin_example
    for i in 111 292 308 442 489 509 534 542 595 676 677 707 {python mipsgal-image-stamps.py $i $i}
  #+end_example
+ So we have them all now
**** DONE Get the WISE images too
CLOSED: [2020-07-11 Sat 20:54]
+ The API is described at https://irsa.ipac.caltech.edu/docs/irsa_image_server.html
+ Looks to be similar to the Atlas one above
+ But also lets you ask for a cutout instead of the entire image
+ Two options: SIA or IRSA - we will try the first
+ Even so, there is more than one way of doing it.
+ I have worked everything out in this notebook:
  + [[file:Test-WISE-image-search.py]]
  + [[file:Test-WISE-image-search.ipynb]]
+ Now for the production version

#+begin_src python :eval no :tangle wise-image-stamps.py
  import sys
  import io
  from pathlib import Path
  import requests
  import numpy as np
  from astropy.table import Table
  from astropy.io import fits
  import astropy.units as u
  import astropy.coordinates as coord

  SIA_URL = 'https://irsa.ipac.caltech.edu/SIA'

  sia_params = {
      'COLLECTION': 'wise_allwise',
      'RESPONSEFORMAT': 'VOTABLE',
      'FORMAT': 'image/fits',
      'POS': 'circle $RA $DEC 0.0',
  }

  SOURCE_DIR = Path('OB/Kobulnicky2016')
  source_table = Table.read(
      str(SOURCE_DIR / 'table1.dat'),
      format='ascii.cds',
      readme=str(SOURCE_DIR / 'ReadMe')
  )

  OUTPUT_IMAGE_DIR = Path('OB/WISE')
  OUTPUT_IMAGE_DIR.mkdir(exist_ok=True)

  BASE_IMAGE_SIZE_ARCMIN = 8.0

  def skycoord_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{data['DE-']}{data['DEd']} {data['DEm']} {data['DEs']}"
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))

  try:
      k1 = int(sys.argv[1])
  except:
      k1 = 1
  try:
      k2 = int(sys.argv[2])
  except:
      k2 = None

  # Loop over all sources in the table
  for source_data in source_table[k1-1:k2]:
      print(source_data["Seq", "Name", "Alias", "R0"])

      # Make a SkyCoord object
      c = skycoord_from_table_row(source_data)
      sia_params['POS'] = f"circle {c.to_string()} 0.0"

      # Perform a search around the specified coordinates
      r = requests.get(SIA_URL, params=sia_params)

      tab = Table.read(io.BytesIO(r.content), format='votable')

      # Expand the image size for bigger bows
      expand = 1.0
      for threshold in 40.0, 80.0, 160.0:
          if source_data["R0"] > threshold:
              expand *= 2
      image_size = BASE_IMAGE_SIZE_ARCMIN*expand
      image_params = {
          "center": f"{c.ra.deg:.4f},{c.dec.deg:.4f}",
          "size": f"{image_size}, {image_size} arcmin",
          "gzip": 0,
      }
      # Now fetch images in each band
      for data in tab:
          print(
              f"Fetching image ({image_size} arcmin square) from",
              data['access_url'].decode(),
          )
          r = requests.get(data['access_url'], params=image_params)
          hdulist = fits.open(io.BytesIO(r.content))
          # Get name of WISE bandpass as a unicode string
          bpname = data['energy_bandpassname'].decode()
          hdulist.writeto(
              OUTPUT_IMAGE_DIR / f"{source_data['Seq']:04d}-{bpname}.fits",
              overwrite=True,
          )


#+end_src
*** Get WISE images of the Bodensteiner BSC sources
+ Copy the methodology of Kobulnicky-WISE sources
  + Except that we use astroquery to download the catalog on the fly
+ Tests in this notebook
  + [[file:Look at the Bodensteiner sample.py]]
  + [[file:Look at the Bodensteiner sample.ipynb]]
+ Now for the production version

#+begin_src python :eval no :tangle bsc-wise-image-stamps.py
  import sys
  import io
  from pathlib import Path
  import requests
  import numpy as np
  from astropy.table import Table, join
  from astropy.io import fits
  import astropy.units as u
  import astropy.coordinates as coord
  from astroquery.vizier import Vizier

  SIA_URL = 'https://irsa.ipac.caltech.edu/SIA'

  sia_params = {
      'COLLECTION': 'wise_allwise',
      'RESPONSEFORMAT': 'VOTABLE',
      'FORMAT': 'image/fits',
      'POS': 'circle $RA $DEC 0.0',
  }

  Vizier.ROW_LIMIT = -1
  catalogs = Vizier.get_catalogs("J/A+A/618/A110")
  source_table = join(catalogs[0], catalogs[1])
  source_table.sort(keys=["RAJ2000", "DEJ2000"])
  # Restrict to only bow shock sources
  m = (source_table["MClass"] == "bs") | (source_table["MClass"] == "bsna")
  source_table = source_table[m]

  OUTPUT_IMAGE_DIR = Path('OB/BSC-WISE')
  OUTPUT_IMAGE_DIR.mkdir(exist_ok=True)

  BASE_IMAGE_SIZE_ARCMIN = 8.0

  def skycoord_from_table_row(data):
      ra = data["RAJ2000"]
      dec = data["DEJ2000"]
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))

  try:
      k1 = int(sys.argv[1])
  except:
      k1 = 1
  try:
      k2 = int(sys.argv[2])
  except:
      k2 = None

  # Loop over all sources in the table
  for source_data in source_table[k1-1:k2]:
      print(source_data["HD", "Name", "R0A"])

      # Make a SkyCoord object
      c = skycoord_from_table_row(source_data)
      sia_params['POS'] = f"circle {c.to_string()} 0.0"

      # Perform a search around the specified coordinates
      r = requests.get(SIA_URL, params=sia_params)

      tab = Table.read(io.BytesIO(r.content), format='votable')

      # Expand the image size for bigger bows
      expand = 1.0
      for threshold in 40.0, 80.0, 160.0:
          if 60*source_data["R0A"] > threshold:
              expand *= 2
      image_size = BASE_IMAGE_SIZE_ARCMIN*expand
      image_params = {
          "center": f"{c.ra.deg:.4f},{c.dec.deg:.4f}",
          "size": f"{image_size}, {image_size} arcmin",
          "gzip": 0,
      }
      # Now fetch images in each band
      for data in tab:
          print(
              f"Fetching image ({image_size} arcmin square) from",
              data['access_url'].decode(),
          )
          r = requests.get(data['access_url'], params=image_params)
          hdulist = fits.open(io.BytesIO(r.content))
          # Get name of WISE bandpass as a unicode string
          bpname = data['energy_bandpassname'].decode()
          hdulist.writeto(
              OUTPUT_IMAGE_DIR / f"HD{source_data['HD']:06d}-{bpname}.fits",
              overwrite=True,
          )


#+end_src
**** TODO Initial comments on the BSC WISE sources
+ Lots of sources have straight filaments crossing the curved bow
  + Sometimes these are chiefly seen in W3 (12 micron)
  + Sometimes they also light up near the source in W4 (22 micron)
    + An example is HD 111123 - \beta Cru, D = 85 pc, B1IV
      + This has a nice curved bow (R = 0.12 pc)
      + But also, straight filaments which are mainly visible in W4
      + And which are brighter closer to the star
      + Strangely, the bow shock is apparently misaligned by 150 deg, despite having a very large space velocity of 150 km/s
    + Note that HD 108248, alpha Cru has a misaligned image
+ Small bows visible in the same field
  + In same field as HD 115842 - HR 5027, D = 1540 pc
  + B0.5Ia/ab supergiant with big symmetric bow (R = 1.70 pc)
    + Bow is very bright in Akari 60 micron too
  + Another source at 13:23:38.3027 -56:02:27.293
    + Has a much smaller bow, which is visible in W3 and W2
    + Source seems to be TYC 8666-1967-1
      + parallax = 0.6490 +/- 0.0512 => D = 1540 +/- 121 pc
      + Amazingly, this is the same as HR 5027 (although Gaia distance for HR 5027 puts it slightly further away)
      + The are 0.5 deg away from one another, which is 13 pc at 1.5 kpc
+ Maybe not a bow shock?
  + HD 213087 - 26 Cep, D = 1600 pc, R = 2.58 pc, B0.5 Ib
    + This one does look suspiciously sharp-edged, which originally made me think it was an H II region
    + But looking at the 3-color image, it doesn't look like it, since it has no 12 micron emission
    + The star seems to have excavated a rectangular cavity, so maybe it is a bow shock
  + HD 135742, Beta Lib, B8 Vn, D = 57 pc, R = 0.01 pc
    + I just can't see it at all
  + HD 141637, b Sco, B1.5 Vn, R = 0.02 pc, again can't see it
  + HD 110879, beta Mus, D = 105 pc, R = 0.03 pc, 
+ Certainly not a bow shock
  + HD 203280, alpha Cep, Avn, D = 15 pc !!!
    + Their is IR emission all around and it looks lie molecular filaments
      + In Akari it is brighter at 150 than 70
    + What is identified as the bow shock looks like a chance superposition
    + The molecular gas may be associated with the Dark cloud TGU H598 - Dobashi:2005a
      + It is very close to clump P8 of this cloud
      + alpha Cep is even marked in their Fig 11
+ Super straight bows
  + HD 214680 - 10 Lac, O9V, D = 500 pc, R = 0.94 pc
    + Very straight at 22 micron
    + Looks slightly more curved in Akari 60 micron
  + HD 203064 - 68 Cyg, O7.5 III n((f)), d = 1400 pc, R = 1.5 pc	
    + Various filaments at different angles
  + HD 044743, beta CMa, B1II-III, D = 151 pc, R = 0.25 pc
    + Filaments are slightly curved around star, but I am not totally convinced there is a dynamic interaction
    + But there again, we never see filaments that curve the other way
+ Multiple bows
  + HD 175362 - V686 CrA, B3V, D = 132 pc, R0 = 0.25 pc
    + Beautiful wide bow, with 12 \to 22 micron color gradient
    + W3 is brighter on inside and W4 is brighter on outside
    + Also seen in optical!
      + DSS2 shows blue filaments (Pleiades-like) that cross the star
      + Plus blue continuum from inner edge of bow shock
        + (we have to be careful with the PSF, which shows a ring with a similar radius)
      + DSS2-red shows the outer part of bow shock (H alpha/)
        + (Again, though, there may be some artifacts related to joins between fields)
    + The bow also shows up strongly at longer wavelengths in Akari and IRAF
    + The source is close to the globular cluster NGC 6723
    + Also close to the Corona Australis Molecular Cloud (about 3 pc away)
      + This has the embedded source R CrA, which supposedly is B5 III and has jets and everything
      + Two bright reflection nebulae also in this cloud
        + One around TY CrA (B9e) and HD 176386 (B9 V)
          + Maybe TY CrA has a tiny bow-shock visible in K-band (R = 14 arcsec = 0.009 pc), which is 30 times smaller than V686 CrA
        + Another around HD 176270 (B9V) and HD 176269 (B9V)
        + These are pleiades type with blue filaments
  + HD 210839, lam Cep, O6.5 In, D = 606 pc, R = 1.4 pc
    + Very complicated structure, but clearly a bow shock
  + HD 143275, del Sco, B0.3 IV, D = 150 pc
    + Has fainter stuff on the other side, so maybe a shell rather than a bow
    + Although space velocity is high, 140 km/s
+ Small bows
  + Maia in the Pleiades - HD 23408
    + B8 III, D = 120 pc, R = 0.01 pc
    + Strangely, Maia is no longer believed to be in the class of Maia variables that were named after it (see intro to Balona:2020a)
    + May also be a larger bow, but it is hard to tell with so many filaments around
**** TODO Add in the Peri E-BOSS bow shocks
**** Uncatalogued bow shocks
+ LS I +66 4
  + HIP 338
  + RA, Dec: 00 04 16.1623262190 +66 20 56.862121655
  + l, b = 118.2184091433160 +03.9099992686053
  + O9
  + D = 1090 pc
  + Beautiful 24 micron and 60 micron bow
  + Very surprising that it is not in the Peri catalogs
    + I have double-checked and it doesn't seem to be there
+ Other objects listed in [[id:14E5C827-B660-44C4-A4EF-000254FAE8D2][Particular objects]] in [[file:~/Dropbox/dust-wave-case-studies/dust-wave-case-studies.org][file:~/Dropbox/dust-wave-case-studies/dust-wave-case-studies.org]]
**** TODO [#A] Tracing shapes of the new samples
+ For the others this was done in [[id:52F0288C-C469-4559-98A9-6F195AA9EEDF][How to trace the shapes of the OB bow shocks]] with [[file:mipsgal-trace-arc.py]]
  + But that reads the Kobulnicky:2016a data table, so we need to replace that part
  + The main things it needs are the nominal radius and PA of the bow
    + Radius is given in Bodensteiner
    + PA can be backtracked from the alpha column in the table, which is the misalignment between the PA of the bow and the proper motion
      + Since the give the proper motions too
      + Which supposedly are corrected for the local Galactic rotation according to eq (2) in Comeron:2007a
  + Two options for how to proceed:
    1. Try to wrangle the BSC sources into same form as Kobulnicky table
    2. Write a new version of the tracing program that is dedicated to the BSC sources
  + Option 2 seems easier, but first we should merge in the EBOSS sample if we can
*** DONE How to trace the shapes of the OB bow shocks
CLOSED: [2017-03-28 Tue 13:24]
:PROPERTIES:
:ID:       52F0288C-C469-4559-98A9-6F195AA9EEDF
:END:
+ Strategy is to start at the nominal PA of the bowshock axis and take radial slices
  + Maybe fit a Gaussian brightness as function of radius for each \theta
  + calculate \theta and R for each pixel
  + use \theta \pm d\theta/2 to construct a mask over all the pixels
  + where d\theta is the interval between radii
    + say, d\theta = 5\deg perhaps
+ We can stop when we have got to \pm45\deg or maybe \pm60\deg and then calculate the radius of curvature and a better estimate for the symmetry axis
  + Then we do it again, but with radii drawn from the center of curvature that we have just determined
  + We can call this angle \theta_c
  + The idea is that we are best off taking slices that are close to normal to the bowshock, so that we can get out to \theta = \pm 90\deg if we are lucky
+ [X] Note that at some point I might want to use "sky offset" frames - see documentation for =astropy.coordinates=
+ [X] Improvements to make [2017-03-09 Thu]
  + [X] Add a vector to image to show nominal axis PA
  + [X] Indicate which cases have doubt about the central star
  + [X] Use the =OVERRIDE= dict for sources with bad data
  + [X] Try taking a longer step-back distance (maybe twice R0)
  + [X] Add the \pm90 vertical lines to the graphs
  + [X] (/ABANDONED/) Mask out the stars
    + Either detect point sources
    + Or, download the 8 micron images
  + [X] Do the Rc and R90 fits
  + [X] (/ABANDONED/) Deal with cases where the object dows not fit in the box:
    + 534, 542
+ New improvements [2020-02-04 Tue 18:18]
  + [X] Measure bowshock thickness
  + [X] Measure angular brightness width
  + [X] Same but via a Gaussian fit
  + [X] Option to restrict to a subset of sources
  + [ ] Include star ratings
  + [X] Use 60 deg instead of 45 deg for circle fits
+ Further new improvements
  + [X] Compare the different values of ~CIRCLE_THETA~ 50 \to 80
    + Write each to its own subdir
    + This will give a handle on the uncertainty in planitude
    + This is now done
  + [X] Try it with and without combining the mean and peak radii
    + For the bigger sources, just the peak would be better
  + [-] Find out why it fails for lots of sources
    + [X] The large ones such as zeta oph - probably need to download a bigger image
      + Yes, we have ones that are 4 arcmin - should repeat but for 10 arcmin
    + [X] The ones in range 316 to 415 - we are missing images - is this because they are only WISE?
      + Yes, that seems to be the case: they have l in the range 90 \to 270
    + [ ] Effects of stars
      + A lot are impacted by this
      + We can mask out the stars by making regions by hand in ds9
+ List of the nicest sources
  + 001 - Rc/R0 = 0.8, R90/R0 = 1.4 (misidentified source)
  + 018 - Rc/R0 = 1.26, R90/R0 = 1.7 in hyperbola zone
  + 056 - Rc/R0 = 2.8, R90/R0 = 1.9 in the oblate zone
  + 060 - Smallish example of Rc/R0 ~= 1, R90/R0 ~= 2
  + 087 - On the circle curve for Rc/R0 = 2.5
  + 123 - Beautiful case of Rc/R0 = 1.42 and R90/R0 = 1.72
  + 127 - Another nice case of Rc/R0 = 2
  + 133 - small and flat
  + 231 - inner and outer shell
  + 274 - good pointed wings
  + 285 - nice open wings
  + 292 - big and flat, but asymmetric wings
  + 433 - small with triangular wings
  + 440 - small but well-formed
  + 442 - nice and pointy, circular
  + 447 - flat nose with tucked in wings
  + 489 - Closely circular with Rc/R0 = 1.25
  + 491 - Similar to 489
  + 509 - big flat thing
  + 530 - smaller pointy one
  + 595 - nice pointy wings
  + 598 - textbook example of Rc/R0 = 2
  + 634 - big cometary shape - boxy contours suggest double shell
  + 635 - flatter and big
  + 667 - nice curvy one
  + 677, 678 - these two overlap
#+BEGIN_SRC python :eval no :tangle mipsgal-trace-arc.py
  import glob
  import os
  import sys
  from pathlib import Path
  from collections import OrderedDict
  import numpy as np
  from scipy.signal import medfilt, decimate
  from astropy.table import Table, QTable
  from astropy.io import fits
  from astropy.wcs import WCS
  import astropy.units as u
  import astropy.coordinates as coord
  from astropy.modeling import models, fitting
  from astropy.visualization.wcsaxes import SphericalCircle
  from matplotlib import pyplot as plt
  import seaborn as sns
  import circle_fit_utils

  sns.set_style('white')

  DEBUG = False

  SOURCE_DIR = Path('OB/Kobulnicky2016')
  source_table = Table.read(
      str(SOURCE_DIR / 'table1.dat'),
      format='ascii.cds',
      readme=str(SOURCE_DIR / 'ReadMe')
  )



  ##
  ## Deal with command-line arguments 
  ##

  try:
      CIRCLE_THETA = abs(float(sys.argv[1]))*u.deg
      TRACE_METHOD = "peak" if float(sys.argv[1]) < 0 else "both"
  except:
      print("Adopting default CIRCLE_THETA = 60")
      CIRCLE_THETA = 60.0*u.deg
      TRACE_METHOD = "both"

  try:
      iseq_min, iseq_max = int(sys.argv[2]), int(sys.argv[3])
  except:
      iseq_min, iseq_max = 0, 999_999_999

  try:
      IMAGE_DIR = Path(sys.argv[4])
  except:
      IMAGE_DIR = Path('OB/MipsGal')

  try:
      imglob = sys.argv[5]
  except:
      imglob = ""

  # 10 Feb 2020 - now use a dedicated folder for output, which is named
  # after the value of CIRCLE_THETA
  OUTPUT_DIR = IMAGE_DIR / Path(f"circ_theta_{int(CIRCLE_THETA.value):03d}_{TRACE_METHOD}")

  # Create the output folder if it does not already exist
  OUTPUT_DIR.mkdir(exist_ok=True)

  ENVIRONMENTS = {
      'I': 'Isolated',
      'H': 'H II region',
      'FH': 'Facing H II region',
      'FB': 'Facing bright-rimmed cloud',
  }


  # Some data in the the Kobulnicky2016 table is just wrong
  OVERRIDE = {
      8: {'R0': 5.0},
      10: {'R0': 16.0},
      85: {'R0': 20.0},
      228: {'R0': 18.0},
      648: {'R0': 40},
      650: {'R0': 50},
  }
  STEP_BACK_FACTOR = 2.0

  THMIN, THMAX = coord.Angle([-160.0*u.deg, 160.0*u.deg])

  def description_from_table_row(data):
      desc = data['Name'] + '\n'
      if data['Alias']:
          desc += data['Alias'] + '\n'
      desc += f"R0 = {data['R0']:.1f} arcsec, PA = {data['PA']} deg" + '\n'
      csource = 'Multiple candidates' if data['Unc'] == 'C' else 'Single candidate'
      desc += f'{csource} for central source' + '\n'
      desc += f"Environment: {ENVIRONMENTS[data['Env']]}"
      return desc


  def skycoord_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{data['DE-']}{data['DEd']} {data['DEm']} {data['DEs']}"
      return coord.SkyCoord(f'{ra} {dec}', unit=(u.hourangle, u.deg))


  def coord_concat(array_tuple, **kwds):
      """Like numpy.concatenate but ensures result is of coordinate type"""
      return coord.SkyCoord(np.concatenate(array_tuple, **kwds))


  def find_x_for_y_fraction(x, y, ymax, yfrac):
      """Find `x` where `y` is a fraction `yfrac` of maximum `ymax`

      Returns tuple of left and right x values.  Assumes unimodal peak
      in y(x) and that the peak is near to x = 0.  If y never falls
      below the fraction on the left (right), then returns the minimum
      (maximum) value of x on that side.
      """
      try:
          xleft = np.max(x[(y < yfrac*ymax) & (x < 0.0)])
      except:
          xleft = x.min()
      try:
          xright = np.min(x[(y < yfrac*ymax) & (x > 0.0)])
      except:
          xright = x.max()
      return xleft, xright


  fitter = fitting.LevMarLSQFitter()

  #
  # Sherpa/Saba is suspended 11 Feb 2020 - crashes with composite models
  #
  # This one is for getting uncertainties in the fitted shell thickness
  # It require sherpa and saba packages to be installed (I had to
  # install them from source)
  # sfitter = fitting.SherpaFitter(
  #     statistic='chi2',
  #     optimizer='levmar',
  #     estmethod='confidence',
  # )

  for source_data in source_table:

      if not iseq_min <= source_data['Seq'] <= iseq_max:
          # Skip this source if not in the requested range
          continue

      print(source_data)

      # Override data from table where necessary
      if source_data['Seq'] in OVERRIDE:
          for k, v in OVERRIDE[source_data['Seq']].items():
              source_data[k] = v

      # Coordinates of source central star
      c = skycoord_from_table_row(source_data)
      # Find all the images for this source
      provisional_list = IMAGE_DIR.glob(
          # f"*-{source_data['Name']}-*.fits"
          f"{source_data['Seq']:04d}*{imglob}.fits"
      )
      # Look for an image that is good
      good_image_list = []
      for image_path in provisional_list:
          hdu, = fits.open(image_path)
          # looks_good = hdu.header['NAXIS1'] == hdu.header['NAXIS2']
          looks_good = (hdu.header['NAXIS1'] > 100) &  (hdu.header['NAXIS2'] > 100)
          if looks_good:
              good_image_list.append(image_path)

      if good_image_list:
          # Use the first one in the list - because: why not?
          image_path = good_image_list[0]
          hdu, = fits.open(image_path)
      else:
          # If there were no good images, then never mind
          print("ABORT - no good images")
          continue

      image_stem = image_path.stem

      # Create WCS object for this image
      w = WCS(hdu)
      # Save pixel scale for later use
      pix_size = coord.Angle(abs(w.wcs.cdelt[0]), unit=u.deg)
      # Find celestial coordinates for each pixel
      ny, nx = hdu.data.shape
      xpix = np.arange(nx)[None, :]
      ypix = np.arange(ny)[:, None]
      cpix = coord.SkyCoord.from_pixel(xpix, ypix, w)
      # Now find radius and position angle from source
      rpix = c.separation(cpix).to(u.arcsec)
      pa_pix = c.position_angle(cpix).to(u.degree)
      # Nominal PA of bowshock axis from table
      pa0 = coord.Angle(source_data['PA'], unit=u.degree)
      # theta is angle from nominal axis, set to range [-180:180]
      theta_pix = coord.Longitude(pa_pix - pa0, wrap_angle=180*u.degree)

      # Also create an offset frame in case we need it later, in which
      # measurements are with respect to the central source coordinate,
      # and rotated by pa0
      offset_frame = c.skyoffset_frame(rotation=pa0)
      # Coordinates of each pixel in the offset frame - this has
      # components: offset_pix.lat (along pa0) and offset_pix.lon
      # (perpendicular to pa0)
      offset_pix = cpix.transform_to(offset_frame)

      # Nominal arc radius from source table
      R0 = source_data['R0']*u.arcsec

      # Only look in a restricted range of radius around R0
      rad_mask = (rpix > 0.5*R0) & (rpix < 3.0*R0)

      # Minimum and median brightness, which we might need later
      bright_min = np.nanmin(hdu.data)
      bright_median = np.nanmedian(hdu.data)
      # Calculate a robust stddev as 1.4826 times MAD
      bright_mad = np.nanmedian(np.abs(hdu.data - bright_median))
      bright_sigma = 1.4826*bright_mad

      # Next, we trace the arc

      # 08 Mar 2017 - Try a different tack - take radii from a center
      # that is "stepped back" by STEP_BACK_FACTOR times R0 away from
      # the source
      c_sb = coord.SkyCoord(0.0*u.deg, -STEP_BACK_FACTOR*R0,
                            frame=offset_frame).transform_to('icrs')
      # Repeat all the above to find radius, angle from this new point
      # Now find radius and position angle from source
      r_sb_pix = c_sb.separation(cpix).to(u.arcsec)
      pa_sb_pix = c_sb.position_angle(cpix).to(u.degree)
      # theta is angle from nominal axis, set to range [-180:180]
      th_sb_pix = coord.Longitude(pa_sb_pix - pa0, wrap_angle=180*u.degree)
      # And a frame relative to the "step back" center too
      sb_offset_frame = c_sb.skyoffset_frame(rotation=pa0)


      # Loop over a grid of angles between +/- 80 degrees
      ntheta = 68
      theta_grid, dtheta = np.linspace(-80.0, 80.0, ntheta, retstep=True)
      # Make everything be a longitude in range [-180:180]
      th_sb_grid = coord.Longitude(theta_grid, unit=u.degree, wrap_angle=180*u.degree)
      dtheta = coord.Longitude(dtheta, unit=u.degree, wrap_angle=180*u.degree)
      r_sb_peak_grid = []
      r_sb_mean_grid = []
      bmax_grid = []
      bmean_grid = []
      for th_sb in th_sb_grid:
          # Select only pixels in the wedge within +/- dtheta/2 of this theta
          theta_mask = np.abs(th_sb_pix - th_sb) < 0.5*dtheta
          # Combine with the radius mask
          m = theta_mask & rad_mask

          if np.alltrue(~m):
              # If mask is empty, fill in this theta with NaNs
              r_sb_peak = np.nan*u.deg
              r_sb_mean = np.nan*u.deg
              bright_max = np.nan
              bmean = np.nan
              print("Empty mask for theta =", th_sb)
          else:            
              # Try a variety of methods for determining the arc radius
              # at this theta ...

              # Peak brightness
              ipeak = hdu.data[m].argmax()
              r_sb_peak = r_sb_pix[m][ipeak]

              # Mean brightness-weighted radius. We divide weights by
              # radius to compensate for density of pixels. Also, we
              # select only points brighter than 0.5 times the peak
              # brightness in this wedge.  And all brightnesses are
              # relative to a background floor, which is either the
              # median over the whole image or, if the peak in the wedge
              # is lower than that, then the minimum over the image
              bright_max = np.nanmax(hdu.data[m])
              bright_floor = bright_median if bright_max > bright_median else bright_min
              mb = (hdu.data - bright_floor) > 0.5*(bright_max - bright_floor)
              weights = (hdu.data[m & mb] - bright_floor)/r_sb_pix[m & mb]
              try: 
                  r_sb_mean = np.average(r_sb_pix[m & mb], weights=weights)
                  bmean = np.average(hdu.data[m & mb], weights=weights)
              except ZeroDivisionError:
                  r_sb_mean = np.nan*u.deg
                  bmean = np.nan
              if DEBUG:
                  print("Bright max, mean = ", bright_max, bmean, "for theta =", th_sb)

          # Fit Gaussian to profile - TODO?

          # Save all quantities into grid lists
          r_sb_mean_grid.append(r_sb_mean)
          r_sb_peak_grid.append(r_sb_peak)
          bmax_grid.append(bright_max)
          bmean_grid.append(bmean)

      # convert to single array of each quantity
      r_sb_mean_grid = coord.Angle(r_sb_mean_grid)
      r_sb_peak_grid = coord.Angle(r_sb_peak_grid)
      bmax_grid = np.array(bmax_grid)
      bmean_grid = np.array(bmean_grid)


      # Now switch back to the frame centered on the source

      # Get the arc coordinates in RA, Dec
      #
      # Use the offset frame centered on the source and aligned with PA
      # axis.  The order of components is (lon, lat) where lon is
      # perpendicular and lat parallel to the bowshock axis
      rmean_coords = coord.SkyCoord(
          r_sb_mean_grid*np.sin(th_sb_grid),
          r_sb_mean_grid*np.cos(th_sb_grid),
          frame=sb_offset_frame).transform_to('icrs')
      rpeak_coords = coord.SkyCoord(
          r_sb_peak_grid*np.sin(th_sb_grid),
          r_sb_peak_grid*np.cos(th_sb_grid),
          frame=sb_offset_frame).transform_to('icrs')

      # Switch back to frame centered on source
      rmean_grid = c.separation(rmean_coords).to(u.arcsec)
      theta_mean_grid = coord.Longitude(
          c.position_angle(rmean_coords).to(u.degree) - pa0,
          wrap_angle=180*u.degree)
      rpeak_grid = c.separation(rpeak_coords).to(u.arcsec)
      theta_peak_grid = coord.Longitude(
      c.position_angle(rpeak_coords).to(u.degree) - pa0,
          wrap_angle=180*u.degree)

      # Fit circle to peak points within CIRCLE_THETA of axis
      cmask_peak = np.abs(theta_peak_grid) <= CIRCLE_THETA
      cmask_mean = np.abs(theta_mean_grid) <= CIRCLE_THETA
      # Use the mean and peak points
      try:
          if TRACE_METHOD == "both":
              points2fit = coord_concat((rpeak_coords[cmask_peak],
                                         rmean_coords[cmask_mean]))
          elif TRACE_METHOD == "peak":
              points2fit = rpeak_coords[cmask_peak]

          # Winnow out the points with radii too far from median
          r2fit = c.separation(points2fit).to(u.arcsec)
          rmed = np.median(r2fit)
          print('Median radius for circle fit:', rmed)
          mfit = (r2fit >= 0.5*rmed) & (r2fit <= 2.0*rmed)
          n_drop = (~mfit).sum()
          if n_drop > 0:
              print(n_drop, 'points dropped for circle fit')
          points2fit = points2fit[mfit]
          # Initial guess for center would make Rc/R0 = 2
          center0 = coord.SkyCoord(0.0*u.deg, -R0,
                                   frame=offset_frame).transform_to('icrs')
          Rc, center = circle_fit_utils.fit_circle(points2fit, center0)
          Rc = Rc.to(u.arcsec)
      except:
          print('ABORT - Problem with points2fit or circle_fit_utils.fit_circle')
          continue


      if Rc > 100*R0:
          print('ABORT due to ridiculous radius of curvature: Rc =', Rc)
          continue

      # Find standard deviation of points from circle
      Rc_sigma = np.std(
          circle_fit_utils.deviation_from_circle(points2fit, center)
      ).to(u.arcsec)

      # Find PA of circle fit
      # First assume case where center of curvature is "behind" the source
      pa_circ = center.position_angle(c).to(u.deg)
      # Find difference between fitted and nominal position angle
      delta_pa = coord.Longitude(pa_circ - pa0, wrap_angle=180*u.deg)
      if np.abs(delta_pa) > 90*u.deg:
          # Check for Case where center of curvature is "in front of" the source
          pa_circ = c.position_angle(center).to(u.deg)
          delta_pa = coord.Longitude(pa_circ - pa0, wrap_angle=180*u.deg)

      # Find our estimate of R0
      #
      # Make some masks selecting points within 10 deg of pa_circ
      # m0_peak = np.abs(theta_peak_grid - delta_pa) <= 10.0*u.deg
      # m0_mean = np.abs(theta_mean_grid - delta_pa) <= 10.0*u.deg
      # 05 Feb 2020 - change to using nominal PA, instead of PA_circ to define axis
      m0_peak = np.abs(theta_peak_grid) <= 10.0*u.deg
      m0_mean = np.abs(theta_mean_grid) <= 10.0*u.deg

      # Then concatenate all the R values that meet this condition
      if TRACE_METHOD == "both":
          R0_grid = coord.Angle(
              np.concatenate((rpeak_grid.value[m0_peak],
                              rmean_grid.value[m0_mean])),
              unit=u.arcsec)
      elif TRACE_METHOD == "peak":
          R0_grid = coord.Angle(rpeak_grid.value[m0_peak], unit=u.arcsec)

      R0_fit, R0_sigma = R0_grid.mean(), R0_grid.std()
      fit_msg = f'Fitted R0 = {R0_fit.arcsec:.1f} +/- {R0_sigma.arcsec:.1f} arcsec' + '\n'

      # Make an offset frame centered on the center of curvature
      circ_offset_frame = center.skyoffset_frame(rotation=pa_circ)
      # Find R(theta) for the fitted circle
      thdash = np.linspace(-180.0, 180.0, 501)*u.deg
      circ_points = coord.SkyCoord(
          Rc*np.sin(thdash), Rc*np.cos(thdash),
          frame=circ_offset_frame).transform_to('icrs')
      circ_theta = coord.Longitude(
          c.position_angle(circ_points).to(u.deg) - pa0,
          wrap_angle=180*u.degree)
      circ_radius = c.separation(circ_points).to(u.arcsec)
      # Eliminate points that are not within +/- 100 deg of nominal axis
      mcirc = (circ_theta >= -100.0*u.deg) & (circ_theta <= 100.0*u.deg)
      circ_radius[~mcirc] *= np.nan
      fit_msg += f'PA_circ = {pa_circ.deg:.1f}, delta PA = {delta_pa.deg:.1f}' + '\n'
      fit_msg += f'Rc = {Rc.arcsec:.1f} +/- {Rc_sigma.arcsec:.1f} arcsec' + '\n'

      # Find R90
      #
      # Make some masks selecting points within 10 deg of +90 and -90
      m90p_peak = np.abs(theta_peak_grid - 90.0*u.deg) <= 10.0*u.deg
      m90n_peak = np.abs(theta_peak_grid + 90.0*u.deg) <= 10.0*u.deg
      m90p_mean = np.abs(theta_mean_grid - 90.0*u.deg) <= 10.0*u.deg
      m90n_mean = np.abs(theta_mean_grid + 90.0*u.deg) <= 10.0*u.deg
      # Then concatenate all the R values for the two cases
      if TRACE_METHOD == "both":
          R90p_grid = coord.Angle(
              np.concatenate((rpeak_grid.value[m90p_peak],
                              rmean_grid.value[m90p_mean])),
              unit=u.arcsec)
          R90n_grid = coord.Angle(
              np.concatenate((rpeak_grid.value[m90n_peak],
                              rmean_grid.value[m90n_mean])),
              unit=u.arcsec)
      elif TRACE_METHOD == "peak":
          R90p_grid = coord.Angle(rpeak_grid.value[m90p_peak], unit=u.arcsec)
          R90n_grid = coord.Angle(rpeak_grid.value[m90n_peak], unit=u.arcsec)

      # And calculate mean and standard deviation
      R90p, R90p_sigma = R90p_grid.mean(), R90p_grid.std()
      R90n, R90n_sigma = R90n_grid.mean(), R90n_grid.std()
      fit_msg += f'R90+ = {R90p.arcsec:.1f} +/- {R90p_sigma.arcsec:.1f} arcsec' + '\n'
      fit_msg += f'R90- = {R90n.arcsec:.1f} +/- {R90n_sigma.arcsec:.1f} arcsec' + '\n'

      # Calculate angular fwhm width of brightness distribution
      x, y = theta_peak_grid.value, bmax_grid - bright_median
      try:
          b_max = np.nanmax(bmax_grid[m0_peak]) - bright_median
      except ValueError:
          print('ABORT - No valid pixels in m0_peak, cannot continue')
          continue

      if not np.isfinite(b_max):
          print("Axis peak brightnesses:", bmax_grid[m0_peak])
          print("Setting to 10 x median:", bright_median)
          b_max = 20*bright_median

      # Use 3 different brightness levels: [0.841, 0.5, 0.210], which
      # for a Gaussian correspond to [0.5, 1, 1.5] times the FWHM
      th841_left, th841_right = find_x_for_y_fraction(x, y, b_max, 0.841)
      th500_left, th500_right = find_x_for_y_fraction(x, y, b_max, 0.5)
      th210_left, th210_right = find_x_for_y_fraction(x, y, b_max, 0.210)

      # Another attempt at angular half width using Gaussian fit
      g_init = (models.Gaussian1D(amplitude=b_max, mean=0.0, stddev=60.0)
                + models.Const1D(amplitude=0.05*b_max))
      g_fit = fitter(g_init, x, y)

      # Finally fit the width on the axis

      # THE RADIAL BRIGHTNESS PROFILE
      #
      # This is to try and measure h, the bow thickness
      #
      # Use the offset_pix frame, centered on the star, with
      # offset_pix.lat along the axis and offset_pix.lon across the axis.

      # Restrict to a strip of width 0.3 times fitted radius
      strip_breadth = 0.3*R0_fit
      m = np.abs(offset_pix.lon) < 0.5*strip_breadth
      # Estimate number of image pixels across the strip
      n_across_strip = int(round(strip_breadth.arcsec / pix_size.arcsec))

      # Also restrict to points not too far from star
      m = m & (rpix < 4.0*R0_fit) 
      x, y, across = offset_pix.lat[m].arcsec, hdu.data[m], offset_pix.lon[m].arcsec

      gg_init = (
          models.Gaussian1D(amplitude=np.nanmax(y),
                            mean=R0_fit.arcsec,
                            stddev=0.5*R0_fit.arcsec)
          + models.Gaussian1D(amplitude=0.1*np.nanmax(y),
                              mean=0.0,
                              stddev=6.0)
          + models.Polynomial1D(degree=2, c0=bright_median)
          )
      # Obligatory to provide errors with SherpaFitter, at least for "chi2" statistic
      # gg_fit = sfitter(gg_init, x, y, err=bright_median*np.ones_like(y))
      try:
          gg_fit = fitter(gg_init, x, y)
      except:
          print("ABORT: Failed to fit radial brightness profile")
          continue

      # 11 Feb 2020 - shelve Sherpa for now
      # # Find the 1-sigma confidence intervals
      # gg_errors = sfitter.est_errors(sigma=1.0)

      # Save derived values from fitting the brightness profile
      R0_from_bright_fit = gg_fit[0].mean.value
      # Multiply sigma by 2 sqrt(2 ln(2)) to get FWHM
      H_from_bright_fit = 2.35*gg_fit[0].stddev.value
      Peak_from_bright_fit = gg_fit[0].amplitude.value
      # Note we need to unpack a length-1 array here
      BG_from_bright_fit, = gg_fit(R0_from_bright_fit) - Peak_from_bright_fit
      Contrast_fom_bright_fit = Peak_from_bright_fit / BG_from_bright_fit

      # Alternative thickness measurement II: direct FWHM
      # This is the same as we did for the angle breadth

      # First subtract polynomial background
      yy = y - gg_fit[-1](x)
      # Center x axis on peak position
      xx = x - R0_fit.arcsec
      # Sort the x, y points by x
      pts_order = np.argsort(xx)
      xx = xx[pts_order]
      yy = yy[pts_order]
      # Apply median filter by typical number of points in the
      # transverse direction.
      n_across_strip = 2*(n_across_strip // 2) + 1  # ensure odd number 
      yy = medfilt(yy, n_across_strip)
      xx = medfilt(xx, n_across_strip)
      # Then winnow down the number of points by a similar factor
      nwinnow = max(1, n_across_strip // 2)
      yy = yy[::nwinnow]
      xx = xx[::nwinnow]
      yymax = np.nanmax(yy[np.abs(xx <= R0_fit.arcsec)])
      # Find Half-max points
      r_in, r_out = find_x_for_y_fraction(xx, yy, yymax, 0.5)
      H_direct_fwhm = r_out - r_in

      # Save the fit data for each source
      table_file_name = f"{image_stem}-arcfit.tab"
      save_vars = [
          ['Seq', source_data['Seq']], 
          ['R0_fit', R0_fit.arcsec], 
          ['R0_sigma', R0_sigma.arcsec],
          ['pa_circ', pa_circ.deg],
          ['delta_pa', delta_pa.deg],
          ['Rc', Rc.arcsec],
          ['Rc_sigma', Rc_sigma.arcsec],
          ['R90p', R90p.arcsec],
          ['R90p_sigma', R90p_sigma.arcsec],
          ['R90n', R90n.arcsec],
          ['R90n_sigma', R90n_sigma.arcsec],
          ['th_p', th500_right],
          ['th_m', th500_left],
          ['th_p_841', th841_right],
          ['th_m_841', th841_left],
          ['th_p_210', th210_right],
          ['th_m_210', th210_left],
          ['th_g', g_fit.mean_0.value],
          ['dth_g', 2.35*g_fit.stddev_0.value],
          ['H_g', H_from_bright_fit],
          ['H_d', H_direct_fwhm],
          ['H_d_out', r_out],
          ['H_d_in', r_in],
          ['R0_g', R0_from_bright_fit],
          ['Peak24', Peak_from_bright_fit],
          ['Contrast', Contrast_fom_bright_fit],
      ]
      colnames, colvals = zip(*save_vars)
      Table(rows=[list(colvals)],
            names=list(colnames)).write(
                OUTPUT_DIR / table_file_name,
                format='ascii.tab',
                overwrite=True)

      # Save a figure for each source
      fig = plt.figure(figsize=(12, 8))

      # Make a plot of the radii and brightnesses versus theta
      ax_r = fig.add_axes((0.08, 0.55, 0.35, 0.4))
      ax_b = fig.add_axes((0.08, 0.08, 0.35, 0.4))
      ax_i = fig.add_axes((0.5, 0.1, 0.45, 0.45), projection=w)
      ax_r.plot(theta_mean_grid, rmean_grid, 'o', c='c', label='mean')
      ax_r.plot(theta_peak_grid, rpeak_grid, 'o', c='r', label='peak')
      ax_r.plot(circ_theta, circ_radius,
                '--', c='m', label='circle fit')
      ax_r.axhline(R0.value)
      ax_r.axvspan(-90.0, 90.0, facecolor='k', alpha=0.05)
      ax_r.axvspan(-CIRCLE_THETA.value, CIRCLE_THETA.value, facecolor='k', alpha=0.05)
      ax_r.axvline(0.0, c='k', ls='--')
      ax_r.legend()
      ax_r.set(xlim=[THMIN.deg, THMAX.deg],
               ylim=[0.0, None], ylabel='Bow shock radius, arcsec')
      ax_b.plot(theta_mean_grid, bmean_grid - bright_median, 'o', c='c', label='mean')
      ax_b.plot(theta_peak_grid, bmax_grid - bright_median, 'o', c='r', label='peak')
      ax_b.plot([th500_left, th500_right], [0.5*b_max]*2,
                "-", c="r", alpha=0.2, lw=5, label="_nolabel_")
      ax_b.plot([th841_left, th841_right], [0.841*b_max]*2,
                "-", c="r", alpha=0.2, lw=3, label="_nolabel_")
      ax_b.plot([th210_left, th210_right], [0.210*b_max]*2,
                "-", c="r", alpha=0.2, lw=3, label="_nolabel_")
      thgrid = np.linspace(THMIN.deg, THMAX.deg, 101)
      ax_b.plot(thgrid, g_fit(thgrid), '--', c="r", alpha=0.3, lw=3, label="_nolabel_")
      ax_b.axvspan(-90.0, 90.0, facecolor='k', alpha=0.05)
      ax_b.axvspan(-CIRCLE_THETA.value, CIRCLE_THETA.value, facecolor='k', alpha=0.05)
      ax_b.axvline(0.0, c='k', ls='--')
      ax_b.legend()
      ax_b.set(xlim=[THMIN.deg, THMAX.deg], xlabel='Angle from nominal axis, degree',
               ylim=[0.0, 1.4*b_max],
               ylabel='Bow shock brightness',
      )

      # And also plot the image
      ax_i.imshow(hdu.data,
                  vmin=bright_min, vmax=bmean_grid[m0_peak].max(), origin='lower')

      # And contours
      if bmax_grid[m0_peak].max() > bright_median:
          clevels = np.linspace(bright_median, bmax_grid[m0_peak].max(), 10)
      else:
          clevels = np.linspace(bright_median, hdu.data.max(), 10)
      ax_i.contour(hdu.data, levels=clevels, alpha=0.5)

      wtran = ax_i.get_transform('world')

      # Add markers for the traced bow shock
      ax_i.scatter(rmean_coords.ra.deg, rmean_coords.dec.deg, transform=wtran,
                   marker='.', c='c', s=30, alpha=0.5)
      ax_i.scatter(rpeak_coords.ra.deg, rpeak_coords.dec.deg, transform=wtran,
                   marker='.', c='r', s=30, alpha=0.5)

      # Add a line for the PA orientation
      PA_coords = coord.SkyCoord(
          [0.0*u.deg, 0.0*u.deg], [-2*R0, 2*R0],
          frame=offset_frame).transform_to('icrs')
      ax_i.plot(PA_coords.ra.deg, PA_coords.dec.deg,
                transform=wtran, c='orange', lw=2, alpha=0.8)

      # And plot the fitted circle
      circ = SphericalCircle((center.ra, center.dec), Rc,
                             edgecolor='m', lw=2, alpha=0.5, facecolor='none',
                             transform=wtran)
      ax_i.add_patch(circ)
      # And a line for the fitted PA axis
      PA_fit_coords = coord.SkyCoord(
          [0.0*u.deg, 0.0*u.deg], [-1.2*Rc, 1.2*Rc],
          frame=circ_offset_frame).transform_to('icrs')
      ax_i.plot(PA_fit_coords.ra.deg, PA_fit_coords.dec.deg,
                transform=wtran, c='m', lw=1.5, alpha=0.6)
      # And the center of curvature
      ax_i.scatter(center.ra.deg, center.dec.deg, transform=wtran,
                   marker='o', s=30, edgecolor='k', facecolor='m')
      # Add a marker for the source
      ax_i.scatter(c.ra.deg, c.dec.deg, transform=wtran,
                   s=150, marker='*', edgecolor='k', facecolor='orange')


      # Add coordinate grids
      ax_i.coords.grid(color='m', linestyle='solid', alpha=0.2)
      ax_i.coords['ra'].set_axislabel('Right Ascension')
      ax_i.coords['dec'].set_axislabel('Declination')
      overlay = ax_i.get_coords_overlay('galactic')
      overlay.grid(color='c', linestyle='solid', alpha=0.2)
      overlay['l'].set_axislabel('Galactic Longitude')
      overlay['b'].set_axislabel('Galactic Latitude')

      # Add title
      ax_i.text(0.5, 1.7, description_from_table_row(source_data),
                transform=ax_i.transAxes, ha='center', va='bottom'
      )
      ax_i.text(0.5, 1.6, fit_msg,
                transform=ax_i.transAxes, ha='center', va='top'
      )

      fig.savefig(OUTPUT_DIR /  f"{image_stem}-multiplot.pdf")
      # Important to close figure explicitly so as not to leak resources
      plt.close(fig)



      # And another fig for the radial brightness profile
      fig, ax = plt.subplots()
      ax.scatter(x, y, c=across, marker='.', alpha=0.2)
      xgrid = np.linspace(x.min(), x.max(), 101)
      ax.plot(xgrid, gg_fit(xgrid), '-', color="k")
      ax.plot(xgrid, gg_fit[0](xgrid), '--', lw=0.5, color="k")
      # And plot the median-filtered profile used to find direct FWHM
      ax.plot(xx + R0_fit.arcsec, yy, '-', color="g")
      ax.plot(np.array([r_in, r_out]) + R0_fit.arcsec, [0.5*yymax]*2,
              "-", color="g", lw=3, alpha=0.3)
      ax.axvline(0.0, c="k", ls="--")
      ax.axvline(R0_fit.arcsec, c="k", ls=":")
      ax.set(
          xlabel = "Offset along axis, arcsec",
          ylabel = r"Brightness in strip of width $0.3 \times R_0$",
      )
      fig.savefig(OUTPUT_DIR / f'{image_stem}-rad-bright.pdf')
      plt.close(fig)
#+END_SRC
**** Running ~mipsgal-trace-arc.py~ for all fit variants
+ I have been doing this by hand in a shell
+ It seems to work better when done in chunks of 200 or so
+ Something like
  #+begin_src sh :eval no
    time python mipsgal-trace-arc.py -50 1 200
    time python mipsgal-trace-arc.py -50 201 500
    time python mipsgal-trace-arc.py -50 501 800
  #+end_src
+ And then repeat for first argument of ~-50, -60, -70, 50, 60, 70~
  + The absolute value of argument is ~CIRCLE_THETA~ while the sign determines whether ridge is just the peak (negative) of both peak and mean (positive)
+ Each chunk takes about 200 s, so 5 min per fit variant, and 30 min in total

**** Updated routines for circle fitting
+ Updated version of [[file:~/Work/Bowshocks/Jorge/bowshock-shape/read-shapes-LL/fit-circle-shell.py]]
+ Main difference is that we work in sky coordinates
  + =astropy.coords.SkyCoord=
#+BEGIN_SRC python :eval no :tangle circle_fit_utils.py
  import numpy as np
  import astropy.coordinates as coord
  import astropy.units as u
  import lmfit

  def Rc_from_data(points, center):
      return np.mean(center.separation(points))

  def deviation_from_circle(points, center):
      return center.separation(points) - Rc_from_data(points, center)

  def model_minus_data(params, points):
      center = coord.SkyCoord(params["ra"].value*u.deg, params["dec"].value*u.deg)
      return deviation_from_circle(points, center).arcsec

  def fit_circle(points, center0):
      """Fit a circle to `points` with initial guess that center is at
  `center0`.  Returns radius of curvature and center of curvature"""
      params = lmfit.Parameters()
      params.add("ra", value=center0.ra.deg)
      params.add("dec", value=center0.dec.deg)
      out = lmfit.minimize(model_minus_data, params, args=(points,))
      lmfit.report_fit(out)
      center = coord.SkyCoord(out.params["ra"].value*u.deg, out.params["dec"].value*u.deg)
      Rc = Rc_from_data(points, center)
      return Rc, center


#+END_SRC

**** The star ratings
+ These are in [[file:star-ratings.tab]] for the MIPSGAL fits
+ We need to also do it for WISE

**** Combining the fit data into one table
#+name: combine-arcfit-results :eval no
#+BEGIN_SRC python :results file :return combo_file :var SUFF="060_both" SET="MipsGal"
  import os
  import sys
  import glob
  from astropy.table import Table, join

  SOURCE_DIR = 'OB/Kobulnicky2016'
  source_table = Table.read(
      os.path.join(SOURCE_DIR, 'table1.dat'),
      format='ascii.cds',
      readme=os.path.join(SOURCE_DIR, 'ReadMe')
  )

  IMAGE_DIR = f'OB/{SET}/circ_theta_{SUFF}'

  # Updated 19 Feb 2020 to include inner/outer widths
  NCOLUMNS = 26                   # What it *should* be
  list_of_rows = []
  tabfiles = glob.glob(f"{IMAGE_DIR}/*-arcfit.tab")
  print(tabfiles)
  for tabfile in tabfiles:
      t = Table.read(tabfile, format='ascii.tab')
      if len(t.colnames) == NCOLUMNS:
          list_of_rows.append(t[0])

  print(list_of_rows)

  star_prefix = "" if SET == "MipsGal" else f"{SET.lower()}-"
  fit_table = Table(rows=list_of_rows, names=t.colnames)
  star_table = Table.read(f'{star_prefix}star-ratings.tab', format='ascii.tab')

  combo_table = join(
      join(source_table, fit_table, join_type='outer'),
      star_table, join_type='outer')


  combo_file = f'{SET.lower()}-arcfit-{SUFF}.tab'
  combo_table.write(combo_file, format='ascii.tab', overwrite=True)
#+END_SRC

Note that we are no longer including the ~both~ method. 

#+call: combine-arcfit-results(SUFF="050_peak")

#+RESULTS:
[[file:mipsgal-arcfit-050_peak.tab]]

#+call: combine-arcfit-results(SUFF="060_peak")

#+RESULTS:
[[file:mipsgal-arcfit-060_peak.tab]]

#+call: combine-arcfit-results(SUFF="070_peak")

#+RESULTS:
[[file:mipsgal-arcfit-070_peak.tab]]

***** Also combine the WISE fit data
The ~both~ method has serious problems, so we ditch it.

#+call: combine-arcfit-results(SUFF="050_peak", SET="WISE")

#+RESULTS:
[[file:wise-arcfit-050_peak.tab]]

#+call: combine-arcfit-results(SUFF="060_peak", SET="WISE")

#+RESULTS:
[[file:wise-arcfit-060_peak.tab]]

#+call: combine-arcfit-results(SUFF="070_peak", SET="WISE")

#+RESULTS:
[[file:wise-arcfit-070_peak.tab]]

**** DONE Combining all the fit variants
CLOSED: [2020-02-14 Fri 08:51]
+ This is done in the jupyter notebook:
  + [[file:Merge-all-MIPSGAL-statistics.ipynb]]
  + [[file:Merge-all-MIPSGAL-statistics.py]] (editable version)
+ The merged data file is
  + [[file:mipsgal-arcfit-all-variants.tab]]
+ The columns with ~E something~ are the dispersion between fit variants, while ~e something~ are the internal dispersion within a fit variant. 

*** Plot the radius ratio diagnostics for the OB bowshocks
First, radius versus radius

#+name: plot-r0-r0
#+BEGIN_SRC python :return figfile :results file :var SET="mipsgal" SUFF="060_both"
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = f'{SET}-r0-r0-{SUFF}.pdf'

  combo_file = f'{SET}-arcfit-{SUFF}.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  # Unrated and 0 stars
  m0 = ~(m1 | m2 | m3 | m4 | m5)

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10
  
  resolution_limit = 12.0 if SET == "wise" else 5.5

  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.errorbar('R0', 'R0_fit', yerr='R0_sigma', data=tab[m],
                  fmt='o', lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  ax.plot([1.0, 400.0], [1.0, 400.0])
  ax.axhline(resolution_limit, 0.0, 0.55, ls=':', lw=1, color='k')
  ax.legend()
  ax.set(
      xlim=[2, 330], ylim=[2, 330],
      xlabel='Catalog $R_0$, arcsec',
      ylabel='Fitted $R_0$, arcsec',
      xscale='log', yscale='log')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS: plot-r0-r0
[[file:mipsgal-r0-r0-060_both.pdf]]


Old version:
[[file:mipsgal-r0-r0.pdf]]

Difference with peak method
#+call: plot-r0-r0(SET="mipsgal", SUFF="060_peak")

#+RESULTS:
[[file:mipsgal-r0-r0-060_peak.pdf]]

#+call: plot-r0-r0(SET="wise", SUFF="060_both")

#+RESULTS:
[[file:wise-r0-r0-060_both.pdf]]

#+call: plot-r0-r0(SET="wise", SUFF="060_peak")

#+RESULTS:
[[file:wise-r0-r0-060_peak.pdf]]

Various conclusions can be drawn from these: 
1. There are a lot more WISE sources (symbols), and they extend to large radii
2. The ~both~ results show a deviation to larger radii for R <= 2 W, where
   - W = 5.5 arcsec for Spitzer
   - W = 12 arcsec for WISE
3. The ~peak~ results don't seem to show a bias, just an increased spread for R <= 2 W
4. So, if we restrict ourselves to R > 20 arcsec, we can probably be free of resolution effects


And now, Rc versus R90
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')

  figfile = 'mipsgal-Rc-R90.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2)
                              + 0.5*(tab['R90p'] - tab['R90n'])**2)

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m1 = Q > 50.0
  m2 = (Q > 20.0) & ~m1
  m3 = (Q > 5.0)  & ~(m1 | m2)
  m4 = ~(m1 | m2 | m3)

  masks = m4, m3, m2, m1
  alphas = 0.1, 0.2, 0.4, 0.8
  labels = 'Q <= 5', 'Q > 5', 'Q > 20', 'Q > 50'


  for m, alpha, label in zip(masks, alphas, labels):
      ax.errorbar('Rc', 'R90', xerr='Rc_sigma', yerr='R90_sigma', data=tab[m],
                  fmt='.', lw=1, alpha=alpha, label=label)
  ax.plot([0.0, 100.0], [0.0, 100.0])
  ax.legend()
  ax.set(
      xlim=[0.1, 100.0], ylim=[0.1, 100.0],
      xlabel='Radius of curvature ratio: Rc/R0',
      ylabel='Perpendicular radius ratio: R90/R0',
      xscale='log', yscale='log')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90.pdf]]

Zoom in on the best data
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-zoom.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])
  
  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  Q = tab['R0_fit']/tab['R0_sigma']

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, m4, m5
  alphas = 0.2, 0.4, 0.8
  stars = '3', '4', '5'
  colors = 'c', 'r', 'b'
  sizes = 5, 7, 10

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.errorbar('Rc', 'R90', xerr='Rc_sigma', yerr='R90_sigma', data=tab[m],
                  fmt='o', ms=ms, lw=1, alpha=alpha, c=c, label=label)
      ax.errorbar('Rc', 'R90', yerr='R90_asym', data=tab[m],
                  fmt='none', elinewidth=0.5, alpha=alpha, ecolor=c, label=None)
      # ax.errorbar('Rcp', 'R90p', xerr='Rc_sigma', yerr='R90p_sigma', data=tab[m],
      #             fmt='o', lw=1, alpha=alpha, c=c, label=label)
      # ax.errorbar('Rcn', 'R90n', xerr='Rc_sigma', yerr='R90n_sigma', data=tab[m],
      #             fmt='s', lw=1, alpha=alpha, c=c, label=None)

  for source in tab[m5]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')
  for source in tab[m4 & (tab['Rc'] < 1.0)]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')

  ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-zoom.pdf]]

Plot KDE of the distribution


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-kde.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, (m4 | m5)
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma in zip(masks, alphas, cmaps, shades, gammas):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)



  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-kde.pdf]]

+ This figure is modified using Graphic.app to add thumbnail images of selected bow shocks
+ The result is exported in [[file:mipsgal-Rc-R90-thumbnails.pdf]]


**** DONE Test out log-log axes for these graphs
CLOSED: [2020-02-06 Thu 18:12]
+ [2019-03-31 Sun 11:30] Return to this project - reborn as Paper IV!
+ I want to see if the graphs would look better with log axes
+ That way, we wouldn't have such a long tail towards high planitude

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib.ticker as mticker
  import seaborn as sns

  #sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-zoom-log.pdf'

  range_ = [0.35, 9.5]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  Q = tab['R0_fit']/tab['R0_sigma']

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, m4, m5
  alphas = 0.2, 0.4, 0.8
  stars = '3', '4', '5'
  colors = 'c', 'r', 'b'
  sizes = 5, 7, 10

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.errorbar('Rc', 'R90', xerr='Rc_sigma', yerr='R90_sigma', data=tab[m],
                  fmt='o', ms=ms, lw=1, alpha=alpha, c=c, label=label)
      ax.errorbar('Rc', 'R90', yerr='R90_asym', data=tab[m],
                  fmt='none', elinewidth=0.5, alpha=alpha, ecolor=c, label=None)
      # ax.errorbar('Rcp', 'R90p', xerr='Rc_sigma', yerr='R90p_sigma', data=tab[m],
      #             fmt='o', lw=1, alpha=alpha, c=c, label=label)
      # ax.errorbar('Rcn', 'R90n', xerr='Rc_sigma', yerr='R90n_sigma', data=tab[m],
      #             fmt='s', lw=1, alpha=alpha, c=c, label=None)

  for source in tab[m5]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')

  for source in tab[m4 & (
          (tab['Rc'] <= 1.2) | (tab['Rc'] >= 2.5)
          | (tab['R90'] >= 2.0) 
  )]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')

  for source in tab[m3 & (
          (tab['Rc'] <= 1.0) | (tab['Rc'] >= 3.0)
          | (tab['R90'] >= 2.0) | (tab['R90'] <= 1.2)
  )]:
      ax.text(source['Rc'], source['R90'], f'{source["Seq"]}',
              fontsize=3, color='0.5', ha='center', va='center')

  ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xscale="log", yscale="log",
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-zoom-log.pdf]]

+ Do the same for the KDE graph on log axes
  + This has the problem that we want to calculate the KDE in log space, and seaborn can't do that natively
  + *SOLVED* We can do it my monkey patching!
    + We just swap out ~seaborn.distributions._statsmodels_bivariate_kde~ for our own version that takes logs of x and y first and then antilogs of the resultant grid
    + The only remaining adjustment necessary is in the contour levels


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-kde-log.pdf'

  range_ = [0.35, 9.5]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = m3, (m4 | m5)
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma in zip(masks, alphas, cmaps, shades, gammas):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
  #                bw=(0.18, 0.12),
                  bw=(0.06, 0.04),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)



  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-kde-log.pdf]]


**** TODO Isophotal thickness and breadth
+ These are the new ([2020-02-06 Thu]) quantities that we are measuring:
  + Shell Thickness :: h = H_0/R_0 where H_0 is FWHM of brightness profile along axis
  + Shell Breadth :: Angular version is \Delta\theta = \theta+ - \theta- where \theta+, \theta- are the half-brightness points measured around the shell from the star
    + Currently I am plotting 0.5 \Delta\theta in degrees
    + But we could also do a dimensionless length version, which might be better since it is more directly comparable with the thickness
      + For \Lambda = 1, we have \Delta{}s = R_0 \Delta\theta, measured in radians
      + For \Lambda \gg 1, we have \Delta{}s = R_0 tan \Delta\theta, so \Delta{}s \to \infty as \Delta\theta \to 90\deg
      + [ ] There must be a simple formula for the intermediate case
  + Spanish: grosor y anchura
+ There is a clear correlation between breadth and thickness
  + See [[file:mipsgal-h0-thb.pdf]]
  + The thin shells (h = 0.3 \to 0.7) are also narrow (HWHM \Delta\theta = 50 \to 60\deg)
    + These are mainly 5-star sources: 292, 263, 489, 123, 442, 598
    + And some 4 star: 111, 44 (beautiful and flat!), 110
    + The also tend to be leptokurtic (peaked
  + The thick shells (h = 1.5 \to 3) are also broad (HWHM \Delta\theta = 80 \to 100\deg)
    + Only 4-star sources:
      + Some supposedly have h > 2, but this is from failed fits, and h should really be smaller:
        + 048, 696 (actually thin), 046 (is quite thick, but not as much as the fit), 114 (ditto), 215
      + But some around h = 2 are more legitimate
        + 060, 589, 197 (but narrow component inside broader one), 215 (ditto), 274, 589, 021, 060, etc (some are small)
  + Intermediate shells (h = 0.7 \to 1.5)
    + 5-star: 692, 061 (maybe h should be bigger), 530 is nice, 688


***** Shell angular breadth and arc-length breadth
+ So far I have the angular breadth, but I want to convert it to an arc length
+ Two ways of doing it (see Apple Notes):
  1. Planitude method, which assumes arc is a circle

     |   \theta | s, \Pi = 1 | s, \Pi = 1.5 | s, \Pi = 2 | s, \Pi = 3 | s, \Pi = 10 | s, \Pi = \infty |
     |-----+----------+------------+----------+----------+-----------+----------|
     |   0 |     0.00 |       0.00 |     0.00 |     0.00 |      0.00 |        0 |
     |  15 |     0.26 |       0.26 |     0.26 |     0.27 |      0.27 |     0.27 |
     |  30 |     0.52 |       0.53 |     0.54 |     0.55 |      0.57 |     0.58 |
     |  45 |     0.79 |       0.82 |     0.85 |     0.88 |      0.96 |     1.00 |
     |  50 |     0.87 |       0.92 |     0.96 |     1.01 |      1.12 |     1.19 |
     |  60 |     1.05 |       1.13 |     1.20 |     1.30 |      1.53 |     1.73 |
     |  70 |     1.22 |       1.35 |     1.47 |     1.63 |      2.14 |     2.75 |
     |  80 |     1.40 |       1.59 |     1.76 |     2.04 |      3.07 |     5.67 |
     |  90 |     1.57 |       1.85 |     2.09 |     2.52 |      4.51 |  tan(90) |
     | 100 |     1.75 |       2.12 |     2.46 |     3.09 |      6.56 |    -5.67 |
     | 110 |     1.92 |       2.40 |     2.86 |     3.73 |      9.12 |    -2.75 |
     | 120 |     2.09 |       2.70 |     3.29 |     4.44 |     12.01 |    -1.73 |
     | 130 |     2.27 |       3.02 |     3.75 |     5.20 |     15.08 |    -1.19 |
     | 140 |     2.44 |       3.34 |     4.23 |     6.00 |     18.27 |    -0.84 |
     | 150 |     2.62 |       3.68 |     4.73 |     6.83 |     21.51 |    -0.58 |
     | 160 |     2.79 |       4.02 |     5.24 |     7.69 |     24.80 |    -0.36 |
     | 170 |     2.97 |       4.36 |     5.76 |     8.55 |     28.10 |    -0.18 |
     #+TBLFM: $2=rad($1);f2::$3=rad(1.5 arccos(cos($1) sqrt(1 - (sin($1)/3)**2) + (sin($1)**2)/3));f2::$4=rad(2 arccos(cos($1) sqrt(1 - (sin($1)/2)**2) + (sin($1)**2)/2));f2::$5=rad(3 arccos(cos($1) sqrt(1 - (2 sin($1)/3)**2) + (2 sin($1)**2)/3));f2::$6=rad(10 arccos(cos($1) sqrt(1 - (9 sin($1)/10)**2) + (9 sin($1)**2)/10));f2::$7=tan($1);f2

  2. Alatude method, which assumes arc is a parabola
     
     This uses an auxiliary variable, t

     |    \theta | t, \Lambda = 2 | s, \Lambda = 2 | t, \Lambda = 1.5 | s, \Lambda = 1.5 |
     |------+----------+----------+------------+------------|
     | 0.01 |   8.7e-5 |   1.7e-4 |     1.6e-4 |     1.8e-4 |
     |   15 |     0.13 |     0.26 |       0.23 |       0.26 |
     |   30 |     0.27 |     0.55 |       0.45 |       0.52 |
     |   45 |     0.41 |     0.84 |       0.67 |       0.81 |
     |   50 |     0.47 |     0.97 |       0.74 |       0.90 |
     |   60 |     0.58 |     1.22 |       0.88 |       1.11 |
     |   70 |     0.70 |     1.51 |       1.02 |       1.32 |
     |   80 |     0.84 |     1.86 |       1.17 |       1.57 |
     |   90 |     1.00 |     2.30 |       1.33 |       1.86 |
     |  100 |     1.19 |     2.86 |       1.52 |       2.23 |
     |  110 |     1.43 |     3.65 |       1.75 |       2.73 |
     |  120 |     1.73 |     4.77 |       2.03 |       3.40 |
     |  130 |     2.14 |     6.56 |       2.41 |       4.44 |
     |  140 |     2.75 |     9.78 |       2.98 |       6.29 |
     |  150 |     3.73 |    16.43 |       3.92 |      10.09 |
     |  160 |     5.67 |    35.08 |       5.80 |      20.58 |
     |  170 |    11.43 |   134.28 |      11.50 |      76.44 |
     #+TBLFM: $2=(2/2) sqrt(1 + (1/4) (2)**2 cot($1)**2) - cot($1);f2::$3=((1/4) 2**2) ($2 sqrt(1 + $2**2) + arcsinh($2));f2::$4=(2/1.5) sqrt(1 + (1/4) (1.5)**2 cot($1)**2) - cot($1);f2::$5=((1/4) 1.5**2) ($4 sqrt(1 + $4**2) + arcsinh($4));f2

     So, the \Lambda = 1.5 parabola case, starts off very similar to the \Pi = 1.5 circle case, up until about \theta = 90, and then after that it increases faster. This is just what we expect. 



***** TODO Solving the thickness problem
+ There were two puzzling issues
  1. The very good correlation of h with sqrt(R0)
  2. The discrepancy between WISE and Spitzer for the same source
+ It turns out that the two are linked, and are due to resolution effects
+ The brightness profiles have peak+wing structure and this means that Spitzer measures the width of the peak, while WISE measures the width of the wings
  + A clear example is K489, where Spitzer measures h = 23 but WISE measures h = 47, even though
+ [ ] *Solution* might be to only measure the outer width, which is generally more compact.
+ Also, should look at the behaviour of FWHM of Voigt function as you increase gaussian width \sigma, but keep Lorentzian constant.
  + So a = \Gamma/\Delta\nu_D \propto 1/\sigma
  + That isn't going to give me what I want, since wings are less important as \sigma increases :(


***** Look at thickness vs R0

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-r0-h0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10


  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.errorbar('R0_g', 'H_g', xerr='R0_sigma', data=tab[m],
                  fmt='o', lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  for source in tab[m5]:
      ax.text(source['R0_g'], source['H_g'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')
  # for source in tab[m4 & (np.abs(np.log10(tab['H_g']/tab['R0_g'])) > 0.15)]:
  for source in tab[m4]:
      ax.text(source['R0_g'], source['H_g'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')

  ax.plot([1.0, 200.0], [1.0, 200.0])
  ax.axhline(5.5, 0.0, 0.55, ls=':', lw=1, color='k')
  ax.legend()
  ax.set(
      xlim=[2, 110], ylim=[2, 110],
      xlabel='Radius $R_0$, arcsec',
      ylabel='Thickness $H_0$, arcsec',
      xscale='log', yscale='log')

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-r0-h0.pdf]]



***** TODO Utility functions to do linear regression

+ Currently this does OLS (Ordinary Least Squares), but that assumes that the x-values are fixed and that all the errors are in y
+ But in reality, there are errors on both x and y, and in addition there is cosmic variance due to un-modelled factors
+ As a result, the fitted slopes will always come out too "flat" when correlation r < 1
+ Two possible approaches:
  1. Fit y(x) and x(y) and then take the average slope (what I did with the WFC3 calibration)
  2. Use a more sophisticated method, such as:
     - [ ] ODR (Othogonal Distance Regression): ~scipy.odr~
       - This is what I will try first
       - It can use weights on the data points
       - But we will have to calculate r and p separately
     - kmpfit from Kapteyn package, see https://www.astro.rug.nl/software/kapteyn/kmpfittutorial.html
     - [X] Something from sklearn, probably overkill
       - But there is TheilSenRegressor and RANSACRegressor
       - This works, but it gives the same answer as the linear one, and it doesn't give an error estimate on the coefficients
       - Turns out that statsmodels is better for that, but that doesn't cope with errors in x
     - [X] A really sophisticated method is ~linmix~
       - https://github.com/jmeyers314/linmix for python implementation
       - These are based on Kelly:2007a (original in IDL)
       - Uses a Bayesian technique that assumes there is an underlying linear relation \eta = \alpha + \beta \xi + \sigma where \sigma is the intrinsic scatter in the relation
       - Then what we observe are x = \xi + \sigma_x and y = \eta + \sigma_y where the \sigma_x and \sigma_y are the measurement errors, which can be heteroskedastic and optionally correlated.
       - You get out posterior distributions of the slope and intercept, as well as of the "true" value of \sigma, even if it is less than \sigma_x, \sigma_y
       - It can also be used if some of the data are censored (upper limits), which might be useful in the case of the
       - I am running it now in a jupyter notebook
         - This ended up working very well
         - See [[file:Regression-with-linmix.py]]
         - Clearly shows sensitivity to the observational errors on the x axis
         - This means that we have to be very careful with calculating a decent uncertainty in R_c, which will need the use of different values for ~CIRCLE_THETA~
     - Finally there is ~leopy~
       - Described in Feldmann:2019
       - This may be even better, but it is more DIY than ~linmix~
         - You need to provide the minimization and MCMC yourself, presumably from other packages
       - So, this is more flexible in principle, but I will save it for a rainy day

#+begin_src python :eval no :tangle regress_utils.py
  import numpy as np
  from scipy.stats import linregress, pearsonr
  from sklearn.linear_model import TheilSenRegressor 
  from matplotlib import pyplot as plt


  def robust_linregress(x, y):
      """Simple interface to other regressors

      This has same signature as `scipy.stats.linregress`
      """

      # The Pearson correlation is independent of the regression
      r, p = pearsonr(x, y)

      # Fit a linear regression y = a x + b
      reg = TheilSenRegressor(random_state=443)
      X = x[:, None]
      reg.fit(X, y)
      a, = reg.coef_
      b = reg.intercept_
      da = 0.0
      return a, b, r, p, da


  def plot_regression(ax, xdata, ydata,
                      logx=False, logy=False,
                      xlabel_frac=0.8,
                      xlim=None,
                      debug=False,
                      pos="top right",
  ):
      """
      Plot linear regression of `ydata` on `xdata` using axes `ax`

      The plot is labelled with the regression slope (with uncertainty)
      and intercept, together with correlation coefficient, and p-value.

      If the axes are shown on a log scale, it may be desired to take
      log10 of data before regressing.  This is controlled by optional
      flag arguments `logx` and `logy`.

      Remaining arguments control aesthetics and layout of labeling
      """

      # Helper functions for optional log10 transformations of data
      def _x(x):
          "Forward data transformation for x axis"
          if logx:
              return np.log10(x)
          else:
              return x

      def _xx(x):
          "Backward data transformation for x axis"
          if logx:
              return 10**x
          else:
              return x

      def _y(y):
          "Forward data transformation for y axis"
          if logy:
              return np.log10(y)
          else:
              return y

      def _yy(y):
          "Backward data transformation for y axis"
          if logy:
              return 10**y
          else:
              return y


      # Linear regression on the residuals: y = a x + b
      # This does the Pearson r at the same time
      # a, b, r, p, da = linregress(_x(xdata), _y(ydata))
      a, b, r, p, da = robust_linregress(_x(xdata), _y(ydata))
      xstring = r"\log_{10} x" if logx else "x"
      ystring = r"\log_{10} y" if logy else "y"
      s = rf'Linear regression: ${ystring} = m \, {xstring} + c$'
      s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
      s += '\n' + f'Correlation: $r = {r:.2f}$'
      if p > 0.001:
          s += f' $p = {p:.4f}$'
      else:
          pexp = np.floor(np.log10(p))
          s += rf' $p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'

      if debug:
          print(s)

      # xmin, xmax need to be specified in linear space
      if xlim is None:
          xlim = np.nanmin(xdata), np.nanmax(xdata)
      # Now transform to (maybe) log space
      _xgrid = np.linspace(_x(xlim[0]), _x(xlim[1]))
      # Center of x range for pivoting the slopes
      _xc = np.nanmean(_xgrid)
      # Where to place label, controlled by argument xlabel_frac
      _xlab = _xgrid[0] + xlabel_frac*(_xgrid[-1] - _xgrid[0])
      # We need to use the backward transform helper functions _xx and
      # _yy to get everything back to linear space for plotting (and
      # then let matplotlib decide whether to show results on log scale
      # or not)
      if debug:
          print("Arrow head position:", _xx(_xlab), _yy(a*_xlab + b))

      pos_options = "top left", "top right", "bottom left", "bottom right"
      assert pos in pos_options, "Invalid label position"
      vpos, hpos = pos.split()
      xytext = (
          0.02 if hpos == "left" else 0.98,
          1.05 if vpos == "top" else 0.02,
      )
      ha = hpos
      va = vpos

      ax.annotate(s=s, 
                  xy=(_xx(_xlab), _yy(a*_xlab + b)),
                  xytext=xytext, textcoords='axes fraction',
                  arrowprops={'arrowstyle': '-|>', 'color': 'k'},
                  fontsize='small', color='k',
                  bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
                  ha=ha, va=va)
      ax.fill_between(_xx(_xgrid),
                      _yy(a*_xc + (a+da)*(_xgrid - _xc) + b),
                      _yy(a*_xc + (a-da)*(_xgrid - _xc) + b),
                      alpha=0.4)
      ax.plot(_xx(_xgrid), _yy(a*_xc + a*(_xgrid - _xc) + b), lw=2, ls=':')
#+end_src


***** Plot breadth versus thickness and \Lambda, \Pi




#+BEGIN_SRC python :return figfile :eval no :tangle mipsgal-h0-thb.py 
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib.ticker as mticker
  import seaborn as sns
  from regress_utils import plot_regression

  sns.set_color_codes('dark')

  figfile = 'mipsgal-h0-thb.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10

  range_ = [0.25, 8]
  ticks = [0.3, 0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0]

  # Add some columns
  tab["th_b"] = 0.5*(tab["th_p"] - tab["th_m"])
  tab["h"] = tab["H_g"]/tab["R0_g"]
  
  mfinite = np.isfinite(tab["h"]) & np.isfinite(tab["th_b"])

  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.plot('h', "th_b", 'o', data=tab[m],
                  lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')


  for source in tab[m4]:
      ax.text(source['h'], source['th_b'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')
  for source in tab[m5]:
      ax.text(source['h'], source['th_b'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')

  #mgood = m3 | m4 | m5
  mgood = (m5 | m4 ) & mfinite
  # mgood = (m5 | m4 | m3 | m2 | m1) & mfinite
  plot_regression(ax, tab[mgood]["h"], tab[mgood]["th_b"],
                  logx=True, xlim=range_, debug=True, pos="top right")

  ax.legend()
  ax.set(
      xlim=range_, ylim=[0, 135],
      xlabel='Dimensionless shell thickness, $h$',
      ylabel='Brightness half width half max, degrees',
      xscale='log', yscale='linear')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-h0-thb.pdf]]

# #+begin_src sh :results file
#+begin_src sh :results output
python mipsgal-h0-thb.py
#+end_src

#+RESULTS:
: Linear regression: $y = m \, \log_{10} x + c$
: $m = 33.38 \pm 0.00$, $c = 73.07$
: Correlation: $r = 0.45$ $p = 6.3 \times 10^{-6}$
: Arrow head position: 4.0 93.16946191509547

Results for (3+4+5)-star
: Linear regression: $y = m \log_{10} x + c$
: $m = 13.21 \pm 5.05$, $c = 77.13$
: Correlation: $r = 0.17$ $p = 0.0095$
: Label position: 4.0 85.08689806558364

Results for (4+5)-star
: Linear regression: $y = m \log_{10} x + c$
: $m = 28.89 \pm 6.03$, $c = 74.46$
: Correlation: $r = 0.45$ $p = 6.3 \times 10^{-6}$
: Label position: 4.0 91.85110899383268


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib.ticker as mticker
  import seaborn as sns
  from regress_utils import plot_regression
  
  sns.set_color_codes('dark')

  figfile = 'mipsgal-R90-thb.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10

  range_ = [0.7, 4]
  ticks = [0.8, 1.0, 1.2, 1.5, 2.0, 2.5, 3.0, 4.0]

  # Add some columns
  tab["th_b"] = 0.5*(tab["th_p"] - tab["th_m"])
  tab["h"] = tab["H_g"]/tab["R0_g"]
  tab["Lambda"] = 0.5*(tab['R90p'] + tab['R90n']) / tab['R0_fit']

  mfinite = np.isfinite(tab["Lambda"]) & np.isfinite(tab["th_b"])

  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.plot('Lambda', "th_b", 'o', data=tab[m],
                  lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  for source in tab[m4]:
      ax.text(source['Lambda'], source['th_b'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')
  for source in tab[m5]:
      ax.text(source['Lambda'], source['th_b'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')

  mgood = (m5 | m4 | m3) & mfinite
  plot_regression(ax, tab[mgood]["Lambda"], tab[mgood]["th_b"],
                  logx=True, xlim=range_, debug=True, pos="top right")

  ax.legend()
  ax.set(
      xlim=range_, ylim=[0, 135],
      xlabel='Alatude, $\Lambda$',
      ylabel='Brightness half width half max, degrees',
      xscale='log', yscale='linear')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-R90-thb.pdf]]

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib.ticker as mticker
  import seaborn as sns
  from regress_utils import plot_regression

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-thb.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10

  range_ = [0.35, 9.5]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  # Add some columns
  tab["th_b"] = 0.5*(tab["th_p"] - tab["th_m"])
  tab["h"] = tab["H_g"]/tab["R0_g"]
  tab["Pi"] = tab['Rc'] / tab['R0_fit']

  mfinite = np.isfinite(tab["Pi"]) & np.isfinite(tab["th_b"])

  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.plot('Pi', "th_b", 'o', data=tab[m],
                  lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  for source in tab[m4]:
      ax.text(source['Pi'], source['th_b'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')
  for source in tab[m5]:
      ax.text(source['Pi'], source['th_b'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')

  mgood = (m5 | m4 | m3) & mfinite
  plot_regression(ax, tab[mgood]["Pi"], tab[mgood]["th_b"],
                  logx=True, xlim=range_, debug=True, pos="top right")

  ax.legend()
  ax.set(
      xlim=range_, ylim=[0, 135],
      xlabel='Planitude, $\Pi$',
      ylabel='Brightness half width half max, degrees',
      xscale='log', yscale='linear')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-thb.pdf]]

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib.ticker as mticker
  import seaborn as sns
  from regress_utils import plot_regression

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-h0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))

  Q = tab['R0_fit']/tab['R0_sigma']

  # Make quality classes
  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  masks = (m1 | m2), m3, m4, m5
  alphas = 0.05, 0.3, 0.5, 0.8
  labels = '1- or 2-star', '3-star', '4-star', '5-star'
  colors = 'k', 'c', 'r', 'b'
  sizes = 3, 5, 7, 10

  range_ = [0.35, 9.5]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  # Add some columns
  tab["th_b"] = 0.5*(tab["th_p"] - tab["th_m"])
  tab["h"] = tab["H_g"]/tab["R0_g"]
  tab["Pi"] = tab['Rc'] / tab['R0_fit']

  mfinite = np.isfinite(tab["Pi"]) & np.isfinite(tab["h"])

  for m, alpha, c, ms, label in zip(masks, alphas, colors, sizes, labels):
      ax.plot('Pi', "h", 'o', data=tab[m],
                  lw=1, c=c, ms=ms, alpha=alpha,
                  label=f'{label} ($N = {m.sum()}$)')
  for source in tab[m4]:
      ax.text(source['Pi'], source['h'], f'{source["Seq"]}',
              fontsize=4, color='white', ha='center', va='center')
  for source in tab[m5]:
      ax.text(source['Pi'], source['h'], f'{source["Seq"]}',
              fontsize=5, color='orange', ha='center', va='center')

  mgood = (m5 | m4 | m3) & mfinite
  plot_regression(ax, tab[mgood]["Pi"], tab[mgood]["h"],
                  logx=True, xlim=range_, debug=True, pos="bottom left")

  ax.legend()
  ax.set(
      xlim=range_, ylim=range_,
      xlabel='Planitude, $\Pi$',
      ylabel='Dimensionless shell thickness, $h$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-h0.pdf]]


*** Histograms of differences in PA
+ This is not that informative 
+ [X] Maybe include it as an inset to the R_0-R_0 graph
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-delta-PA.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  fig, axes = plt.subplots(3, 1, figsize=(3.5, 4), sharex=True)

  masks = m3, m4, m5
  colors = 'c', 'r', 'b'
  labels = '3-star', '4-star', '5-star'

  x1, x2 = -105.0, 105.0
  for ax, m, c, label in zip(axes, masks, colors, labels):
      sigma = np.nanstd(tab['delta_pa'][m])
      sns.distplot(tab['delta_pa'][m], kde=False,
                   bins=15, hist_kws={'range': [x1, x2]},
                   ax=ax, color=c,
                   label=fr'{label}' + '\n' + fr'$\sigma = {sigma:.0f}^\circ$')
      ax.axvline(0.0, c='k', ls='--', alpha=0.4)
      ax.legend(fontsize='x-small')
      ax.set(xlabel='', xlim=[x1, x2])
      sns.despine(ax=ax, trim=True)

  axes[-1].set(
      xlabel='PA difference: (fitted $-$ catalog), degrees',
      ylabel='Number of sources',
  )
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-delta-PA.pdf]]

*** AB testing of various sub-sets

**** H II region versus isolated
+ So this shows the various 'Env' types:
  + I :: /Isolated/ in purple filled contours
  + FB,FH :: /Facing bright rim/ or /Facing H II region/ as solid orange contours
  + H :: Inside /H II region/ as dashed green contours
+ Result is that there is very little difference

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-environment.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]


  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  misolated = tab['Env'] == 'I'
  mfacing = (tab['Env'] == 'FH') | (tab['Env'] == 'FB')
  mhii = tab['Env'] == 'H'

  masks = misolated & mgood, mfacing & mgood, mhii & mgood
  shades = True, False, False
  alphas = 0.8, 0.8, 0.8
  cmaps = 'Purples', 'Oranges_d', 'Greens_d'
  gammas = 0.5, 0.5, 0.5
  lss = None, 'solid', 'dashed'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.06, 0.04),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)


  masks5 = misolated & m5, mfacing & m5, mhii & m5
  colors = 'purple', 'orange', 'g'
  alphas = 0.8, 0.8, 0.8
  labels = 'Isolated', 'Facing', 'H II region'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nEnvironment')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.06
  subwin_x0 = 0.2
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02



  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_i_Rc = fig.add_axes((subwin_x0,
                              subwin_y0 + 2*(subwin_h + subwin_ymargin),
                              subwin_w, subwin_h))
      ax_f_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_h_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_i_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + 2*(subwin_h + subwin_ymargin),
                               subwin_w, subwin_h))
      ax_f_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_h_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      yq0, dyq = 0.15, 0.05
      for m, c, axx in zip(masks, colors, [ax_i_Rc, ax_f_Rc, ax_h_Rc]):
          sns.distplot(tab['Rc'][m], bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S and A-D statistics
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
      ax_h_Rc.set(xlabel=r'$\Pi$')
      for axx in ax_i_Rc, ax_f_Rc:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 

      for m, c, axx in zip(masks, colors, [ax_i_R90, ax_f_R90, ax_h_R90]):
          sns.distplot(tab['R90'][m], bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m.data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
      ax_h_R90.set(xlabel=r'$\Lambda$')
      for axx in ax_i_R90, ax_f_R90:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 

      for axx in ax_i_Rc, ax_f_Rc, ax_h_Rc, ax_i_R90, ax_f_R90, ax_h_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  #        sns.despine(ax=axx)


  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-environment.pdf]]


+ Do the same, but putting the FH sub-sample with the H, not the FB

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-alt-environment.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  misolated = tab['Env'] == 'I'
  mfacing = tab['Env'] == 'FB'
  mhii = (tab['Env'] == 'FH') | (tab['Env'] == 'H')

  masks = misolated & mgood, mfacing & mgood, mhii & mgood
  shades = True, False, False
  alphas = 0.8, 0.8, 0.8
  cmaps = 'Purples', 'Oranges_d', 'Greens_d'
  gammas = 0.5, 0.5, 0.5
  lss = None, 'solid', 'dashed'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.25, 0.15),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)


  masks5 = misolated & m5, mfacing & m5, mhii & m5
  colors = 'purple', 'orange', 'g'
  alphas = 0.8, 0.8, 0.8
  labels = 'Isolated', 'Facing', 'H II region'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nEnvironment')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.06
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_i_Rc = fig.add_axes((subwin_x0,
                              subwin_y0 + 2*(subwin_h + subwin_ymargin),
                              subwin_w, subwin_h))
      ax_f_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_h_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_i_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + 2*(subwin_h + subwin_ymargin),
                               subwin_w, subwin_h))
      ax_f_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_h_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      yq0, dyq = 0.15, 0.05
      for m, c, axx in zip(masks, colors, [ax_i_Rc, ax_f_Rc, ax_h_Rc]):
          sns.distplot(tab['Rc'][m], bins=10, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S and A-D statistics
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_h_Rc.set(xlabel=r'$R_c/R_0$')
      for axx in ax_i_Rc, ax_f_Rc:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 

      for m, c, axx in zip(masks, colors, [ax_i_R90, ax_f_R90, ax_h_R90]):
          sns.distplot(tab['R90'][m], bins=10, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 7), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]], midrank=False)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_h_R90.set(xlabel=r'$R_{90}/R_0$')
      for axx in ax_i_R90, ax_f_R90:
          axx.set(xlabel='')
          axx.tick_params(labelbottom='off') 


  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-alt-environment.pdf]]


**** Single versus multiple candidates for central source
+ This is the "Unc" column in the table
+ The idea is the ones with "C" have an aditional uncertainty in R_0, which could move points along diagonal lines through the origin
  + Actually not quite that, since R90 would be affected too
+ *Results:* There is no difference between the two samples at all
  + This implies that errors in R_0 due to uncertainty in identifying the stellar source are not important.
+ [X] Add marginal distribution histograms
#+BEGIN_SRC python :return figfile :results file
  import sys
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-candidates.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  mmultiple = tab['Unc'] == 'C'
  msingle = ~mmultiple

  masks = mmultiple & mgood, msingle & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Greens', 'Oranges_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'
 
  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = mmultiple & m5, msingle & m5
  colors = 'g', 'orange'
  alphas = 0.8, 0.8
  labels = 'Multiple', 'Single'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Source\nCandidates')


  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_m_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_s_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_m_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_s_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_m_Rc, ax_s_Rc]):
          sns.distplot(tab['Rc'][m], bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]], midrank=False)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
      ax_s_Rc.set(xlabel=r'$\Pi$')
      ax_m_Rc.set(xlabel='_nolabel_')
      ax_m_Rc.tick_params(labelbottom='off') 

      for m, c, axx in zip(masks, colors, [ax_m_R90, ax_s_R90]):
          sns.distplot(tab['R90'][m], bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m.data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]], midrank=False)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
      ax_s_R90.set(xlabel=r'$\Lambda$')
      ax_m_R90.set(xlabel='_nolabel_')
      ax_m_R90.tick_params(labelbottom='off') 

      for axx in ax_m_Rc, ax_s_Rc, ax_m_R90, ax_s_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-candidates.pdf]]

**** With or without 8 micron emission
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from astropy.table import Table
  from scipy.stats import ks_2samp, anderson_ksamp
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-8micron.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  myes = tab['8um'] == 'Y'
  mno = tab['8um'] == 'N'

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Oranges', 'Greens_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'orange', 'g'
  alphas = 0.8, 0.8
  labels = 'Yes', 'No'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='8 micron\nEmission?')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.01


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel=None)
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel=None)
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-8micron.pdf]]

**** Correlation with extinction
+ This seems to be the only case, where there might be something there
  + The distribution of R_c is slightly broader for the low-extinction sub-sample
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-extinction.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  Ak_median = np.nanmedian(tab['Ak'][mgood])

  myes = tab['Ak'] >= Ak_median
  mno = tab['Ak'] < Ak_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr'$A_K > {Ak_median:.1f}$', fr'$A_K < {Ak_median:.1f}$'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Extinction')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-extinction.pdf]]


**** Correlation with R_0
+ Finally, a highly significant correlation!
+ Larger sources tend to have a higher Rc/R0 (with p=0.005) and (especially) a higher R90/R0 (with p=0.0001)
+ We need to bear in mind that this might possibly be an observational artifact
  + Since the smaller arcs tend to have lower star ratings
  + But I don't think this is the (whole) answer
+ More convincing is the fact that both R0 and Rc/R0 and R90/R0 tend to increase with inclination
  + At least this is true for hyperbolic-type shapes
+ Also worth noting that the observed effect is opposite to what would be expected due to errors in determining R_0
  + In that case you would have larger R_0 producing smaller ratios (and vice versa)
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, mannwhitneyu
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  def rank_biserial(a, b):
      U = mannwhitneyu(a, b, alternative='two-sided')
      rb = 1.0 - 2*U.statistic/(len(a)*len(b))
      return rb, U.pvalue

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-R0.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab[R0var][mgood])

  myes = tab[R0var] >= R0_median
  mno = tab[R0var] < R0_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'c', 'r'
  alphas = 0.8, 0.8
  labels = fr"$R_0 > {R0_median:.1f}''$", fr"$R_0 < {R0_median:.1f}''$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nangular size')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              s = fr'K-S $p = {pKS:.4f}$'
              rb, pMW = rank_biserial(tab['Rc'][m], tab['Rc'][masks[0]])
              s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
            
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m.data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              s = fr'K-S $p = {pKS:.4f}$'
              rb, pMW = rank_biserial(tab['R90'][m], tab['R90'][masks[0]])
  #            s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 
      for axx in ax_y_Rc, ax_n_Rc, ax_y_R90, ax_n_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-R0.pdf]]


***** DONE Do the same, but only for 4-star sources
CLOSED: [2017-03-20 Mon 14:01]
+ This gives nothing significant, so best to forget it
+ And the sign of the effect is opposite to that with the full sample!
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-R0-4star.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m4

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.3],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'c', 'r'
  alphas = 0.8, 0.8
  labels = fr"$R_0 > {R0_median:.1f}''$", fr"$R_0 < {R0_median:.1f}''$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Bow shock\nangular size')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)



#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-R0-4star.pdf]]
***** Look directly at joint distributions of R_0 and the radial ratios
+ These turn out not to be very illuminating
+ The previous graphs are much better
+ [2017-04-06 Thu] But now repurposed to show the change in dispersion of R90 with R0 

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr, linregress
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns
  import statsmodels.api as sm

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, (ax, axr, axa) = plt.subplots(3, 1, sharex=True, figsize=(6, 9))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  cmap = 'Reds'
  gamma = 0.5
  # sns.kdeplot(np.log10(tab[R0var][mgood].data), tab['R90'][mgood].data,
  #             cmap=cmap, n_levels=10, #bw=0.04,
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  R0_median = np.nanmedian(tab[R0var][mgood])
  mbig = tab[R0var] > R0_median
  msmall = ~mbig

  xvar = np.array(np.log10(tab[R0var].data))
  yvar = np.array(tab['R90'].data)

  # Linear regression: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(np.log10(tab[R0var][mgood].data), tab['R90'][mgood].data)
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  # ax.text(0.95, -0.05, s,
  #         fontsize='x-small', color='b',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='right', va='bottom', transform=ax.transAxes)
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  ax.annotate(s=s, 
              xy=(xgrid[-10], a*xgrid[-10] + b),
              xytext=(0.95, -0.05), textcoords='axes fraction',
              arrowprops={'arrowstyle': '-|>', 'color': 'b'},
              fontsize='x-small', color='b',
              bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
              ha='right', va='bottom')
  ax.fill_between(xgrid,
                  a*x0 + (a+da)*(xgrid - x0) + b,
                  a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  ax.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, lowess=True, ax=ax)
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, truncate=True, robust=True,n_boot=100, color='m', ax=ax)



  # Do residuals
  residuals = tab['R90'].data - a*np.log10(tab[R0var].data) - b
  yvar = np.array(np.abs(residuals))
  # sns.kdeplot(np.log10(tab[R0var][mgood].data), yvar[mgood],
  #             cmap=cmap, n_levels=10, #bw=0.04,
  #             shade=True, shade_lowest=False, ax=axr, alpha=0.8)

  # Linear regression on the residuals: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(xvar[mgood], yvar[mgood])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  # axr.text(0.02, 1.05, s,
  #          fontsize='x-small', color='b',
  #          bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #          ha='left', va='top', transform=axr.transAxes)
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  axr.annotate(s=s, 
           xy=(xgrid[7], a*xgrid[7] + b),
           xytext=(0.02, 1.05), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'b'},
           fontsize='x-small', color='b',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axr.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  axr.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')

  lowess = sm.nonparametric.lowess(yvar[mgood], xvar[mgood], frac=0.8)
  axr.plot(lowess[:, 0], lowess[:, 1], lw=4, ls='--', alpha=0.7, color='g')
  s = 'LOWESS regression'
  axr.annotate(
      s=s, xy=(lowess[223,0], lowess[223,1]),
      xycoords='data', color='g',
      xytext=(1.6, -0.1), textcoords='data', fontsize='x-small',
      arrowprops={'arrowstyle': '-|>', 'color': 'g'},
      ha='center', va='center')

  # Based on the LOWESS result, redo the linear regression for log10(R0) < 1.4
  mfit = mgood & (xvar <= 1.4)
  a, b, r, p, da = linregress(xvar[mfit], yvar[mfit])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  xgrid = np.linspace(np.nanmin(xvar[mgood]), 1.4)
  x0 = np.nanmean(np.log10(tab[R0var][mfit].data))
  axr.annotate(s=s, 
           xy=(xgrid[4], a*xgrid[4] + b),
           xytext=(0.05, 0.05), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'r'},
           fontsize='x-small', color='r',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axr.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.2, color='r')
  axr.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':', color='r')



  # sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False,
  #             line_kws=dict(color='orange', alpha=0.5, ls='--', lw=4),
  #             lowess=True, ax=axr)
  #sns.regplot(x=xvar[mgood], y=yvar[mgood], scatter=False, truncate=True, robust=True, n_boot=100, color='m', ax=axr)

  # Do the asymmetry in R90
  yvar2 = np.array(tab['dR90'].data)
  # Linear regression on the residuals: y = a x + b
  # This does the Pearson r at the same time
  a, b, r, p, da = linregress(xvar[mgood], yvar2[mgood])
  s = 'Linear regression: $y = m x + c$'
  s += '\n' + f'$m = {a:.2f} \pm {da:.2f}$, $c = {b:.2f}$'
  s += '\n' + f'Correlation coefficient: $r = {r:.2f}$'
  if p > 0.001:
      s += '\n' + f'$p = {p:.4f}$'
  else:
      pexp = np.floor(np.log10(p))
      s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
  xgrid = np.linspace(np.nanmin(xvar[mgood]), np.nanmax(xvar[mgood]))
  x0 = np.nanmean(np.log10(tab[R0var][mgood].data))
  axa.annotate(s=s, 
           xy=(xgrid[4], a*xgrid[4] + b),
           xytext=(0.05, 0.95), textcoords='axes fraction',
           arrowprops={'arrowstyle': '-|>', 'color': 'b'},
           fontsize='x-small', color='b',
           bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
           ha='left', va='top')
  axa.fill_between(xgrid,
                   a*x0 + (a+da)*(xgrid - x0) + b,
                   a*x0 + (a-da)*(xgrid - x0) + b, alpha=0.4)
  axa.plot(xgrid, a*x0 + a*(xgrid - x0) + b, lw=2, ls=':')

  # sns.regplot(x=xvar[mgood], y=yvar2[mgood], scatter=False,
  #             line_kws=dict(color='g', alpha=0.5, ls='--', lw=2),
  #             lowess=True, ax=axa)



  # AD, levelsAD, pAD = anderson_ksamp(
  #     [tab['R90'][mgood & msmall], tab['R90'][mgood & mbig]],
  #     midrank=False)
  # ax.text(0.5, 0.9, fr'A-D $p = {pAD:.4f}$',
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='center', va='top', transform=ax.transAxes)

  # q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][mgood & msmall],
  #                                            [10, 25, 50, 75, 90])
  # s = f'R0 < {R0_median:.2f}'
  # s += '\n' + f'# of sources: {(mgood & msmall).sum()}'
  # s += '\n' + f'Median: {q50:.2f}'
  # s += '\n' + f'Quartiles: {q25:.2f}, {q75:.2f}'
  # s += '\n' + f'Deciles: {q10:.2f}, {q90:.2f}'
  # ax.text(0.1, 0.9, s,
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='left', va='top', transform=ax.transAxes)

  # q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][mgood & mbig],
  #                                            [10, 25, 50, 75, 90])
  # s = f'R0 > {R0_median:.2f}'
  # s += '\n' + f'# of sources: {(mgood & mbig).sum()}'
  # s += '\n' + f'Median: {q50:.2f}'
  # s += '\n' + f'Quartiles: {q25:.2f}, {q75:.2f}'
  # s += '\n' + f'Deciles: {q10:.2f}, {q90:.2f}'
  # ax.text(0.9, 0.9, s,
  #     fontsize='x-small',
  #     bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
  #     ha='right', va='top', transform=ax.transAxes)



  masks = m3, m4, m5
  alphas = 0.3, 0.4, 0.5
  stars = '3', '4', '5'
  colors = 'c', 'c', 'c'
  sizes = 5, 7, 8

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.plot(np.log10(tab[R0var][m].data), tab['R90'][m].data,  'o',
              ms=ms, lw=1, alpha=alpha, c=c, label=label)
      axr.plot(np.log10(tab[R0var][m].data), yvar[m],  'o',
               ms=ms, lw=1, alpha=alpha, c='m', label=label)
      axa.plot(np.log10(tab[R0var][m].data), yvar2[m],  'o',
               ms=ms, lw=1, alpha=alpha, c='r', label=label)
  # ax.axvline(np.log10(np.nanmedian(tab[R0var][mgood])), color='k')




  ax.set(
      xlim=[0.65, 1.95], ylim=[0.55, 2.9],
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$')
  axr.set(
      ylim=[-0.08, 0.78],
      ylabel=r'Absolute residual from $R_{90}/R_0$ regression')
  xticks_linear = [5.0, 10.0, 20.0, 40.0, 80.0]
  axa.set(
      # ylim=[-0.08, 0.78],
      xticks = [np.log10(_) for _ in xticks_linear],
      xticklabels = [f'{int(_)}' for _ in xticks_linear],
      # xlabel=r'Axial radius: $\log_{10}\, R_0$',
      xlabel=r"Axial radius: $R_0$, $''$ (log scale)",
      ylabel=r'$|R_{90+} - R_{90-}| / R_{90}$')


  sns.despine(trim=True)
  sns.despine(ax=ax, bottom=True)
  sns.despine(ax=axr, bottom=True)
  fig.tight_layout()
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf]]

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-ratio-versus-R0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3
  
  cmap = 'Greens'
  gamma = 0.5
  sns.kdeplot(np.log10(tab['R0_fit'][mgood].data), tab['Rc'][mgood].data,
              cmap=cmap, n_levels=30,
              shade=True, shade_lowest=False, ax=ax, alpha=0.8)

              
  masks = m3, m4, m5
  alphas = 0.2, 0.4, 0.8
  stars = '3', '4', '5'
  colors = 'c', 'r', 'b'
  sizes = 5, 7, 8

  for m, alpha, star, c, ms in zip(masks, alphas, stars, colors, sizes):
      label = f'{star}-star ($N = {m.sum()}$)'
      ax.plot(np.log10(tab['R0_fit'][m].data), tab['Rc'][m].data,  'o',
              ms=ms, lw=1, alpha=alpha, c=c, label=label)

  ax.axvline(np.log10(np.nanmedian(tab['R0_fit'][mgood])), color='k')

  ax.set(
      xlim=[0.7, 1.7], ylim=[0., 5.0],
      xlabel=r'Axial radius: $\log_{10} R_0$',
      ylabel=r'Radius of cuvature ratio: $R_{c}/R_0$',
      xscale='linear', yscale='linear')



  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-ratio-versus-R0.pdf]]


***** Try a finer 5-bin quantization of R_0 and H_0

+ [X] Also, calculate the 5-sample A-D statistic
+ [X] And add in the wing asymmetry factor |R_{90+} - R_{90-}| / R_90
  + This is about 0.2
+ [X] Try tests of heteroscedasticity
  + White's Lagrange Multiplier Test =statsmodels.stats.diagnostic.het_white()=
  + Or just do a Pearson-r on the absolute deviations
  + Finally plumped for Brown--Forsythe variant of Levene test
+ [X] Add in the observational =R90_sigma=

#+BEGIN_SRC python :results file :return figfile
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr, levene
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns

  #sns.set_style('white')
  sns.set_color_codes('dark')
  sns.set_palette('muted')


  figfile = 'mipsgal-boxplot-Rc-R90-versus-R0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'
  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']
  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )

  fig, axes = plt.subplots(5, 1, sharex=False, figsize=(4, 8))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Make some box plots by discretizing the R_0 axis
  logR0 = np.log10(tab[R0var][mgood].data)
  n = len(logR0)
  # Sort R0 into ascending bins with 30 sources per bin
  sort_order = np.argsort(logR0)
  R0_rank = np.empty_like(logR0)
  R0_rank[sort_order] = np.arange(n)
  # R0_rank = np.searchsorted(np.sort(logR0), logR0)
  R0_bins = R0_rank//46
  R0_label = np.zeros_like(R0_bins).astype('U3')
  for ibin in set(R0_bins):
      mbin = R0_bins == ibin
      R0_label[mbin] = int(10**np.nanmedian(logR0[mbin]))

  #R0_label = (2*np.round(logR0/2, 1)).astype('U3')
  R0_order = sorted(set(R0_label), key=float)

  def pformat(p):
      """Pretty-print a p-value"""
      if p > 0.01:
          return f'$p = {p:.3f}$'
      else:
          pexp = np.floor(np.log10(p))
          return rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'

  ytexts = [0.0, 0.0, -0.05, 0.0, None]
  for ax, Rshape, ytext in zip(axes, ['R90', 'Rc', 'dR90', 'R90_sigma', R0var], ytexts):
      dependent = Rshape != R0var
      sns.boxplot(x=R0_label, y=tab[Rshape][mgood], order=R0_order, ax=ax, boxprops=dict(lw=0.0), showfliers=False, whis=[5, 95], notch=dependent, bootstrap=1000)
      if dependent:
          # Anderson-Darling k-sample test over the 5 sub-samples
          subsamples = [tab[Rshape][mgood][R0_label == _] for _ in R0_order]
          AD, levelsAD, pAD = anderson_ksamp(subsamples, midrank=False)
          BF, pBF = levene(*subsamples, center='median')
          s = f'{pformat(pAD)} (AD), {pformat(pBF)} (BF)'
          ax.text(0.05, ytext, s,
                  ha='left', va='center', transform=ax.transAxes,
                  fontsize='small'
          )


  axes[0].set(ylabel='Alatude\n' + r'$\Lambda = R_{90}/R_0$',
              ylim=[0.0, None], yticks=[0, 1, 2, 3])
  axes[1].set(ylabel='Planitude\n' + r'$\Pi = R_{c}/R_0$',
              ylim=[0.0, None],  yticks=[0, 1, 2, 3])
  axes[2].set(ylabel='Asymmetry\n' + r'$|\Lambda_{+} - \Lambda_{-}|/ \Lambda$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.4, 0.6])
  axes[3].set(ylabel='Point dispersion\n' + r'$\epsilon (\Lambda)$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.4, 0.6])
  axes[4].set(ylabel='Bows size\n' + r"$R_0$, arcsec", yscale='log',
              ylim=[4.5, 58])
  axes[4].yaxis.set_major_locator(mticker.FixedLocator([5, 10, 50]))
  axes[4].yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  for iR0, R0_median in enumerate(R0_order):
      x = (iR0 + 0.5) / len(R0_order)
      axes[-1].text(x, 0.94, f'$N = {np.sum(R0_label == R0_median)}$',
                    ha='center', va='center', transform=ax.transAxes,
                    fontsize='small'
      )
  axes[-1].set(xlabel=r"Sub-sample median $R_0$, arcsec", )
  sns.despine(trim=True)
  for ax in axes[:-1]:
      sns.despine(ax=ax, bottom=True)
      ax.set(xticks=[])
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-boxplot-Rc-R90-versus-R0.pdf]]

Try the same with H_0

#+BEGIN_SRC python :results file :return figfile
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr, levene
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-boxplot-Rc-R90-versus-H0.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])
  tab['dR90'] = np.abs(tab['R90p'] - tab['R90n'])/tab['R90']
  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  fig, axes = plt.subplots(5, 1, sharex=True, figsize=(3, 8))

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Make some box plots by discretizing the R_0 axis
  H0 = tab['Hmag'][mgood].data
  n = len(H0)
  # Sort R0 into ascending bins with 30 sources per bin
  sort_order = np.argsort(H0)
  H0_rank = np.empty_like(H0)
  H0_rank[sort_order] = np.arange(n)
  # R0_rank = np.searchsorted(np.sort(logR0), logR0)
  H0_bins = (n - 1 - H0_rank)//46
  H0_label = np.zeros_like(H0_bins).astype('U4')
  for ibin in set(H0_bins):
      mbin = H0_bins == ibin
      H0_label[mbin] = np.nanmedian(H0[mbin])

  #R0_label = (2*np.round(logR0/2, 1)).astype('U3')
  H0_order = sorted(set(H0_label), key=float)[::-1]

  def pformat(p):
      """Pretty-print a p-value"""
      if p > 0.01:
          return f'$p = {p:.3f}$'
      else:
          pexp = np.floor(np.log10(p))
          return rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'

  for ax, Rshape in zip(axes, ['R90', 'Rc', 'dR90', 'R90_sigma', 'Hmag']):
      sns.boxplot(x=H0_label, y=tab[Rshape][mgood], order=H0_order, ax=ax)
      if Rshape != 'Hmag':
          subsamples = [tab[Rshape][mgood][H0_label == _] for _ in H0_order]
          AD, levelsAD, pAD = anderson_ksamp(subsamples, midrank=False)
          BF, pBF = levene(*subsamples, center='median')
          s = f'{pformat(pAD)} (AD), {pformat(pBF)} (BF)'
          ax.text(0.05, -0.04, s,
                  ha='left', va='top', transform=ax.transAxes,
                  fontsize='x-small'
          )
  axes[0].set(ylabel=r'$R_{90} / R_{0}$', ylim=[0.0, None])
  axes[1].set(ylabel=r'$R_{c} / R_{0}$', ylim=[0.0, 5.0])
  axes[2].set(ylabel=r'$|R_{90+} - R_{90-}|/ R_{90}$', ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[3].set(ylabel=r'$\epsilon (R_{90}) / R_{0}$',
              ylim=[-0.01, None], yticks=[0, 0.2, 0.8])
  axes[4].set(ylabel=r'$H_0$, mag', ylim=[4.5, 13.9], yticks=[6, 9, 12])
  for iH0, H0_median in enumerate(H0_order):
      x = (iH0 + 0.5) / len(H0_order)
      axes[-1].text(x, 1.0, f'$N = {np.sum(H0_label == H0_median)}$',
                    ha='center', va='top', transform=ax.transAxes,
                    fontsize='xx-small'
      )
  axes[-1].set(xlabel=r"Sub-sample median $H_0$, mag", )
  sns.despine(trim=True)
  for ax in axes[:-1]:
      sns.despine(ax=ax, bottom=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-boxplot-Rc-R90-versus-H0.pdf]]






**** New correlation with thickness
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, mannwhitneyu
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  def rank_biserial(a, b):
      U = mannwhitneyu(a, b, alternative='two-sided')
      rb = 1.0 - 2*U.statistic/(len(a)*len(b))
      return rb, U.pvalue

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-thick.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Dimensionless thickness 
  Thick = tab["H_g"]/tab[R0var]

  Thick_median = np.nanmedian(Thick[mgood])
  # Force a more logical cut-off
  Thick_median = 1.0


  myes = Thick >= Thick_median
  mno = Thick < Thick_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Blues', 'Reds_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'c', 'r'
  alphas = 0.8, 0.8
  labels = fr"$h_0 > {Thick_median:.1f}$", fr"$h_0 < {Thick_median:.1f}$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Relative\nshell thickness')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
                                                 midrank=False)
              s = fr'K-S $p = {pKS:.4f}$'
              rb, pMW = rank_biserial(tab['Rc'][m], tab['Rc'][masks[0]])
              s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)

              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m.data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
                                                 midrank=False)
              s = fr'K-S $p = {pKS:.4f}$'
              rb, pMW = rank_biserial(tab['R90'][m], tab['R90'][masks[0]])
  #            s += '\n' + fr'$r_b = {rb:.2f}$'
              axx.text(1.0, 0.9, s,
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 
      for axx in ax_y_Rc, ax_n_Rc, ax_y_R90, ax_n_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-thick.pdf]]

**** DONE Stellar magnitude
CLOSED: [2017-03-20 Mon 11:31]
+ Another marginal correlation:
  + Brighter sources tend to have larger Rc and R90
  + But we only have p=0.1 or so, so doesn't meet the formal significance requirement 
+ [X] Need to re-do this to use the extinction-corrected distances
  + It will be interesting to see if the correlation is better or worse that the one with R_0
  + If it is worse, then it is indirect evidence that it is the non-distance component of the R_0 variation that is responsible for the correlation with shape
+ So it turns out that the correlation is now significant for R_90 although only marginally so for R_c
  + This would perhaps be consistent with it being intrinsic source luminosity that is influencing the shape
    + More luminous sources have more open wings
  + Alternatively, it could be a distance effect
  + It would argue against it being inclination that is causing the R_0-shape correlation
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-Mag.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]
  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  MH_median = np.nanmedian(tab['Hmag'][mgood])

  myes = tab['Hmag'] <= MH_median
  mno = tab['Hmag'] > MH_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Oranges', 'Greens_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'g'
  alphas = 0.8, 0.8
  labels = (fr"$H < {MH_median:.1f}$",
            fr"$H > {MH_median:.1f}$")

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Source\nMagnitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.2
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {np.sum(m.data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = kuiper_two(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'K-S $p = {pKS:.4f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 

      for axx in ax_n_Rc, ax_y_Rc, ax_n_R90, ax_y_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-Mag.pdf]]


**** DONE Galactic longitude and latitude
CLOSED: [2017-03-20 Mon 14:22]
+ Use |b| for distance of sight line from plane
+ And cos(l) for distance of sight line from Galactic Center
+ Turns out that there are no significant correlations with either
  + Especially not with longitude
***** Correlation with log_10|b|
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-cos-glat.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  bmedian = np.nanmedian(tab['log10 |b|'][mgood])

  myes = tab['log10 |b|'] >= bmedian
  mno = tab['log10 |b|'] < bmedian

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr"$|b| > {10**bmedian:.1f}^\circ$", fr"$|b| < {10**bmedian:.1f}^\circ$"

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Galactic latitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
						 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-cos-glat.pdf]]

***** Correlation with cos(l)
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-cos-glon.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.6, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 3.0], [0.0, 3.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # cosl_median = np.nanmedian(tab['cos(l)'][mgood])
  cosl_median = 0.8

  myes = tab['cos(l)'] >= cosl_median
  mno = tab['cos(l)'] < cosl_median

  masks = myes & mgood, mno & mgood
  shades = True, False
  alphas = 0.8, 0.8
  cmaps = 'Reds', 'Blues_d'
  gammas = 0.5, 0.5
  lss = None, 'solid'

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.4, 1.6],
                  bw=(0.18, 0.12),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

  masks5 = myes & m5, mno & m5
  colors = 'r', 'c'
  alphas = 0.8, 0.8
  labels = fr'$\cos(\ell) > {cosl_median:.1f}$', fr'$\cos(\ell) < {cosl_median:.1f}$'

  for m, alpha, c, label in zip(masks5, alphas, colors, labels):
      ax.plot(tab['Rc'][m], tab['R90'][m], 
              'o', ms=7, alpha=alpha, c=c, label=label)

  ax.legend(frameon=True, loc='upper right', title='Galactic\nlongitude')


  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=[0.0, 5.0], ylim=[0.0, 5.0],
      xlabel=r'Radius of curvature ratio: $R_c/R_0$',
      ylabel=r'Perpendicular radius ratio: $R_{90}/R_0$',
      xscale='linear', yscale='linear')


  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.09
  subwin_x0 = 0.2
  subwin_y0 = 0.65
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      for m, c, axx in zip(masks, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(tab['Rc'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['Rc'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['Rc'][m], tab['Rc'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['Rc'][m], tab['Rc'][masks[0]]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      #
      ax_n_Rc.set(xlabel=r'$R_c/R_0$')
      ax_y_Rc.set(xlabel='')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      for m, c, axx in zip(masks, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(tab['R90'][m], bins=15, hist_kws={'range': [0.0, 5.0]},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(tab['R90'][m],
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(tab['R90'][m], tab['R90'][masks[0]])
              AD, levelsAD, pAD = anderson_ksamp([tab['R90'][m], tab['R90'][masks[0]]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.2f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
          axx.set(xlim=[0.0, 5.0], xticks=[0, 1, 2, 3, 4, 5])
          sns.despine(ax=axx, trim=True, offset=None)
      ax_n_R90.set(xlabel=r'$R_{90}/R_0$')
      ax_y_R90.set(xlabel='')
      ax_y_R90.tick_params(labelbottom='off') 

  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-cos-glon.pdf]]


**** Reddening and extinction
:PROPERTIES:
:ID:       12C6A97A-CA32-4404-9E51-58B7E84401CF
:END:
+ The reddening is simply calculated from the (H - [4.5]) color excess
+ This follows Majewski et al (2011)
+ It is very simple because most stars are in the Rayleigh--Jeans limit by the H-band, so that there is little spread in the intrinsic (H - [4.5])_0 color
+ In Majewski, they assume (H - [4.5])_0 = 0.08 for all stars
  + But we could maybe improve on that by using a value more tailored for OB stars
+ And use the Indebetouw (2005) reddening law
  + There you can see why (H - [4.5]) is the best color to use
    + Blueward of H (e.g., J), the intrinsic color variation of the stars is a lot greater
    + Redward of 4.5 microns, you start to run into variations between different dust models (and scatter between different lines of sight too), and then the silicate absorption feature at 10 microns comes in as well
  + So Inbetouw give results in terms of A_{[\lambda]} /A_K (averages over 3 regions)
    | Band  |     \lambda | A_{[\lambda]} /A_K    |
    |-------+-------+-------------|
    | J     | 1.240 | 2.50 \pm 0.15 |
    | H     | 1.664 | 1.55 \pm 0.08 |
    | K     | 2.164 | 1.00        |
    | [3.6] | 3.545 | 0.56 \pm 0.06 |
    | [4.5] | 4.442 | 0.43 \pm 0.08 |
    | [5.8] | 5.675 | 0.43 \pm 0.10 |
    | [8.0] | 7.760 | 0.43 \pm 0.10 |
  + And they don't determine A_V/A_K themselves, but that varies from 8.8 (R_V = 3.3) to 7.5 (R_v = 5)
+ This leads Majewski to the formula:
  + A_K = 0.918 (H - [4.5] - 0.08)
  + So the 0.08 is (H - [4.5])_0
  + And the 0.918 factor should be
    + 1/(A_H/A_K - A_{[4.5]}/A_K)
    + = 1/(1.55 \pm 0.08 - 0.43 \pm 0.08)
    + = 0.893 +/- 0.090
    + Which is not quite the same, but well within the uncertainties, which are of order 10%
  + Perhaps the difference is due to them using K_s instead of K
  + And (H - [4.5])_0 varies between about -0.2 for the earliest O stars, up to about -0.05 for the B stars.  By definition, it is 0.0 for A0 stars
  + So, taking -0.1 would be more realistic than +0.08, which will shift the zero point slightly
+ [X] So I can recalculate A_K using the formula:
  + A_K = (0.893 \pm 0.090) (H - [4.5] + 0.1)
+ [X] And then find the corrected stellar magnitude as:
  + H_0 = H - (1.55 \pm 0.08) A_K

**** DONE Multifactor pair plot of the non-shape parameters
CLOSED: [2017-03-20 Mon 10:48]
:PROPERTIES:
:ID:       5493D03D-24D5-479B-8C7B-0BE2FCA576EF
:END:
+ Use =seaborn.pairplot()= to make a grid of regression plots
+ Or =seaborn.PairGrid()= for finer control
+ Note that the sample is only our fitted bow shocks, so doesn't include the non-Spitzer sources
  + This means that it is all sources in the inner Galaxy
+ Note that Kobulnicky's Fig 8 and Fig 9 are reproduced (approximately) in the top-left and top-right corners of the grid
+ We give extinction-corrected magnitudes H_0
  + We re-derived the extinction using a slightly bluer intrinsic color, more suitable for OB stars (see [[id:12C6A97A-CA32-4404-9E51-58B7E84401CF][Reddening and extinction]])
    + This makes alost no difference, except it eliminates some of the apparent small negative extinctions
    + Main uncertainty is due to variations in the IR extinction curve, which give approx 10% uncertainty in A_K
+ /Things that we find:/
  1. Clearest correlation is between size and H_0, which is probably due to distance of the source
     - This has r = -0.43
       + Implying that about 20% of the variance in in size is "explained" by variation in H_0
     - H band magnitudes of Trapezium, etc
       | Star     | Sp Type |     H |  A_V |    D |    M_H |
       |----------+---------+-------+-----+------+-------|
       | \theta^1 C     | O7 V    |  4.63 |   1 |  400 | -3.58 |
       | \theta^1 B     | B3 V    |   6.3 |   1 |  400 | -1.91 |
       | \theta^1 A     | B0 V    |   5.8 |   1 |  400 | -2.41 |
       | \theta^1 D     | B1.5 V  |  5.89 |   1 |  400 | -2.32 |
       | \theta^2 A     | O9.5 IV |  4.97 | 0.2 |  400 | -3.08 |
       | \theta^2 B     | B2-B5 V |  6.27 | 0.2 |  400 | -1.78 |
       |----------+---------+-------+-----+------+-------|
       | HD 93129 | O2 I    |  6.14 |   1 | 2300 | -5.87 |
       | \zeta Pup    | O4 I    |   2.9 |   0 |  330 | -4.69 |
       | \lambda Cep    | O6.5 I  | 4.618 |   0 |  600 | -4.27 |
       | UW CMa   | O7 I    |  5.19 |   0 |  580 | -3.63 |
       | 19 Cep   | O9 Ib   |  4.92 |   0 | 1200 | -5.48 |
       | \alpha Cam    | O9 Ia   |  4.38 |   0 | 1900 | -7.01 |
       | \zeta Ori    | O9.7 I  |  2.35 |   0 |  225 | -4.41 |
       | Rigel    | B8 I    |  0.20 |   0 |  260 | -6.87 |
       #+TBLFM: $6=$3 - 0.2 $4 - (5 log10($5) - 5) ;f2
     - Absolute magnitudes are calculated assuming A_H = 0.2 A_V and D = 400 pc
       + Distance modulus: 5 log10(D) - 5 = 8.01
     - So it seems -4 (early O) to -1.5 (mid-B) is a reasonable spread for the H-band absolute magnitude for MS stars
       + So that is exactly a factor of 10 in H-band luminosity, which seems reasonable
         + We show below that F_H \sim F_bol^0.5, so this is a factor of 100 in total luminosity
       + Say -2 on average (around B2)
     - Supergiants like \zeta Pup are brighter, reaching -4.69, or -6.87 for Rigel
       - In general, supergiants will have higher L_H at lower T_eff, since the bolometric luminosities are roughly constant
       - But the winds will either be roughly constant, or 
     - The peak in the H_0 histogram is around 9.5
       + So this implies distance modulus of 11.5, or D = 10**((11.5 + 5)/5) = 2 kpc, which is totally reasonable
     - The faintest sources have H_0 \approx 12, or distance modulus of 14
       + Implying D = D = 10**((14 + 5)/5) = 6.3 kpc
       + Note that there is a little clump at H_0 \approx 12 at cos(l) = 1, which may correspond to the Galactic center population!
         + Those sources may be slightly brighter than B2 stars
         + If we used -2.5 instead (B0), then we would get 8 kpc
     - Brightest sources have H_0 \approx 5, or distance modulus of 8
       + Implying D = 100 pc, which again is reasonable
     - Total spread due to luminosity spectral type can only be 2.5 mag or so
       + Say from 10,000 to 100,000 times Lsun
       + Total spread in distance can be 30 or so, which gives spread of 1000 in observed flux, or 7.5 in apparent magnitude
       + So conclusion is that the majority of the variation in H_0 should be due to variation in distance
     - Now consider effect on angular size
       + If all bow shocks have same physical size, then an increase by a factor of 10 in R_0 is a decrease by a factor of 10 in distance, which is a decrease of 5 in magnitude
       + This is exactly what is seen!
       + Do this with the constants, assume physical size of 0.1pc
         + R0 = (0.1/D) 206265
           + => D = 20626.5 / R0
         + H0 = MH0 + 5 log10(D) - 5
           + = (MH0 - 5) - 5 log10(R0) + 5 log10(20626.5)
           + = 16.57 + MH0 - 5 log10(R0)
     - But we get the same from variations in intrinsic luminosity
       + Because R_0 \propto \beta{}^{1/2}
       + And \beta ~ L
         + Assuming that
           1. Environment Momentum flux is constant on average
           2. Stellar wind momentum flux is constant fraction of radiative luminosity
     - But it seems that a better estimate is that "modified wind momentum" (Mdot V R^{1/2}) is proportional to L^1.88 approx (although this is only really valid above 200,000 Lsun - see Puls 1996)
       + So we need the R(L) relationship
       + Use Eker et al (2015)
         + L \sim M^2.726 for 7 < M < 32 in solar units
         + R \sim M^0.5 (Fig 7a) => R ~ L^0.18
           + Giving Mdot V ~ L^1.8
         + => T ~ M^a where a = (2.726 - 2 0.5) / 4  = 0.4315
           + Which is consistent with Fig 7b
           + And which means T \sim L^0.158
     - So if we take \beta ~ L^1.88 from above
       + Then bow shock R_0 ~ L^0.94
       + But how does M_H depend on L?
         + We are approx in the RJ tail, so L_\lambda ~ T R^2 whereas L_bol ~ T^4 R^2
         + Therefore F_H ~ L / T_eff^3
         + Taking T \sim L^0.158 from above
         + => F_H ~ L^0.526 or L ~ F_H^1.90
         + This explains why there is only a one order of magnitude in H-band luminosity over the OB stars (although for supergiants, this would no longer hold)
     - We plot the lines for a B2 star at a range of distances from 300 to 8000 pc
       + And that reproduces the linear trend very well
     - We also plot the line for a variety of stars at 2 kpc
       + This overpredicts the variation in R_0, possibly because in reality brighter stars are interacting with higher-momentum environments, which would stop R_0 from increasing so much
       + Explicitly calculate the slope of the line:
         + R_0 = (0.1 / 2000) 206265 (L_H / L_0 )^{3.4/2} = 10.31 (L_H / L_0 )^{1.7}
         + => log10(R_0) = 1.01 + 1.7 log10 (L_H / L_0)
         + => log10 (L_H / L_0) = 0.59 log10(R_0) - 0.59
         + M_H - M_0 = -2.5 log10 (L_H / L_0)
         + H_0 = M_H + (5 log10(2000) - 5) = M_H + 11.51
         + H_0 = M_0 + 11.51 - 2.5 log10 (L_H / L_0)
         + H_0 = 11.51 + M_0  - 1.49 log10(R_0) - 1.49
         + M_0 = -2, so
         + H_0 = 8.02 - 1.49 log10(R_0)
       + And it cannot explain all the variation in H_0, since for MS stars L_H ~ L^0.5
         + Although supergiants are not included, and they would go to bigger L_H values
         + From the above table, they have M_H in range -4 to -7, so up to 100 times brighter than the B2V stars
         + But they are very rare, so probably don't contribute greatly
     - [X] Maybe calculate R_0 assuming radiation pressure on dust grain
       - Calculate distance of closest approach for impact parameter b=0
       - Equation of motion:
         1. m a = \sigma (L/c) / (4 \pi r^2) = m v dv / dr
         2. \int_v0^0 v dv = A \int_\infty^r0 r^-2 dr
            - where A = \sigma L / 4\pi m c
         3. -v^2/2  = -A (1/r_0 - 0)
         4. r_0 = 2 A / v^2 = 2 \sigma L / 4\pi m v^2 c
       - Also we can write for grains of size a and density \rho_s:
         - m = 4\pi/3 \rho_s a^3
         - \sigma = Q \pi a^2
         - => \sigma/m = 3/4 Q / \rho_s a
       - E.g., with
         - \rho_s = 3 g/cm^3
         - a = 0.1 \micro{}m
         - L = 1e4 Lsun
         - v = 50 km/s
         - Q = 1
       - We get r_0 = 0.066 pc (L_4 / a_0.1 v_50^2)
         - This is remarkably close to the 0.1 pc that we had assumed
         - And note that the dependence on L is almost identical to the stellar wind case (which was also roughly linear)
         - But, the ambient density does not enter in this case
       - All this is assuming that the dust is uncoupled from the gas
         - If they are coupled, then each grain has to drag around 100 times its own mass in gas
         - Which will reduce the stagnation radius by a factor of 100
         - So it probably wouldn't be competitive with the hydrodynamic stagnaton radius
       - [2017-09-29 Fri] Apropos of last, we can estimate whether the dust is coupled to the gas or not. Compare:
         - Crossing time: r_0 / v
         - Drag time: m v / f_coll
           - Collisional force: f_coll = \sigma_coll \rho v^2 
           - => t_drag = m / \sigma_coll \rho v
           - First, assume solid body collisions (neutral grain):
             - \sigma_coll = \pi a^2
             - m = 4\pi/3 \rho_s a^3
             - => t_drag = 4/3 (a/v) (\rho_s/\rho)  so roughly crossing time for grain (small!) multiplied by grain-ISM density ratio (large!)
         - So t_drag < t_coll when 4/3 (a/v) (\rho_s/\rho) < r_0 / v
           - => 0.066 pc (L_4 / a_0.1 v_50^2) > 2.16 pc a_0.1 / n_1
           - => a_0.1^2 v_50^2 / L_4 n_1 < 0.03
         - Alternative approach is to calculate terminal drift speed (following Lamers & Cassinelli, Chapter 7)
           - Balance between radiative acceleration and drag
             * (\pi a^2) Q L / 4 \pi r^2 c = (\pi a^2) \rho w (w^2 + a_th^2)^{1/2}
           - If drift speed w is supersonic (w \gg a_th which is the case we are most interested in), then
             * w = [Q L / 4 \pi r^2 \rho c]^{1/2}
             * We take typical values as above and put r = r_0 \approx 0.1 pc
             * => w = 221 km/s L_4^0.5 n_1^-0.5 r_0.1^-1
           - So, the drift speed is pretty high, unless the density is higher than I have been assuming
         - But this is all assuming neutral gas and neutral grains.  In ionized gas, coulomb collisions increase the drag
           - The grain potential U is mainly determined by competition between photoelectric effect and electron capture
             - We need to be careful about the difference between
               1. CGS esu units (statvolt)
               2. Actual volts, where 1 statvolt = 300 V
             - Papers usually give potential in Volts, but in an equation like E_pot = e U we need to use stat Volts 
           - In H II regions, it seems that potential is typically U \approx +1 V, which is \approx 0.003 statV
             - So the parameter \phi = e U / k T is about unity.
             - This is also consistent with fact that e U = 1 eV for U = 1 V
           - The potential does depend on the ionization parameter
             - Feuerbacher et al (1973) have a good graph (Fig 7 and 8)
             - For O5 star @ 0.1 pc, they predict
               - U = +5 V for n = 1000 pcc
               - U = +1.5 V for n = 1e4 pcc
               - U = -0.5 V for n = 1e5 pcc
             - For B0 star @ 0.1 pc, they predict
               - U = +1.5 V for n = 100 pcc
               - U = -1.5 V for n = 1000 pcc
             - These are both for aluminium oxide.  They also give results for graphite, which are less positive on the whole, since photoelectric yield is lower (roughly speaking, everything shifted to 10 times lower densities)
           - Charge on the grain, Z, is related to potential by U = e Z / a, with U in statV if e is the esu value.
             - => Z = a U / e \approx 70 (U / 1 V) a_0.1
           - So, finally we get to the Coulomb multiplier for the drag
             - We can follow Spitzer book and do it in terms of slowing-down time
             - Or we can follow Draine & Salpeter (1979), who themselves seem to be following another Spitzer paper:
               - \sigma_Coulomb / \sigma_Sphere = z_i^2 \phi^2 ln(\Lambda/z_i) G_2(s) / G_0(s)
               - z_i is charge of colliding particle, which we can take as 1
               - \phi = e U / k T, which is about U in Volts (roughly unity)
               - G_2(s) \approx s / (1.32 + s^3)
               - G_0(s) \approx 1.504 (1 + 0.44 s^2)^{1/2}
               - For supersonic velocities, s \gg 1, this reduces to
                 - G_2(s) \simeq s^-2
                 - G_0(s) \simeq s
                 - => \sigma/\sigma \approx U^2 ln \Lambda / s^3
               - For subsonic velocities, s \ll 1, we have
                 - G_2(s) \approx s / 1.32
                 - G_0(s) \approx 1.504
                 - => \sigma/\sigma \approx U^2 ln \Lambda 0.5 s
               - ln \Lambda  \simeq 20 in H II regions
               - If we have v = 50 km/s, then s \approx 4
               - So \sigma/\sigma \approx 0.3 U^2, which means that there is no real boost unless U is significantly larger than 1 V
               - However, the v should be the relative velocity
       - [2017-09-30 Sat] Also consider effects of gravity
         - Dust-Eddington luminosity:
         - G M m / r^2 = \sigma L_edd / (4 \pi r^2 c)
         - L_edd = 4 \pi c G M m / \sigma
           + where m / \sigma = 4/3 \rho_s a / Q
           + L_edd / M = (16\pi/3) c G \rho_s a / Q
             + Where: G = 6.673e-8
             + \rho = 3 g / cm^3
             + a = 0.1 \mu m
             + Q \sim 1
             + => (L/M)_Edd in solar units is 1.93 (L_\odot/M_\odot) (\rho_3 a_0.1 / Q) 
             + Whereas all our stars of interest (O stars, RSG, AGB) have L/M > 1000 L_\odot/M_\odot, which means they are very super-Eddington
         - The same is true, even if we have dust coupled to gas.  Roughly, this should mean that we multiply m by about 100 to account for the gas that is dragged along
           - Which would give about 200 L_\odot/M_\odot
           - But I will also do the calculation using a standard dust opacity of 5e-22 cm^2/H
             - L / M = 4 \pi c G m_H / \sigma = 162 (L_\odot/M_\odot)
             - That is close enough
           - So the gravity can be ignored in all these cases (roughly 10% reduction in acceleration for well-coupled grains, or 0.1% reduction for uncoupled grains).
  2. Next highest correlation is A_K versus |b|, which is unsurprising: higher extinction closer to the Galactic plane
  3. Finally, there is a weak correlation of A_K with H_0, due to larger extinction at greater distances.  But the fact that it is so weak implies that the variation between different lines of sight is more important for determining A_K


#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  import json
  from scipy.stats import ks_2samp, anderson_ksamp, pearsonr
  from astropy.table import Table
  import astropy.units as u
  import astropy.coordinates as coord
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import seaborn as sns

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  sns.set_style('white')
  sns.set_color_codes('dark')

  figfile = 'mipsgal-pairplot.pdf'

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')
  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  tab['R0_fit'][tab['R0_fit'] == 0.0] = np.nan

  tab['log10 R0'] = np.log10(tab['R0_fit'])


  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  plotvars = ['log10 R0', 'log10 |b|', 'cos(l)', 'Hmag', 'Ak']
  bad_rows = np.zeros((len(tab),), dtype=bool)
  clip_values = {
      'Hmag': [4.5, 12.0],
      'Ak': [0.0, 5.0],
      'log10 R0': [0.3, 1.8],
      'log10 |b|': [-2.0, 1.3],
  }
  for pvar in plotvars:
      bad_rows = bad_rows | ~np.isfinite(np.array(tab[pvar]))
      if pvar in clip_values:
          vmin, vmax = clip_values[pvar]
          bad_rows = bad_rows | (np.array(tab[pvar]) <= vmin) | (np.array(tab[pvar]) >= vmax) 
  bad_row_indices, = np.nonzero(bad_rows)
  tab.remove_rows(bad_row_indices)

  # Make column names that print nicely on the graph
  pretty_vars = [
      r"$\log_{10} (R_0, '')$",
      r'$\log_{10} (|b|,{}^\circ)$', r'$\cos(\ell)$',
      r'$H_0$ mag', r'$A_K$']
  for pvar, ppvar in zip(plotvars, pretty_vars):
      tab[pvar].name = ppvar

  df = tab.to_pandas().fillna(0)
  g = sns.PairGrid(df, vars=pretty_vars, size=1.5)
  g = g.map_upper(plt.scatter, marker='.', alpha=0.2, color='r')
  g = g.map_lower(sns.kdeplot, cmap="Purples_d", n_levels=10)
  g = g.map_diag(plt.hist)

  # Plot the line for size of a 0.1 pc bow shock at distances from 0.3 to 8 kpc
  Dgrid = np.logspace(2.5, 3.9)*u.pc
  R_phys = 0.1*u.pc
  R0 = (R_phys/Dgrid)*u.rad.to(u.arcsec)

  # Against apparent magnitude of an M_H = -2.0 star at the same distances
  MH0 = -2.0
  H = MH0 + (5*np.log10(Dgrid/u.pc) - 5)

  ax = g.axes[0, 3]
  ax.plot(H, np.log10(R0.value), ls='--', c='k', lw=2, alpha=0.8)
  axx = g.axes[3, 0]
  axx.plot(np.log10(R0.value), H, ls='--', c='k', lw=2, alpha=0.8)

  # Now do a varying H magnitude at a fixed distance of 2 kpc
  D0 = 2000*u.pc
  MHgrid = np.linspace(-3.6, -1.5)
  Hb = MHgrid + (5*np.log10(D0/u.pc) - 5)

  # H-band luminosity with respect to M_H = -2.0 star
  LH = 10**(0.4*(MH0 - MHgrid))
  # Bolometric luminosities for MS stars
  L = LH**1.90
  # Wind momentum relative to fiducial star with fixed environment momentum
  beta = L**1.80
  # Bow shock stand-off distance with physical radius ~ sqrt(beta)
  R0b = (R_phys*np.sqrt(beta)/D0)*u.rad.to(u.arcsec)

  # Plot as yellow dotted
  ax.plot(Hb, np.log10(R0b.value), ls=':', c='k', lw=2, alpha=0.8)
  axx.plot(np.log10(R0b.value), Hb, ls=':', c='k', lw=2, alpha=0.8)

  # Calculate Pearson correlations
  ytext = [None, 0.02, 0.02, 0.02, 0.7]
  savedict = {}
  for j, vy in enumerate(pretty_vars):
      for i, vx in enumerate(pretty_vars[:j]):
          r, p = pearsonr(df[vx], df[vy])
          savedict[f'{vx} vs. {vy}'] = {'r': r, 'p': p}
          s = f'$r = {r:.2f}$'
          if p > 0.001:
              s += '\n' + f'$p = {p:.4f}$'
          else:
              pexp = np.floor(np.log10(p))
              s += '\n' + rf'$p = {p/10**pexp:.1f} \times 10^{{{pexp:.0f}}}$'
          rax = g.axes[j, i]
          rax.text(0.95, ytext[j], s,
                   fontsize='xx-small',
                   bbox={'fc': 'white', 'ec': 'none', 'alpha': 0.85, 'pad': 1},
                   ha='right', va='bottom', transform=rax.transAxes)

  g.savefig(figfile)

  with open(figfile.replace('.pdf', '.json'), 'w') as f:
      json.dump(savedict, f, indent=4)


#+END_SRC

#+RESULTS:
[[file:mipsgal-pairplot.pdf]]

+ JSON file with the stats results: [[file:mipsgal-pairplot.json]]



*** Do all the statistical tests at once
:PROPERTIES:
:ID:       997CAD56-7C46-410A-921B-A569380C9ED3
:END:
+ This includes all the A/B tests on the MIPSGAL dataset
+ Plus intercomparison with Orion and RSG
+ And we do all the statistical tests we can think of
#+BEGIN_SRC python :return tabfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp, mannwhitneyu, ttest_ind, levene
  from astropy.stats import kuiper_two
  import astropy.coordinates as coord
  from astropy.table import Table
  import astropy.units as u
  import json

  def ra_dec_string_from_table_row(data):
      ra = f"{data['RAh']} {data['RAm']} {data['RAs']}"
      dec = f"{int(data['DE-']*data['DEd'])} {data['DEm']} {data['DEs']}"
      return f'{ra} {dec}'

  def rank_biserial(a, b):
      U = mannwhitneyu(a, b, alternative='two-sided')
      rb = 1.0 - 2*U.statistic/(len(a)*len(b))
      return rb, U.pvalue

  class MyEncoder(json.JSONEncoder):
      def default(self, obj):
          if isinstance(obj, np.integer):
              return int(obj)
          elif isinstance(obj, np.floating):
              return float(obj)
          elif isinstance(obj, np.ndarray):
              return obj.tolist()
          else:
              return super(MyEncoder, self).default(obj)

  tabfile = 'mipsgal-all-stats.json'


  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  ra_dec_strings = [ra_dec_string_from_table_row(row) for row in tab]
  c =  coord.SkyCoord(ra_dec_strings, unit=(u.hourangle, u.deg)).transform_to('galactic')

  tab['log10 |b|'] = np.log10(np.abs(c.b.deg))
  tab['cos(l)'] = np.cos(c.l)

  R0var = 'R0_fit'

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab[R0var]

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  # Recalculate extinction
  tab['Ak'] = 0.893*(tab['Hmag'] - tab['4.5mag'] + 0.1)
  tab['Ak'][tab['Ak'] < 0.0] = np.nan

  # Correct H magnitude for extinction
  tab['Hmag'] -= 1.55*tab['Ak']

  otab = Table.read('../LL-shapes-2017/new-ll-arcs-median.tab', format='ascii.tab')
  ctab = Table.read('../LL-shapes-2017/rsg-arcs-radii.tab', format='ascii.tab')
  otab['Rc'] = otab['Pi']
  otab['R90'] = otab['Lambda']
  otab['R90_asym'] = otab['d Lambda']
  otab['R90_asym'][otab['R90_asym'] == 0.0] = np.nan
  ctab['Rc'] = ctab['Rc out']
  ctab['R90_asym'] = ctab['dR90']
  ctab['R90_asym'][ctab['R90_asym'] == 0.0] = np.nan


  Ak_median = np.nanmedian(tab['Ak'][mgood])
  R0_median = np.nanmedian(tab[R0var][mgood])
  MH_median = np.nanmedian(tab['Hmag'][mgood])
  bmedian = np.nanmedian(tab['log10 |b|'][mgood])
  cosl_median = 0.8

  results = {}

  masks4tests = {
      'Environment: Facing': [
          tab['Env'] == 'I',
          (tab['Env'] == 'FH') | (tab['Env'] == 'FB')],
      'Environment: H II': [
          tab['Env'] == 'I',
          tab['Env'] == 'H'],
      'Single/Multiple source candidate': [
          tab['Unc'] != 'C',
          tab['Unc'] == 'C'],
      'With/without 8 micron': [
          tab['8um'] == 'Y',
          tab['8um'] != 'Y'],
      '3-star/4+-star': [
          m3,
          (m4 | m5)],
      'Low/high extinction': [
          tab['Ak'] < Ak_median,
          tab['Ak'] >= Ak_median],
      'Low/high R0': [
          tab[R0var] < R0_median,
          tab[R0var] >= R0_median],
      'Faint/bright H magnitude': [
          tab['Hmag'] > MH_median,
          tab['Hmag'] <= MH_median],
      'Low/high |b|': [
          tab['log10 |b|'] < bmedian,
          tab['log10 |b|'] >= bmedian],
      'High/low cos(l)': [
          tab['cos(l)'] >= cosl_median,
          tab['cos(l)'] < cosl_median],
  }

  datasets4tests = {
      'OB vs Orion': [tab[mgood], otab],
      'OB vs RSG': [tab[mgood], ctab]
  }


  # First do the descriptive stats on the full sample of 3, 4, 5-star sources

  dep_vars = 'Rc', 'R90', 'Rc_sigma', 'R90_sigma', 'R90_asym'

  descriptive_stats = {
      'mean': np.nanmean,
      'median': np.nanmedian,
      'sigma': np.nanstd,
      'iqr': lambda x: np.diff(np.nanpercentile(x, [25, 75]))[0],
      'mad': lambda x: np.nanmedian(np.abs(x - np.nanmedian(x))),
      'n': len,
  }

  test_stats = {
      'Welch t-test for mean': lambda x, y: ttest_ind(x, y, equal_var=False),
      'Anderson-Darling': lambda x, y: anderson_ksamp([x, y], midrank=False)[::2],
      'Kuiper': kuiper_two, 
      'Kolmogorov-Smirnov': ks_2samp, 
      'Rank biserial coefficient': rank_biserial,
      'Brown-Forsythe test for dispersion': levene,
  }

  results['Full sample'] = {
      v: {slabel: stat(tab[v][mgood])
          for slabel, stat in descriptive_stats.items()}
      for v in dep_vars}

  for mlabel, (m1, m2) in masks4tests.items():
      results[mlabel] = {
          v: {
              'Sample A': {
                  slabel: stat(tab[v][mgood & m1])
                  for slabel, stat in descriptive_stats.items()},
              'Sample B': {
                  slabel: stat(tab[v][mgood & m2])
                  for slabel, stat in descriptive_stats.items()},
              'A vs B Tests':{
                  tlabel: test(tab[v][mgood & m1], tab[v][mgood & m2])
                  for tlabel, test in test_stats.items()}
          } for v in dep_vars}

  # We only have a sub-set of the vars for the other datasets
  dep_vars = 'Rc', 'R90', 'R90_asym'
  for dlabel, (d1, d2) in datasets4tests.items():
      results[dlabel] = {
          v: {
              'Sample A': {
                  slabel: stat(d1[v][np.isfinite(d1[v])])
                  for slabel, stat in descriptive_stats.items()},
              'Sample B': {
                  slabel: stat(d2[v][np.isfinite(d2[v])])
                  for slabel, stat in descriptive_stats.items()},
              'A vs B Tests':{
                  tlabel: test(d1[v][np.isfinite(d1[v])], d2[v][np.isfinite(d2[v])])
                  for tlabel, test in test_stats.items()}
          } for v in dep_vars}

  with open(tabfile, 'w') as f:
      json.dump(results, f, indent=4, sort_keys=False, cls=MyEncoder)

#+END_SRC

#+RESULTS:
[[file:mipsgal-all-stats.json]]


*** Make a table of all the statistics
#+BEGIN_SRC python :return tabfile :results file
  import json
  import numpy as np
  from astropy.table import Table

  tabfile = 'mipsgal-summary-stats.tab'
  comparisons = json.load(open('mipsgal-all-stats.json'))

  cols = [
      'Comparison',
      'Variable',
      # Descriptive stats
      'mean A',
      'mean B',
      'sigma A',
      'sigma B',
      'delta A',
      'delta B',
      # Effect sizes
      'r_b',
      'd_c',
      'sig/tau',
      # p-values
      'K-S p',
      'r_b p',
      'B-F p',
  ]

  formats = {
      'Comparison': '{}',
      'Variable': '{}',
      # Descriptive stats
      'mean A': '{:.3f}',
      'mean B': '{:.3f}',
      'sigma A': '{:.3f}',
      'sigma B': '{:.3f}',
      'delta A': '{:.3f}',
      'delta B': '{:.3f}',
      # Effect sizes
      'r_b': '{:.3f}',
      'd_c': '{:.3f}',
      'sig/tau': '{:.3f}',
      # p-values
      'K-S p': '{:.3g}',
      'r_b p': '{:.3g}',
      'B-F p': '{:.3g}',
  }


  select_params = ['R90', 'Rc', 'R90_asym']

  default_delta = {
      'Sample A': {'mean': np.nan},
      'Sample B': {'mean': np.nan},
  }

  rows = []
  for comparison, params in comparisons.items():
      if comparison == 'Full sample':
          continue
      for param, data in params.items():
          assert 'Sample A' in data, f'{comparison} {param} {data}'
          if param not in select_params:
              continue
          sig_param = param + '_sigma'
          sdata = params.get(sig_param, default_delta)
          delta_A = sdata['Sample A']['mean']
          delta_B = sdata['Sample B']['mean']
          sigA = data['Sample A']['sigma']
          sigB = data['Sample B']['sigma']
          nA = data['Sample A']['n']
          nB = data['Sample B']['n']
          sig_pool = np.sqrt((nA*sigA**2 + nB*sigB**2)/(nA + nB))
          row = {
             'Comparison': comparison,
             'Variable': param,
             # Descriptive stats
             'mean A': data['Sample A']['mean'],
             'mean B': data['Sample B']['mean'],
             'sigma A': sigA,
             'sigma B': sigB,
             'delta A': delta_A,
             'delta B': delta_B,
             # Effect sizes
             'r_b': data['A vs B Tests']['Rank biserial coefficient'][0],
             'd_c': (data['Sample B']['mean'] - data['Sample A']['mean'])/sig_pool,
             'sig/tau': sigB / sigA,
             # p-values
             # 'K-S p': data['A vs B Tests']['Kolmogorov-Smirnov'][1],
             'K-S p': data['A vs B Tests']['Kuiper'][1],
             'r_b p': data['A vs B Tests']['Rank biserial coefficient'][1],
             'B-F p': data['A vs B Tests']['Brown-Forsythe test for dispersion'][1],
          }
          rows.append(row)

  tab = Table(names=cols, rows=rows)

  tab.write(tabfile, format='ascii.tab', formats=formats)

#+END_SRC

#+RESULTS:
[[file:mipsgal-summary-stats.tab]]


**** Tidy up p-value table for conversion to latex 
:PROPERTIES:
:TABLE_EXPORT_FILE: migsgal-summary-stats-tidied
:END:


#+name: table-header-snippet
#+BEGIN_SRC latex
  % \Width is used to align number under col header in first column
  \newlength\Width\settowidth\Width{Comparison}
  \begin{tabular}{
    @{} ll @{\quad }
    % Mean
    S[round-mode=places]S[round-mode=places]
    % Std Dev
    S[round-mode=places]S[round-mode=places]
    % Obs Disp
    SS
    % Effect sizes
    @{\quad} SSS[round-mode=places]
    % p values
    @{\quad}
    S[table-format = +1.2e1]
    S[table-format = +1.2e1]
    S[table-format = +1.2e1] @{}
    }\toprule
    & {Dependent}
    & \multicolumn{2}{c}{Mean}
    & \multicolumn{2}{c}{Std.\ Dev.}
    & \multicolumn{2}{c}{Obs.\ Disp.}
    & \multicolumn{3}{c @{} }{\dotfill Effect sizes\dotfill }
    & \multicolumn{3}{c @{}}{Non-parametric test \(p\)-values} \\ 
    {Comparison} & {Variable}
    & {\(\langle \text{A} \rangle\)} & {\(\langle \text{B} \rangle\)}
    & {\(\sigma_{\text{A}}\)} & {\(\sigma_{\text{B}}\)}
    & {\(\langle \epsilon_{\text{A}} \rangle\)} & {\(\langle \epsilon_{\text{B}} \rangle\)}
    & {\(r_b\)} & {Cohen \(d\)} & {\(\sigma_{\text{A}}/\sigma_{\text{B}}\)}
    & {K--S} & {Rank} &  {B--F}\\
    {\makebox[\Width]{(1)}} & \multicolumn{1}{c@{\quad}}{(2)}
    & {(3)} & {(4)}
    & {(5)} & {(6)}
    & {(7)} & {(8)}
    & {(9)} & {(10)} & {(11)}
    & {(12)} & {(13)} & {(14)}  \\  
    \midrule
#+END_SRC



#+name: table-description-snippet
#+begin_src latex
  \multicolumn{14}{@{}p{\linewidth}@{}}{
    \textit{Description of columns:}
    (Col.~1)~How the two A/B source sub-samples are defined, also giving the size of each sub-sample, \(n_{\text{A}}\) and~\(n_{\text{B}}\).
    (Col.~2)~Dependent variable whose distribution is compared between the two sub-samples.
    (Cols.~3--6)~Mean and standard deviation, \(\sigma\), of the dependent variable for each of the two sub-samples.
    (Cols.~7--8)~Mean over each sub-sample of the observational dispersion (\(\epsilon\), standard deviation) of radii that contribute to the dependent variable for each individual source, as in steps~\ref{step:R0} and \ref{step:R90} of \S~\ref{sec:autom-trac-fitt}.  Note that in the case of \(\Pi\), this is \(\epsilon(R_0)\), and so is not a direct measure of the observational uncertainty in \(\Pi\). 
    % (Cols.~9--10)~``Standard error of the mean'' (s.e.m.) of the dependent variable for each of the two sub-samples. 
    (Cols.~9--11)~Standardized ``effect sizes'', which are dimensionless measures of the difference in the distribution of the dependent variable between the two sub-samples.
    (Col.~9)~Rank biserial correlation coefficient \citep{Cureton:1956a}, which is obtained by considering all \(n_{\text{A}} n_{\text{B}}\) pair-wise comparisons of the dependent variable between a source in sub-sample~A and a source in sub-sample~B.  It is the difference between the fraction of such comparisons ``won'' by sub-sample~A and those ``won'' by sub-sample~B, and thus may vary between \(-1\) and \(+1\). 
    (Col.~10)~Cohen's \(d\), which is a dimensionless mean difference: \(d = (\langle \text{A} \rangle - \langle \text{B} \rangle) / \sigma_{\text{pool}} \), where \(\sigma_{\text{pool}} = (n_{\text{A}} \sigma_{\text{A}}^2 + n_{\text{B}} \sigma_{\text{B}}^2)^{1/2} / \sqrt{n_{\text{A}} + n_{\text{B}}}\) is the pooled standard deviation.
    (Col.~11)~Ratio of standard deviations between the two sub-samples.
    (Cols.~12--14)~Probabilities (\(p\)-values) of the two sub-samples being as different as observed if they were to be drawn from the same population, according to three different non-parametric tests.
    (Col.~12)~Anderson--Darling 2-sample test, which is a general test of similarity between two distributions that is designed to retain sensitivity to differences in the tails of the distributions.
    (Col.~13)~Mann--Whitney--Wilcoxon \(U\) test \citep{Mann:1947a}, which is sensitive to differences in the central value of the distributions.
    (Col.~14)~Brown--Forsythe test for equality of variance \citep{Brown:1974a}
  }
#+end_src

#+RESULTS: table-description-snippet
#+begin_export latex
\multicolumn{14}{@{}p{\linewidth}@{}}{
  \textit{Description of columns:}
  (Col.~1)~How the two A/B source sub-samples are defined, also giving the size of each sub-sample, \(n_{\text{A}}\) and~\(n_{\text{B}}\).
  (Col.~2)~Dependent variable whose distribution is compared between the two sub-samples.
  (Cols.~3--6)~Mean and standard deviation, \(\sigma\), of the dependent variable for each of the two sub-samples.
  (Cols.~7--8)~Mean over each sub-sample of the observational dispersion (\(\epsilon\), standard deviation) of radii that contribute to the dependent variable for each individual source, as in steps~\ref{step:R0} and \ref{step:R90} of \S~\ref{sec:autom-trac-fitt}.  Note that in the case of \(\Pi\), this is \(\epsilon(R_0)\), and so is not a direct measure of the observational uncertainty in \(\Pi\). 
  % (Cols.~9--10)~``Standard error of the mean'' (s.e.m.) of the dependent variable for each of the two sub-samples. 
  (Cols.~9--11)~Standardized ``effect sizes'', which are dimensionless measures of the difference in the distribution of the dependent variable between the two sub-samples.
  (Col.~9)~Rank biserial correlation coefficient \citep{Cureton:1956a}, which is obtained by considering all \(n_{\text{A}} n_{\text{B}}\) pair-wise comparisons of the dependent variable between a source in sub-sample~A and a source in sub-sample~B.  It is the difference between the fraction of such comparisons ``won'' by sub-sample~A and those ``won'' by sub-sample~B, and thus may vary between \(-1\) and \(+1\). 
  (Col.~10)~Cohen's \(d\), which is a dimensionless mean difference: \(d = (\langle \text{A} \rangle - \langle \text{B} \rangle) / \sigma_{\text{pool}} \), where \(\sigma_{\text{pool}} = (n_{\text{A}} \sigma_{\text{A}}^2 + n_{\text{B}} \sigma_{\text{B}}^2)^{1/2} / \sqrt{n_{\text{A}} + n_{\text{B}}}\) is the pooled standard deviation.
  (Col.~11)~Ratio of standard deviations between the two sub-samples.
  (Cols.~12--14)~Probabilities (\(p\)-values) of the two sub-samples being as different as observed if they were to be drawn from the same population, according to three different non-parametric tests.
  (Col.~12)~Anderson--Darling 2-sample test, which is a general test of similarity between two distributions that is designed to retain sensitivity to differences in the tails of the distributions.
  (Col.~13)~Mann--Whitney--Wilcoxon \(U\) test \citep{Mann:1947a}, which is sensitive to differences in the central value of the distributions.
  (Col.~14)~Brown--Forsythe test for equality of variance \citep{Brown:1974a}
}
#+end_export

#+header: :var table_header=table-header-snippet table_desc=table-description-snippet
#+BEGIN_SRC python :return outfile :results file
  import numpy as np
  import datetime
  from textwrap import dedent
  from astropy.table import Table

  tabfile = 'mipsgal-summary-stats.tab'
  outfile = 'mipsgal-summary-stats-table-body.tex'
  tab = Table.read(tabfile, format='ascii.tab')

  file_header = f"""\
  %%% MIPSGAL summary statistics
  %%% Table automatically generated from {tabfile}
  %%% {datetime.datetime.now()}
  %%%
  """

  table_footer = rf'''
  \\
  \bottomrule
  {table_desc}
  \end{{tabular}}
  '''

  order = [
      ['Faint/bright H magnitude', 
       'Low/high R0', 
       'Low/high extinction', 
       'Low/high |b|',
       'High/low cos(l)'
      ], 
      ['Environment: Facing', 
       'Environment: H II', 
       'Single/Multiple source candidate', 
       'With/without 8 micron',
       '3-star/4+-star',
      ], 
      ['OB vs Orion', 
       'OB vs RSG'
      ], 
  ]

  variable_replacements = {
      'R90': r'\(\Lambda\)',
      'R90_asym': r'\(\Delta \Lambda\)',
      'Rc': r'\(\Pi\)',
  }

  comparison_replacements = {
      'Faint/bright H magnitude': [r'Faint/bright',
                                   r'\(H\) magnitude',
                                   r'\(n_{\text{A}} =  n_{\text{B}} = 113\)'], 
      'Low/high R0': [r'Low/high',
                      r'bow shock size, \(R_0\)',
                      r'\(n_{\text{A}} =  n_{\text{B}} = 113\)'], 
      'Low/high extinction': [r'Low/high',
                              r'extinction, \(A_K\)',
                              r'\(n_{\text{A}} =  n_{\text{B}} = 113\)'], 
      'High/low cos(l)': [r'High/low',
                          r'\(\cos \ell\)',
                          r'\(n_{\text{A}}, n_{\text{B}} = 137, 90\)'], 
      'Low/high |b|': [r'Low/high',
                       r'\(\vert{}b\vert\)',
                       r'\(n_{\text{A}} =  n_{\text{B}} = 113\)'], 
      'Environment: Facing': [r'Environment:',
                              r'Isolated vs Facing',
                              r'\(n_{\text{A}}, n_{\text{B}} = 170, 41\)'], 
      'Environment: H II': [r'Environment:',
                            r'Isolated vs \hii',
                            r'\(n_{\text{A}}, n_{\text{B}} = 170, 16\)'], 
      'Single/Multiple source candidate': [r'Single/multiple',
                                           r'source candidate',
                                           r'\(n_{\text{A}}, n_{\text{B}} = 167, 60\)'], 
      'With/without 8 micron': [r'With/without',
                                r'\SI{8}{\um} emission',
                                r'\(n_{\text{A}}, n_{\text{B}} = 45, 182\)'], 
      'OB vs Orion': [r'MIPS vs Orion',
                      r'',
                      r'\(n_{\text{A}}, n_{\text{B}} = 227, 18\)'], 
      'OB vs RSG': [r'MIPS vs RSG',
                    r'',
                    r'\(n_{\text{A}}, n_{\text{B}} = 227, 16\)'],
      '3-star/4+-star': [r'3-star vs (4+5)-star',
                         r'',
                         r'\(n_{\text{A}}, n_{\text{B}} = 133, 94\)'],
  }


  def format_group_header(s):
      head = r'\multicolumn{10}{@{} l @{}}{\itshape '
      tail = r'}\\'
      return head + s + tail + '\n' + r'\addlinespace' + '\n'

  group_headers = [
      'Median split of continuous independent variables',
      'Categorical independent variables',
      'Intercomparison with other datasets',
  ]


  # Which p value is important for which columns
  signifiers = {
      'K-S p': 'K-S p',
      'r_b p': 'r_b p',
      'B-F p': 'B-F p',
      'r_b': 'r_b p',
      'd_c': 'r_b p',
      'sig/tau': 'B-F p',
  }

  p_threshold = 0.003
  p_threshold_marginal = 0.05

  def format_field(field, colname, row):
      """Indicate significant p values with font changes"""
      if colname == 'Comparison':
          # Take elements one by one from front of list
          return comparison_replacements[field].pop(0)
      elif colname == 'Variable':
          return variable_replacements[field]
      elif colname in signifiers:
          p = row[signifiers[colname]]
          if p <= p_threshold:
              return fr'\bfseries {field}'
          elif p <= p_threshold_marginal:
              return fr'\itshape {field}'
          else:
              return f'{field}'
      else:
          return f'{field}'


  def remove_nans(s):
      return ' ' if 'nan' in s else s

  linesep = r'\\' + '\n' 
  stanzasep = r'\\' + '\n' + r'\addlinespace' + '\n'
  groupsep = r'\\' + '\n' + r'\midrule' + '\n'
  fieldsep = ' & '
  lines = groupsep.join(
      format_group_header(gheader) + stanzasep.join(
          linesep.join(
              fieldsep.join(
                  remove_nans(format_field(field, colname, row))
                  for field, colname in zip(row.as_void(), row.colnames))
              for row in tab[tab['Comparison'] == comparison])
          for comparison in group)
      for group, gheader in zip(order, group_headers))

  with open(outfile, 'w') as f:
      f.write(
          dedent(file_header)
          + dedent(table_header)
          + lines
          + dedent(table_footer))

#+END_SRC

#+RESULTS:
[[file:mipsgal-summary-stats-table-body.tex]]



***** Test of using external latex snippets in python code block
#+name: test-snippet
#+BEGIN_SRC latex
  \emph{Hello}
#+END_SRC

#+BEGIN_SRC python :var s=test-snippet :return ss :results latex
ss = s.replace('Hello', 'Goodbye')
#+END_SRC

#+RESULTS:
#+BEGIN_EXPORT latex
\emph{Goodbye}
#+END_EXPORT

***** Old version done by hand

| Comparison                       | Variable | mean A | mean B | sigma A | sigma B | delta A | delta B | sigtot A | sigtot B |     r_b |     d_c | sig/tau |    A-D p |     r_b p |    B-F p |
|----------------------------------+----------+--------+--------+---------+---------+---------+---------+----------+----------+--------+--------+---------+----------+----------+----------|
| Faint/bright \(H\) magnitude     | R90      |  1.677 |  1.768 |   0.269 |   0.316 |   0.231 |   0.236 |    0.025 |    0.030 |  0.174 | -0.308 |   0.851 |   0.0215 |   0.0235 |    0.125 |
|                                  | dR90     |  0.183 |  0.198 |   0.161 |   0.163 |         |         |    0.015 |    0.015 |  0.070 | -0.093 |   0.987 |    0.538 |    0.365 |    0.761 |
|                                  | Rc       |  1.655 |  1.917 |   0.631 |   1.045 |   0.097 |   0.078 |    0.059 |    0.098 |  0.123 | -0.303 |   0.604 |    0.123 |    0.111 |   0.0335 |
| Low/high \(R_0\)                  | R90      |  1.707 |  1.739 |   0.250 |   0.336 |   0.256 |   0.212 |    0.024 |    0.031 |  0.061 | -0.110 |   0.745 |   0.0281 |    0.428 |  0.00139 |
|                                  | dR90     |  0.175 |  0.204 |   0.157 |   0.165 |         |         |    0.015 |    0.015 |  0.091 | -0.176 |   0.948 |    0.103 |    0.238 |    0.193 |
|                                  | Rc       |  1.766 |  1.803 |   0.975 |   0.755 |   0.114 |   0.062 |    0.092 |    0.071 |  0.100 | -0.043 |   1.291 |    0.228 |    0.192 |    0.599 |
| Low/high extinction              | R90      |  1.703 |  1.742 |   0.267 |   0.323 |   0.233 |   0.235 |    0.025 |    0.030 |  0.040 | -0.132 |   0.824 |    0.554 |    0.602 |    0.123 |
|                                  | dR90     |  0.186 |  0.195 |   0.138 |   0.183 |         |         |    0.013 |    0.017 | -0.039 | -0.057 |   0.754 |    0.301 |     0.61 |    0.112 |
|                                  | Rc       |  1.725 |  1.846 |   0.822 |   0.917 |   0.091 |   0.085 |    0.077 |    0.086 |  0.082 | -0.139 |   0.896 |    0.219 |    0.285 |    0.982 |
| Low/high \(\vert{}b\vert\)                 | R90      |  1.722 |  1.724 |   0.328 |   0.261 |   0.234 |   0.234 |    0.031 |    0.024 |  0.020 | -0.008 |   1.256 |    0.308 |    0.795 |   0.0534 |
|                                  | dR90     |  0.188 |  0.191 |   0.161 |   0.162 |         |         |    0.015 |    0.015 |  0.009 | -0.021 |   0.995 |    0.964 |    0.907 |    0.694 |
|                                  | Rc       |  1.706 |  1.862 |   0.727 |   0.988 |   0.085 |   0.091 |    0.068 |    0.092 |  0.069 | -0.181 |   0.736 |     0.19 |    0.368 |   0.0842 |
| High/low \(\cos \ell\)              | R90      |  1.734 |  1.707 |   0.279 |   0.321 |   0.241 |   0.223 |    0.024 |    0.034 | -0.049 |  0.093 |   0.868 |    0.361 |    0.532 |    0.159 |
|                                  | dR90     |  0.182 |  0.201 |   0.155 |   0.171 |         |         |    0.013 |    0.018 |  0.054 | -0.122 |   0.909 |    0.604 |    0.491 |    0.365 |
|                                  | Rc       |  1.807 |  1.751 |   0.946 |   0.742 |   0.090 |   0.084 |    0.081 |    0.078 | -0.000 |  0.064 |   1.274 |     1.03 |    0.999 |    0.549 |
|----------------------------------+----------+--------+--------+---------+---------+---------+---------+----------+----------+--------+--------+---------+----------+----------+----------|
| Environment: Facing              | R90      |  1.735 |  1.693 |   0.283 |   0.338 |   0.238 |   0.218 |    0.022 |    0.053 | -0.070 |  0.142 |   0.838 |    0.603 |     0.49 |    0.392 |
|                                  | dR90     |  0.190 |  0.195 |   0.161 |   0.172 |         |         |    0.012 |    0.027 | -0.019 | -0.034 |   0.938 |    0.507 |     0.85 |    0.438 |
|                                  | Rc       |  1.757 |  1.852 |   0.854 |   0.899 |   0.087 |   0.083 |    0.066 |    0.140 |  0.042 | -0.110 |   0.950 |    0.713 |    0.676 |    0.377 |
| Environment: \hii                | R90      |  1.735 |  1.680 |   0.283 |   0.309 |   0.238 |   0.233 |    0.022 |    0.077 | -0.130 |  0.193 |   0.916 |    0.518 |    0.391 |    0.782 |
|                                  | dR90     |  0.190 |  0.175 |   0.161 |   0.138 |         |         |    0.012 |    0.034 | -0.048 |  0.095 |   1.170 |    0.932 |    0.754 |    0.799 |
|                                  | Rc       |  1.757 |  1.907 |   0.854 |   0.955 |   0.087 |   0.105 |    0.066 |    0.239 |  0.024 | -0.174 |   0.894 |    0.496 |    0.875 |    0.255 |
| Single/Multiple source candidate | R90      |  1.709 |  1.762 |   0.289 |   0.315 |   0.230 |   0.243 |    0.022 |    0.041 |  0.074 | -0.177 |   0.917 |    0.342 |    0.396 |    0.338 |
|                                  | dR90     |  0.184 |  0.206 |   0.162 |   0.160 |         |         |    0.013 |    0.021 |  0.093 | -0.136 |   1.013 |    0.421 |    0.284 |     0.97 |
|                                  | Rc       |  1.767 |  1.833 |   0.825 |   0.988 |   0.090 |   0.080 |    0.064 |    0.128 |  0.027 | -0.076 |   0.835 |    0.999 |    0.756 |    0.605 |
| With/without \SI{8}{\um}         | R90      |  1.734 |  1.721 |   0.289 |   0.298 |   0.223 |   0.237 |    0.043 |    0.022 | -0.042 |  0.044 |   0.970 |    0.595 |    0.667 |    0.563 |
|                                  | dR90     |  0.203 |  0.186 |   0.205 |   0.149 |         |         |    0.031 |    0.011 |  0.021 |  0.106 |   1.377 |    0.765 |    0.826 |    0.219 |
|                                  | Rc       |  1.714 |  1.802 |   0.598 |   0.926 |   0.091 |   0.087 |    0.089 |    0.069 | -0.012 | -0.101 |   0.646 |    0.824 |    0.904 |      0.2 |
|----------------------------------+----------+--------+--------+---------+---------+---------+---------+----------+----------+--------+--------+---------+----------+----------+----------|
| MIPS vs Orion                    | R90      |  1.723 |  2.418 |   0.297 |   0.811 |         |         |    0.020 |    0.191 |  0.700 | -1.928 |   0.366 | 8.02e-06 | 7.84e-07 | 6.41e-06 |
|                                  | dR90     |  0.190 |  0.506 |   0.162 |   0.551 |         |         |    0.011 |    0.130 |  0.220 | -1.468 |   0.294 |  3.6e-05 |    0.121 | 4.03e-14 |
|                                  | Rc       |  1.784 |  2.639 |   0.871 |   1.302 |         |         |    0.058 |    0.307 |  0.516 | -0.940 |   0.669 | 0.000505 | 0.000273 |     0.12 |
| MIPS vs RSG                      | R90      |  1.723 |  1.386 |   0.297 |   0.122 |         |         |    0.020 |    0.046 | -0.756 |  1.152 |   2.425 | 0.000494 | 0.000671 |   0.0573 |
|                                  | dR90     |  0.190 |  0.197 |   0.162 |   0.296 |         |         |    0.011 |    0.112 | -0.242 | -0.045 |   0.546 |    0.156 |    0.276 |    0.397 |
|                                  | Rc       |  1.784 |  1.426 |   0.871 |   0.079 |         |         |    0.058 |    0.030 | -0.201 |  0.418 |  10.969 |   0.0742 |    0.367 |   0.0505 |
|----------------------------------+----------+--------+--------+---------+---------+---------+---------+----------+----------+--------+--------+---------+----------+----------+----------|


*** Copy mipsgal figure files to paper folder
#+BEGIN_SRC sh :results output
  FIGFILES='mipsgal-r0-r0-plus-dPA-edited.pdf mipsgal-Rc-R90-zoom-annotated.pdf mipsgal-Rc-R90-thumbnails.pdf mipsgal-pairplot.pdf mipsgal-Rc-R90-Mag.pdf mipsgal-Rc-R90-R0.pdf mipsgal-Rc-R90-candidates.pdf mipsgal-Rc-R90-environment.pdf mipsgal-Rc-R90-vs-Orion.pdf mipsgal-Rc-R90-vs-Herschel.pdf p-value-histogram-new.pdf p-value-histogram-new-linear.pdf mipsgal-boxplot-Rc-R90-versus-R0.pdf mipsgal-boxplot-Rc-R90-versus-H0.pdf mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf mipsgal-summary-stats-table-body.tex RSG/*-imageplot.pdf'
  date
  pwd
  for f in $FIGFILES; do
      cp -av $f ../papers/Paper1/figs 
  done
#+END_SRC

#+RESULTS:
#+begin_example
Wed Jul  5 23:24:08 CDT 2017
/Users/will/Work/Bowshocks/Jorge/bowshock-shape/Stellar-Bowshocks-2017
mipsgal-r0-r0-plus-dPA-edited.pdf -> ../papers/Paper1/figs/mipsgal-r0-r0-plus-dPA-edited.pdf
mipsgal-Rc-R90-zoom-annotated.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-zoom-annotated.pdf
mipsgal-Rc-R90-thumbnails.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-thumbnails.pdf
mipsgal-pairplot.pdf -> ../papers/Paper1/figs/mipsgal-pairplot.pdf
mipsgal-Rc-R90-Mag.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-Mag.pdf
mipsgal-Rc-R90-R0.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-R0.pdf
mipsgal-Rc-R90-candidates.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-candidates.pdf
mipsgal-Rc-R90-environment.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-environment.pdf
mipsgal-Rc-R90-vs-Orion.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-vs-Orion.pdf
mipsgal-Rc-R90-vs-Herschel.pdf -> ../papers/Paper1/figs/mipsgal-Rc-R90-vs-Herschel.pdf
p-value-histogram-new.pdf -> ../papers/Paper1/figs/p-value-histogram-new.pdf
p-value-histogram-new-linear.pdf -> ../papers/Paper1/figs/p-value-histogram-new-linear.pdf
mipsgal-boxplot-Rc-R90-versus-R0.pdf -> ../papers/Paper1/figs/mipsgal-boxplot-Rc-R90-versus-R0.pdf
mipsgal-boxplot-Rc-R90-versus-H0.pdf -> ../papers/Paper1/figs/mipsgal-boxplot-Rc-R90-versus-H0.pdf
mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf -> ../papers/Paper1/figs/mipsgal-R90-ratio-versus-R0-heteroscedastic.pdf
mipsgal-summary-stats-table-body.tex -> ../papers/Paper1/figs/mipsgal-summary-stats-table-body.tex
RSG/alphaori-imageplot.pdf -> ../papers/Paper1/figs/alphaori-imageplot.pdf
RSG/cwleo-imageplot.pdf -> ../papers/Paper1/figs/cwleo-imageplot.pdf
RSG/epaqr-imageplot.pdf -> ../papers/Paper1/figs/epaqr-imageplot.pdf
RSG/khicyg-imageplot.pdf -> ../papers/Paper1/figs/khicyg-imageplot.pdf
RSG/mucep-imageplot.pdf -> ../papers/Paper1/figs/mucep-imageplot.pdf
RSG/rcas-imageplot.pdf -> ../papers/Paper1/figs/rcas-imageplot.pdf
RSG/rhya-imageplot.pdf -> ../papers/Paper1/figs/rhya-imageplot.pdf
RSG/rleo-imageplot.pdf -> ../papers/Paper1/figs/rleo-imageplot.pdf
RSG/rscl-imageplot.pdf -> ../papers/Paper1/figs/rscl-imageplot.pdf
RSG/rtvir-imageplot.pdf -> ../papers/Paper1/figs/rtvir-imageplot.pdf
RSG/tetaps-imageplot.pdf -> ../papers/Paper1/figs/tetaps-imageplot.pdf
RSG/uuaur-imageplot.pdf -> ../papers/Paper1/figs/uuaur-imageplot.pdf
RSG/v1943sgr-imageplot.pdf -> ../papers/Paper1/figs/v1943sgr-imageplot.pdf
RSG/waql-imageplot.pdf -> ../papers/Paper1/figs/waql-imageplot.pdf
RSG/wpic-imageplot.pdf -> ../papers/Paper1/figs/wpic-imageplot.pdf
RSG/xpav-imageplot.pdf -> ../papers/Paper1/figs/xpav-imageplot.pdf
#+end_example

Also, example objects for each star rating
| 3 star | 0503 |
| 4 star | 0014 |
| 5 star | 0018 |

Three consecutive arcs, all with similar values
| 3 star | 0633 |
| 4 star | 0634 |
| 5 star | 0635 |

Close to each other, and similar sizes
| 3 star | 0689 |
| 4 star | 0696 |
| 5 star | 0688 |

Another nice group of 3, all similar sizes
| 3 star | 0533 |
| 4 star | 0532 |
| 5 star | 0530 |

Close group of 3, but disparate sizes
| 3 star | 0528 |
| 4 star | 0521 |
| 5 star | 0527 |

This is the one I am tending towards - close together on the sky, clearly showing progression in quality, and with a variety of sizes
| 3 star | 0510 |
| 4 star | 0506 |
| 5 star | 0517 |


#+BEGIN_SRC sh :results output
  date
  pwd
  cp -av OB/MipsGal/0510-*.png ../papers/Paper1/figs/0510-3-star.png 
  cp -av OB/MipsGal/0506-*.png ../papers/Paper1/figs/0506-4-star.png 
  cp -av OB/MipsGal/0517-*.png ../papers/Paper1/figs/0517-5-star.png 
#+END_SRC

#+RESULTS:
: Mon Mar 20 19:04:51 CST 2017
: /Users/will/Work/Bowshocks/Jorge/bowshock-shape/Stellar-Bowshocks-2017
: OB/MipsGal/0510-G315.8313+00.1055-MG3160p005-multiplot.png -> ../papers/Paper1/figs/0510-3-star.png
: OB/MipsGal/0506-G314.6326+00.0995-MG3150p005-multiplot.png -> ../papers/Paper1/figs/0506-4-star.png
: OB/MipsGal/0517-G316.5611-00.3164-MG3170n005-multiplot.png -> ../papers/Paper1/figs/0517-5-star.png







*** Distribution of p-values
:PROPERTIES:
:ID:       7D9AF45C-AD38-4FA9-B522-BEB0C7B94DFA
:END:
+ To make sure that we are not indulging in p-hacking
+ We can do a histogram of all the p-values

#+name: all-p-values
| Correlation     |         p |
|-----------------+-----------|
| Rc vs R0        |    0.0054 |
| R90 vs R0       |    0.0001 |
| Rc vs H         |    0.1229 |
| R90 vs H        |    0.0215 |
| Rc vs Facing    |      0.71 |
| Rc vs H II      |      0.50 |
| R90 vs Facing   |      0.60 |
| R90 vs H II     |      0.52 |
| Rc vs Confuse   |      1.00 |
| R90 vs Confuse  |      0.34 |
| Rc vs Herschel  |     0.074 |
| R90 vs Herschel |   0.00052 |
| Rc vs M42       |   0.00048 |
| R90 vs M42      | 0.0000105 |
| Rc vs 8 mic     |      0.82 |
| R90 vs 8 mic    |       0.6 |
| Rc vs AK        |      0.19 |
| R90 vs AK       |      0.63 |
| Rc vs b         |      0.19 |
| R90 vs b        |      0.31 |
| Rc vs cos(l)    |       1.0 |
| R90 vs cos(l)   |      0.36 |

# :return pvalues
#+header: :var tab=all-p-values
#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  import matplotlib.pyplot as plt
  import seaborn as sns
  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram.pdf'
  pvalues = np.array([float(p) for s, p in tab])
  n = len(pvalues)
  fig, ax = plt.subplots(figsize=(6,3))
  x1, x2 = -5.0, 0.0
  sns.distplot(np.log10(pvalues), kde=False, rug=True,
               rug_kws={'height': 0.4/9.0},
               hist_kws={'range': [x1, x2]}, bins=18, ax=ax)
  x = np.linspace(x1, x2, 200)
  ax.plot(x, 9.0*10**x, c='r')
  xu = -0.6
  ax.annotate('uniform', (xu, 9.0*10**xu), color='r',
              xytext=(-5, 20), textcoords='offset points',
              ha='right', va='bottom', bbox={'fc': 'w', 'alpha': 0.7, 'ec': 'none'},
              arrowprops={'arrowstyle': '-|>', 'color': 'r'})

  for p0 in 0.001, 0.05:
      ax.axvspan(np.log10(p0), x2+0.05, color='k', alpha=0.05)
      ax.axvline(np.log10(p0), lw=2, ls='--', alpha=0.7, c='k')
  ax.set(xlim=[x1-0.1, x2+0.05], ylim=[-0.7, 9.0],
	 xlabel='$\log_{10}(p)$', ylabel='Number of correlations tested',
  )
  ax.text(np.log10(0.001), 6, '$p = 0.001$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  ax.text(np.log10(0.05), 6, '$p = 0.05$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  xa, xb = np.log10(0.001), np.log10(0.05)
  ax.annotate('significant', (xa, 7.5),
              xytext=(-10, 0), textcoords='offset points',
              ha='right', va='bottom')
  ax.annotate('marginally\nsignificant', (0.5*(xa+xb), 7.5),
              xytext=(0, 0), textcoords='offset points',
              ha='center', va='center')
  ax.annotate('non-significant', (xb, 7.5),
              xytext=(10, 0), textcoords='offset points',
              ha='left', va='bottom')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram.pdf]]


+ [2017-04-16 Sun] Try again with the values from astropy table

#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  from astropy.table import Table
  import matplotlib.pyplot as plt
  import seaborn as sns
  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram-new.pdf'
  tab = Table.read('mipsgal-summary-stats.tab', format='ascii.tab')
  pvalues = np.concatenate([tab['r_b p'], tab['B-F p'], tab['K-S p']])
  n = len(pvalues)
  nsig = (pvalues < 0.003).sum()
  nn = n - nsig
  fig, ax = plt.subplots(figsize=(6,3.5))
  x1, x2 = -6.0, 0.0
  nbins = 18
  height = 500.0
  pvalues[pvalues < 10**x1] = 10**x1
  pvalues[pvalues > 1.0] = 1.0
  sns.distplot(np.log10(pvalues), kde=False, rug=True,
               rug_kws={'height': 0.045, 'lw': 0.5, 'alpha': 0.5},
               hist_kws={'range': [x1, x2], 'bottom': 0.01}, bins=nbins, ax=ax)
  x = np.linspace(x1, x2, nbins)
  xc = 0.5*(x[1:] + x[:-1])
  pc = 10**x[1:] - 10**x[:-1]
  ax.plot(xc, nn*pc, c='r')
  xu = -0.6

  ax.annotate('uniform\n$p$ distribution', (xc[-7], nn*pc[-7]), color='r',
              xytext=(5, -20), textcoords='offset points',
              ha='left', va='top', bbox={'fc': 'w', 'alpha': 0.7, 'ec': 'none'},
              arrowprops={'arrowstyle': '-|>', 'color': 'r'})

  for p0 in 0.003, 0.05:
      ax.axvspan(np.log10(p0), x2+0.05, color='k', alpha=0.05)
      ax.axvline(np.log10(p0), lw=2, ls='--', alpha=0.7, c='k')
  ticklabels = [f'$10^{{{i}}}$' for i in range(-6, 1)]
  ticklabels[0] = r'$\leq 10^{-6}$'
  ax.set(xlim=[x1-0.1, x2+0.05], ylim=[0.005, height],
	 xticks=range(-6, 1),
	 xticklabels=ticklabels,
	 xlabel='Significance level, $p$', ylabel='Number of correlations tested',
	 yscale='log',
  )
  ax.text(np.log10(0.003), 20, '$p = 0.003$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  ax.text(np.log10(0.05), 20, '$p = 0.05$', ha='center', va='bottom',
          bbox={'fc': 'w'})
  xa, xb = np.log10(0.003), np.log10(0.05)
  ax.annotate('significant', (xa, 0.4*height),
              xytext=(-20, 0), textcoords='offset points',
              ha='right', va='bottom', fontsize='small')
  ax.annotate('marginally\nsignificant', (0.5*(xa+xb), 0.4*height),
              xytext=(0, 0), textcoords='offset points',
              ha='center', va='center', fontsize='small')
  ax.annotate('non-significant', (xb, 0.4*height),
              xytext=(5, 0), textcoords='offset points',
              ha='left', va='bottom', fontsize='small')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram-new.pdf]]


+ [X] [2017-04-16 Sun] Try linear version again
  + Still not as good as log-log one
  + But give complementary info, so we will use both
+ Previously, linear version does not work because we didn't have enough samples
+ But now we have more if we use all the r_b and B--F p-values
#+BEGIN_SRC python :return figfile :results file 
  import numpy as np
  import matplotlib.pyplot as plt
  from astropy.table import Table
  import seaborn as sns

  sns.set_style('white')
  sns.set_color_codes('dark')
  figfile='p-value-histogram-new-linear.pdf'
  tab = Table.read('mipsgal-summary-stats.tab', format='ascii.tab')
  pvalues = np.concatenate([tab['r_b p'], tab['B-F p'], tab['K-S p']])
  pvalues[pvalues > 1.0] = 1.0

  n = len(pvalues)
  nsig = (pvalues < 0.001).sum()
  nn = n - nsig

  fig, ax = plt.subplots(figsize=(6,3.5))
  x1, x2 = 0.0, 1.0
  nbins = 20
  sns.distplot(pvalues, kde=False, rug=True,
               rug_kws={'height': 0.04, 'lw': 0.3, 'alpha': 0.3},
               hist_kws={'range': [x1, x2]}, bins=nbins, ax=ax)
  x = np.linspace(x1, x2, 200)
  ax.plot(x, (nn/nbins)*x**0.0, c='r')
  #ax.axvspan(0.05, x2, color='k', alpha=0.05)
  ax.axvline(0.05, lw=2, ls='--', alpha=0.7, c='k')
  ax.annotate('uniform\n$p$ distribution', (0.45, nn/nbins), color='r',
              xytext=(10, 30), textcoords='offset points',
              ha='left', va='bottom', bbox={'fc': 'w', 'alpha': 0.7, 'ec': 'none'},
              arrowprops={'arrowstyle': '-|>', 'color': 'r'})
  ax.set(xlim=[x1-0.02, x2+0.02], ylim=[-1.1, 21.8], yticks=[0, 5, 10, 15, 20],
	 xlabel='Significance level, $p$', 
     ylabel='Number of correlations tested',
  )
  ax.annotate('$p = 0.05$', (0.05, 11),
              xytext=(20, 0), textcoords='offset points',
              ha='left', va='center',
              bbox={'fc': 'w'}, 
              arrowprops={'arrowstyle': '-|>'})
  # ax.annotate('significant', (0.05, 2),
  #             xytext=(-10, 0), textcoords='offset points',
  #             ha='right', va='bottom')
  # ax.annotate('non-significant', (0.05, 2),
  #             xytext=(10, 0), textcoords='offset points',
  #             ha='left', va='bottom')
  sns.despine(ax=ax, trim=True)
  fig.tight_layout()
  fig.savefig(figfile)
#+END_SRC

#+RESULTS:
[[file:p-value-histogram-new-linear.pdf]]



**** Relation of p values to standard deviations
+ If we have a two-sided test, then we have the following:
  #+BEGIN_SRC python :return table
    import numpy as np
    import scipy.special
    from scipy.special import erfinv

    def two_sided_gauss_quantile(p):
        """Also known as 'probit function', `p` is the usual p-value from a
    two-sided significance test.  Returns the number of standard deviations"""
        p1 = 1 - 0.5*p
        return np.sqrt(2)*erfinv(2*p1 - 1)

    pvalues = [0.05, 0.003, 6e-5, 6e-7, 2e-9]
    table = [None, ['p', '(1 - p) %', 'n sigma', 'approx'], None]
    for p in pvalues:
        nsig = two_sided_gauss_quantile(p)
        table.append([p, 100*(1 - p), f'{nsig:.2f}', int(np.round(nsig))])
    table.append(None)
  #+END_SRC

    #+RESULTS:
    |-------+------------+---------+--------|
    |     p |  (1 - p) % | n sigma | approx |
    |-------+------------+---------+--------|
    |  0.05 |       95.0 |    1.96 |      2 |
    | 0.003 |       99.7 |    2.97 |      3 |
    | 6e-05 |     99.994 |    4.01 |      4 |
    | 6e-07 |   99.99994 |    4.99 |      5 |
    | 2e-09 | 99.9999998 |    6.00 |      6 |
    |-------+------------+---------+--------|

+ So, for instance 3-sigma significance corresponds to p = 0.003 and 99.7% confidence


**** Controlling the familywise error rate
+ This is the "multiple comparison" problem
  + Also known as Jelly Bean problem: https://xkcd.com/882/
+ We can use the Holm--Bonferroni method or the Holm--idk method to modify the confidence level, so as to maintain p=0.05 over all the tests
  + \cite{Holme:1979a}
+ \alpha = 0.05 is significance level
+ m = 22 is number of hypotheses
+ k is rank of p-value ordered from lowest to highest
+ Holm--Bonferroni compares each p-value agains  \alpha/(m + 1 - k)
  + And, once we have one p larger than this, discards that and all remaining ones as non-significant
+ Holm--idk uses 1 - (1-\alpha)^{1/(m + 1 - k)} instead
  + But it doesn't actually make a fat lot of difference
+ In fact, in our case we would get the same result from using \alpha/m for all comparisons
  + Which is the classical Bonferroni procedurew
+ Whichever way, it is only the first four hypotheses that make the cut.
+ But we can also use Benjamini & Hochberg (1995)
  + \cite{Benjamini:1995a}
  + Supposedly controls the False Discovery Rate (FDR)
  + The same as above, but comparing against k \alpha / m
  + This is slightly /softer/ and leads to null hypothesis rejection for the first 5 tests. 

| Correlation     |         p |  k | m + 1 - k |     HB |     HS |     BH |   |
|-----------------+-----------+----+-----------+--------+--------+--------+---|
| R90 vs M42      | 0.0000105 |  1 |        22 | 0.0023 | 0.0023 | 0.0023 | * |
| R90 vs R0       |    0.0001 |  2 |        21 | 0.0024 | 0.0024 | 0.0045 | * |
| Rc vs M42       |   0.00048 |  3 |        20 | 0.0025 | 0.0026 | 0.0068 | * |
| R90 vs Herschel |   0.00052 |  4 |        19 | 0.0026 | 0.0027 | 0.0091 | * |
| Rc vs R0        |    0.0054 |  5 |        18 | 0.0028 | 0.0028 | 0.0114 | x |
| R90 vs H        |    0.0215 |  6 |        17 | 0.0029 | 0.0030 | 0.0136 | . |
| Rc vs Herschel  |     0.074 |  7 |        16 | 0.0031 | 0.0032 | 0.0159 |   |
| Rc vs H         |    0.1229 |  8 |        15 | 0.0033 | 0.0034 | 0.0182 |   |
| Rc vs AK        |      0.19 |  9 |        14 | 0.0036 | 0.0037 | 0.0205 |   |
| Rc vs b         |      0.19 | 10 |        13 | 0.0038 | 0.0039 | 0.0227 |   |
| R90 vs b        |      0.31 | 11 |        12 | 0.0042 | 0.0043 | 0.0250 |   |
| R90 vs Confuse  |      0.34 | 12 |        11 | 0.0045 | 0.0047 | 0.0273 |   |
| R90 vs cos(l)   |      0.36 | 13 |        10 | 0.0050 | 0.0051 | 0.0295 |   |
| Rc vs H II      |      0.50 | 14 |         9 | 0.0056 | 0.0057 | 0.0318 |   |
| R90 vs H II     |      0.52 | 15 |         8 | 0.0063 | 0.0064 | 0.0341 |   |
| R90 vs Facing   |      0.60 | 16 |         7 | 0.0071 | 0.0073 | 0.0364 |   |
| R90 vs 8 mic    |       0.6 | 17 |         6 | 0.0083 | 0.0085 | 0.0386 |   |
| R90 vs AK       |      0.63 | 18 |         5 | 0.0100 | 0.0102 | 0.0409 |   |
| Rc vs Facing    |      0.71 | 19 |         4 | 0.0125 | 0.0127 | 0.0432 |   |
| Rc vs 8 mic     |      0.82 | 20 |         3 | 0.0167 | 0.0170 | 0.0455 |   |
| Rc vs Confuse   |      1.00 | 21 |         2 | 0.0250 | 0.0253 | 0.0477 |   |
| Rc vs cos(l)    |       1.0 | 22 |         1 | 0.0500 | 0.0500 | 0.0500 |   |
#+TBLFM: $5=0.05/$4;f4::$6=1 - (1-0.05)**(1/($4));f4::$7=0.05 $3/22 ;f4


**** Dealing with "the error of the transposed conditional"
:PROPERTIES:
:TABLE_EXPORT_FILE: p-values-type-I-rate
:END:

+ The p-value gives 
  #+BEGIN_QUOTE
  The probability of finding a difference between two populations as large (or larger) than observed *if* there is no difference in the underlying distribution from which the two populations are drawn (the null hypothesis).
  #+END_QUOTE
+ The error lies in transposing that to
  #+BEGIN_QUOTE
  The probability that the null hypothesis is true *given* the observations.  That is, the probability of a /false positive/ or a /Type I error/. 
  #+END_QUOTE
+ This is discussed in detail in Colquhoun (2014)
  + \cite{Colquhoun:2014a}
+ Se also
  + \cite{Sellke:2001a}
  + Type I error probability \alpha from their eq (3) is given in table below
  + This is technically a lower bound on \alpha, which given by 
    \[
    \alpha(p) = \bigg[ 1 - \big(e p \ln p\big)^{-1} \bigg]^{-1}
    \]
  + But only when p < 1/e = 0.3679
+ One way of getting from one to the other is via Bayes' theorem
  + But that requires a prior (probability of hypothesis, independent of the data), which may be hard to estimate
+ Alternatively, by taking a more stringent significance threshold (e.g, p = 0.001), one can reduce the Type I error rate to about 0.05, regardless of the prior distribution
+ In general, we need to make a qualitative balance between:
  + Type I errors: false positives, thinking we have found something that is not really there
  + Type II errors: false negatives, failing to find a real effect due to insufficient /power/ in our methods
+ By decreasing our significance threshold from 0.05 to 0.001, we decrease the Type I error rate, but we have reduced the /statistical power/, so we will /increase/ the Type II error rate
  + Especially for effect sizes smaller than the widths of the distributions
+ Then there are Type III errors:
  + "correctly rejecting the null hypothesis for the wrong reason"
  + \cite{Mosteller:1948a}
  + Although, when I look at this in detail, it is more specific and less relevant than I initially thought

#+name: error-rates
| Correlation     |         p |      \alpha |   |
|-----------------+-----------+--------+---|
| Rc vs R0        |    0.0054 | 0.0712 | . |
| R90 vs R0       |    0.0001 | 0.0025 | * |
| Rc vs H         |    0.1229 | 0.4119 |   |
| R90 vs H        |    0.0215 | 0.1833 | . |
| Rc vs Facing    |      0.71 |      1 |   |
| Rc vs H II      |      0.50 |      1 |   |
| R90 vs Facing   |      0.60 |      1 |   |
| R90 vs H II     |      0.52 |      1 |   |
| Rc vs Confuse   |      1.00 |      1 |   |
| R90 vs Confuse  |      0.34 | 0.4993 |   |
| Rc vs Herschel  |     0.074 | 0.3437 |   |
| R90 vs Herschel |   0.00052 | 0.0106 | * |
| Rc vs M42       |   0.00048 | 0.0099 | * |
| R90 vs M42      | 0.0000105 | 0.0003 | * |
| Rc vs 8 mic     |      0.82 |      1 |   |
| R90 vs 8 mic    |       0.6 |      1 |   |
| Rc vs AK        |      0.19 | 0.4617 |   |
| R90 vs AK       |      0.63 |      1 |   |
| Rc vs b         |      0.19 | 0.4617 |   |
| R90 vs b        |      0.31 | 0.4967 |   |
| Rc vs cos(l)    |      1.00 |      1 |   |
| R90 vs cos(l)   |      0.36 | 0.4999 |   |
#+TBLFM: $3=$2 < exp(-1) ? 1/(1+1/(-exp(1) $2 log($2))) : 1 ;f4


|   C | \xi=0.1 |   | \xi=0.5 |   |  \xi=1 |   |
|-----+-------+---+-------+---+------+---|
| 0.0 |  1.00 |   |  1.00 |   | 1.00 |   |
| 0.1 |  0.21 |   |  0.68 |   | 0.90 |   |
| 0.2 |  0.15 | . |  0.55 |   | 0.80 |   |
| 0.3 |  0.11 |   |  0.45 |   | 0.70 |   |
| 0.4 |  0.09 |   |  0.37 | . | 0.60 |   |
| 0.5 |  0.07 |   |  0.29 |   | 0.50 | . |
| 0.6 |  0.05 |   |  0.23 |   | 0.40 |   |
| 0.7 |  0.04 |   |  0.16 |   | 0.30 |   |
| 0.8 |  0.02 |   |  0.11 |   | 0.20 |   |
| 0.9 |  0.01 |   |  0.05 |   | 0.10 |   |
|  1. |  0.00 |   |  0.00 |   | 0.00 |   |
#+TBLFM: $2=1 - $1**0.1;f2::$4=1 - $1**0.5;f2::$6=1 - $1;f2::


**** TODO False discovery rate revisited [2017-04-07 Fri]
+ Colquhoun uses "False discovery rate" to mean the probability of Type I error (given the observations)
+ There are some extensive discussions:
  + In discussions after [[https://errorstatistics.com/2015/03/16/stephen-senn-the-pathetic-p-value-guest-post/][this blog post]]
  + And in [[http://stats.stackexchange.com/questions/143325/confusion-with-false-discovery-rate-and-multiple-testing-on-colquhoun-2014/146405#146405][this stack exchange question]]
+ In both cases Colquhoun joins in
+ And there is a lot of push-back against his paper
+ Some of the anti-Colquhoun points made are
  1. That he misuses the term "false discovery rate" FDR when he really means "false discovery proportion" FDP, as defined by Benjamini-Hochberg
     - This point is made by Bonferroni in a stack exchage comment!
  2. That Colquhoun is assuming point nulls and two-sided tests, whereas in practice people often use composite nulls and one-sided tests
     - Although everyone seems to agree that most papers fail to be explicit about it
     - A point null is something like "there is no difference", or "parameters are uncorrelated"
     - A composite null can be something like "A is no better than B", that is, "difference is less than or equal to zero"
  3. That his "FDP \ge 30% for p < 0.05" is not as watertight as he thinks
     - It would be smaller if the prior probability of the null were < 50%
       + But he rebuts this by mocking the idea that we should presuppose the truth of the hypothesis we are testing
       + I'm not sure what I think of this - certainly in some cases we may have good external grounds for thinking that the null is not true
       + But he is right that it would be odd to be testing /only/ hypotheses that we are already convinced of
     - Supposedly things are different with one-sided tests and composite nulls, but I haven't really looked into this (see below)
+ Further info on this
  + Casella & Berger (1987) "Reconciling bayesian and frequentist evidence in the one-sided testing problem"
  + This argues a counterpoint to Berger & Sellke (1987), which was the ur-paper for Sellke, Bayarri, & Berger (2001) that gives the "callibration" of p-values
  + Note that these are two different Bergers!
    1. James O. Berger, who works with Sellke
    2. Roger L. Berger, who works with Casella
  + So, Casella & Berger consider 1-sided tests between two "diffuse" hypothesese, instead of the 2-sided test of a point hypothesis pace Berger & Sellke
    + They find that the posterior probability of H_0 (which is the false discovery proportion) is no higher than p in this case
    + Which is very different from Berger & Sellke
    + They suggest that the problem lies in having a point null, so that the (supposedly fair) prior is a "point mass" of 0.5 at H_0 and the other 0.5 spread over H_1.  They think that this is not an "impartial" prior, but is rather heavily biased in favour of H_0
+ The HEP point of view
  + Excellent review paper: Cousins (2017) "The Jeffreys--Lindley paradox and discovery criteria in high energy physics"
  + Jeffreys--Lindley paradox is that we can have a small p, which disfavours the null hypothesis H_0 in frequentist framework (small likelihood ratio), but if n is sufficiently large, then the Bayes Factor will favour H_0
    + This is for simple-vs-composite hypothesis testing
    + And is because \lambda \propto (\sigma_tot/\tau) BF
    + Where \lambda = L(\theta_0) / L(\hat{\theta}) is ratio of likelihood of \theta_0 under H_0 (which is a bit like p, but with the pdf instead of cdf) and L(\hat{\theta}) is maximum likelihood of \theta under H_1
    + And \sigma_tot = \sigma/N^{1/2} is the std of the observed sample mean if \sigma^2 is the population variance
    + And \tau is the scale of the prior pdf for H_1
  + It turns out that the false-positive Type I error rate \alpha is more usually defined as the /probability of wrongly rejecting H_0 when it is true/, which means that it is equal to the p value
    + So this is very different from how Sellke (2001) use it, which is /probability of H_0 given the data/, or the "posterior probability of H_0": Pr(H_0 | x)
    + So I should probably not use \alpha in this way, since it is a bit non-standard
  + Interesting history of 5-\sigma criterion (p = 3e-7 !!!):
    + This arose from observations in 1960s of resonances associated with new particles
    + Partly a way of mitigating the "multiple trials factor", which in HEP seems to be called the /look elsewhere effect/
    + And partly to offset poorly understood "systematic effects"
    + Was mainly practical, in the sense that empirically it was found that 3-\sigma and 4-\sigma discoveries tended to go away as more data was accumulated
    + There is even a short paper by Louis Lyons (2013) on it
  + One strategy for dealing with the look elsewhere effect is given in Gross & Vitells (2010), while another is given in Algeri & van Dyk (2017)
    + These are both a lot more complicated than tha Bonferroni correction
  + Hierarchy of scales that give rise to the Jeffreys--Lindley paradox
    + \tau \gg \sigma_tot \gg \epsilon
    + \tau and \sigma_tot are defined above (H_1 prior scale and evidence scale)
    + \epsilon is the scale of H_0, which \to 0 for a point hypothesis
  + So the factor (\sigma_tot/\tau) is called the /Ockham factor/
    + It can become very small for large N
  + In HEP there is often a high degree of belief in the null hypothesis
+ So there is a big fight among
  1. Those who don't like p-values and think we should report posterior probabilities instead
     - For example, [[http://www.fharrell.com/2017/02/a-litany-of-problems-with-p-values.html][Frank Harrell in this blog post]]
  2. Those who say this is confusing things and that \alpha should always mean the significance level for the likelihood integral.  And that there is no problem with p-values per se, just with people abusing them
     - For example, anything by [[https://errorstatistics.com][Deborah Mayo]]


**** Problems with the median split
+ Cautionary quote from \cite{Ruscio:2008a}
  #+BEGIN_QUOTE
  The methodological literature consistently cautions against artificially dichotomizing continuous variables, and the consequences of this practice on measures of effect size will not be considered further.
  #+END_QUOTE
+ See also \cite{MacCallum:2002a}
  #+BEGIN_QUOTE
  The authors examine the practice of dichotomization of quantitative measures, wherein relationships among variables are examined after 1 or more variables have been converted to dichotomous variables by splitting the sample at some point on the scale(s) of measurement. A common form of dichotomization is the median split, where the independent variable is split at the median to form high and low groups, which are then compared with respect to their means on the dependent variable. The consequences of dichotomization for measurement and statistical analyses are illustrated and discussed. The use of dichotomization in practice is described, and justifications that are offered for such usage are examined. The authors present the case that dichotomization is rarely defensible and often will yield misleading results.
  #+END_QUOTE
+ And finally \cite{Streiner:2002a}
  #+BEGIN_QUOTE
  So. in conclusion, the one word of advice about turning continuous variables into dichotomies isdon't!
  #+END_QUOTE
+ *CONCLUSION*
  + We really ought to do the Pearson r for all the continuous variables, to check that the p-values from those are comparable to the Anderson-Darling ones
  + The main problem with the median split is that we are throwing away information. 

**** TODO Statistical power, Type II errors (\beta), and effect size
+ [X] Get the McGrath & Meyer (2006) paper
  + Discusses differences between r and d as measures of effect size for two-sample tests
  + But only interested in changes in the mean
+ [ ] Calculate effect sizes for all our tests
  + Cohen's d for the dichotomous tests
    + Note that pooled std dev requires care to calculate
    + https://en.wikipedia.org/wiki/Pooled_variance
    + And [[http://stats.stackexchange.com/questions/43159/how-to-calculate-pooled-variance-of-two-groups-given-known-group-variances-mean][this]] stack exchange answer
  + [ ] Or we can use the rank biserial correlation coefficient that we calculated from the Mann-Whitney U statistic
  + And we can use sigma ratio to give heteroscedastic effect size 
  + Pearson r for the continuous-continuous (but we already have this)
  + Also https://www.psychometrica.de/effect_size.html has lots of javascript calculators for transorming between different sorts of effect sizes
+ [X] Find p value for Pearson r tests (such as in the pair plot)
+ [ ] Do Pearson r for all the continuous variables against Rc and R90, and compare the p-values with those from A-D
***** Effect size for changes in dispersion
+ There is a paper by Best (1994) that talks about a "partition-of-\chi^2" test that treats location and spread separately
  + This cites a previous paper by Nair (1986)
  + And that has a citation of Mood (1954), who has what may be even better, so we look at that next
+ Mood has various tests, but including:
  #+BEGIN_QUOTE
  square rank test for dispersion
  #+END_QUOTE
  which looks worth investigating
+ There are more tests discussed in "Rank Tests of Dispersion" by Moses (1963)
  + He finds that most go wrong when the means or medians are not equal
+ Further analysis is done by Fligner & Killeen (1976) "Distribution-Free Two-Sample Tests for Scale"
  + They assume equal medians
  + They have modified versions of three previous tests
    1. Ansari-Bradley
    2. Mood
    3. Klotz
  + They spend most time on the Mood analog
  + For an effect size, they use \sigma/\tau, which is the ratio of the dispersions of the underlying distribution functions for the two samples
+ Now I have discovered more tests for equality of dispersion
  + [[https://en.wikipedia.org/wiki/F-test_of_equality_of_variances][F-test_of_equality_of_variances]] is for Gaussian distributions, and it is supposedly very sensitive to the normality assumption so needs to be used with care
    + The test statistic is just the ratio of variances between the two groups
      + It's distribution should follow the central F-distribution if the population variances are in fact equal.  For large N, this just looks like a slightly skew gaussian, centered on 1
      + If they are not equal, then the distribution of the test statistic is a non-central F-distribution, that will center on the the true ratio
    + A version of this for the k-sample case is Hartley's test, which simply looks at the ratio of group variances between the largest and smallest
  + There are other, more robust tests, of which the best seems to be the [[https://en.wikipedia.org/wiki/Brown%E2%80%93Forsythe_test][BrownForsythe_test]]
    + Brown & Forsyth (1974)
  + But the only one I can find a python routine for is [[https://en.wikipedia.org/wiki/Levene%2527s_test][Levene's test]]
    + See also this [[http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm][NIST page]]
    + Implemented in =scipy.stats.levene=
    + Has the advantage that there are three different variants, which use different measures of the "location" (mean, median, or trimmed mean), which are better suited to different sorts of distributions
    + So, if we use the median option, then this /is/ the Brown-Forsythe test
    + In Brown & Forsyth (1974), the three options are called W_0, W_50, and W_10
      + W_0 (mean) is the original Levine
      + W_50 (median) is B--F, and is recommended for skewed distros
      + W_10 (trimmed) is recommended for heavy-tailed distros
+ Brown & Forsyth (1974) Table 1 gives power estimates for various tests at the \alpha = 0.05 level
  + By which they mean the p-value threshold
  + Numbers are expressed as percentages
  + For zero effect size (1:1 variances), these /ought/ to give p = \alpha = 5%
    + But the parametric tests, e.g., F-test, give much larger values when the distros are non-gaussian
  + With N=40 in each sample, we only have power of about 40% for 2:1 variances, or 80% for 4:1 variances (this is using W_50 or W_10, as appropriate)
  + Presumably, this would improve with larger N
  + Unfortunately, there is no estimate for smaller values of \alpha than 0.05

*** Comparison with the Orion Nebula bow shocks

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-vs-Orion.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  otab = Table.read('../LL-shapes-2017/new-ll-arcs-all.tab', format='ascii.tab')
  omtab = Table.read('../LL-shapes-2017/new-ll-arcs-median.tab', format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.7, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = mgood, 
  shades = True, 
  alphas = 0.5, 
  cmaps = 'Purples', 
  gammas = 0.5, 
  lss = None, 

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03), 
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

      sns.kdeplot(otab['Pi'].data, otab['Lambda'].data, 
                  n_levels=8, cmap='Greens_d', linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  #levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.4, 1.6],
                  bw=(0.06, 0.045),
                  shade=False, shade_lowest=False, ax=ax, alpha=alpha)

  # masks5 = m5, 
  # colors = 'purple', 
  # alphas = 0.8, 
  # labels = 'MIPSGAL',

  # Fake a legend for the NIPSGAL contours
  cmap = matplotlib.cm.get_cmap(cmaps[0])
  ax.fill_between([], [],
                  color=cmap(0.7), alpha=alpha, label='MIPSGAL arcs')
  # Only put points for the LL arcs
  ax.plot(omtab['Pi'], omtab['Lambda'], 
          'o', ms=7, alpha=0.8, c='g', mec='w', mew=1, label='M42 arcs')

  ax.legend(frameon=True, loc='lower right', title='')

  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.17
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02

  colors = 'purple', 'g'
  alphas = 0.8, 0.8
  labels = 'MIPSGAL', 'M42'

  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      datasets = tab['Rc'][m], omtab['Pi']
      for data, c, axx in zip(datasets, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(data, bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      datasets = tab['R90'][m], omtab['Lambda']
      for data, c, axx in zip(datasets, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(data, bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {len(data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 

      for axx in ax_y_Rc, ax_n_Rc, ax_y_R90, ax_n_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-vs-Orion.pdf]]


**** Orion sources but colored by R_0/D
#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.stats import kuiper_two
  from astropy.table import Table
  from matplotlib import pyplot as plt
  import matplotlib
  from matplotlib.colors import PowerNorm
  from matplotlib.legend_handler import HandlerTuple
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-vs-Orion-R0-D.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  otab = Table.read('../LL-shapes-2017/new-ll-arcs-all.tab', format='ascii.tab')
  omtab = Table.read('../LL-shapes-2017/new-ll-arcs-extras.tab', format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.7, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = mgood, 
  shades = True, 
  alphas = 0.5, 
  cmaps = 'Purples', 
  gammas = 0.5, 
  lss = None, 

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03), 
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)

      sns.kdeplot(otab['Pi'].data, otab['Lambda'].data, 
                  n_levels=8, cmap='Greens_d', linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  #levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.4, 1.6],
                  bw=(0.06, 0.045),
                  shade=False, shade_lowest=False, ax=ax, alpha=alpha)

  # masks5 = m5, 
  # colors = 'purple', 
  # alphas = 0.8, 
  # labels = 'MIPSGAL',

  # Fake a legend for the NIPSGAL contours
  cmap = matplotlib.cm.get_cmap(cmaps[0])
  p1 = ax.fill_between([], [],
                  color=cmap(0.7), alpha=alpha, label='MIPSGAL arcs')
  # Only put points for the LL arcs
  ll_cmap = sns.dark_palette((0.4, 0.8, 0.4), n_colors=256, as_cmap=True)
  g = ax.scatter(omtab['Pi'], omtab['Lambda'], 
                 marker='o', alpha=0.8, s=70, zorder=100,
                 c=np.log10(omtab['1000 R_0/D']), cmap=ll_cmap,
                 edgecolors='w', linewidths=1, label='_nolabel_')
  p2, = ax.plot([], [], 'o', mec='w', mew=1, ms=7,
               color=ll_cmap(0.1), alpha=0.8, label='M42 arcs')
  p3, = ax.plot([], [], 'o', mec='w', mew=1, ms=7,
               color=ll_cmap(0.5), alpha=0.8, label='M42 arcs')
  p4, = ax.plot([], [], 'o', mec='w', mew=1, ms=7,
               color=ll_cmap(0.9), alpha=0.8, label='M42 arcs')

  ax.legend([p1, (p2, p3, p4)], ['MIPSGAL arcs', 'M42 arcs'],
            frameon=True, loc='lower right', title='',
            handler_map={tuple: HandlerTuple(ndivide=None)},
  )

  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.17
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02

  colors = 'purple', 'g'
  alphas = 0.8, 0.8
  labels = 'MIPSGAL', 'M42'

  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      datasets = tab['Rc'][m], omtab['Pi']
      for data, c, axx in zip(datasets, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(data, bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              Ku, pKu = kuiper_two(data, datasets[0])
              axx.text(1.0, 0.9, fr'K-S $p = {pKu:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      datasets = tab['R90'][m], omtab['Lambda']
      for data, c, axx in zip(datasets, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(data, bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {len(data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              Ku, pKu = kuiper_two(data, datasets[0])
              axx.text(1.0, 0.9, fr'K-S $p = {pKu:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 

      for axx in ax_y_Rc, ax_n_Rc, ax_y_R90, ax_n_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-vs-Orion-R0-D.pdf]]


*** Comparison with the Herschel AGB/RSG sources

#+BEGIN_SRC python :return figfile :results file
  import numpy as np
  from scipy.stats import ks_2samp, anderson_ksamp
  from astropy.table import Table
  from matplotlib import pyplot as plt
  from matplotlib.colors import PowerNorm
  import matplotlib.ticker as mticker
  import seaborn as sns
  import seaborn.distributions 

  # Save original version of KDE function
  smkde_original = seaborn.distributions._statsmodels_bivariate_kde
  def smkde_logxy(x, y, bw, gridsize, cut, clip):
      """Calculate KDE on logarithmic grid for x and y"""
      xx, yy, z = smkde_original(np.log10(x), np.log10(y), bw, gridsize, cut, clip)
      xx = 10**xx
      yy = 10**yy
      return xx, yy, z
  # Monkey patch the function that sns.kdeplot uses to calculate the KDE
  seaborn.distributions._statsmodels_bivariate_kde = smkde_logxy

  sns.set_color_codes('dark')

  figfile = 'mipsgal-Rc-R90-vs-Herschel.pdf'

  # Limits and ticks for new log scale (used in xlim and histograms)
  range_ = [0.35, 9.5]
  nhist = 15
  bins_ = np.logspace(np.log10(range_[0]), np.log10(range_[1]), nhist+1)
  binsx = np.logspace(np.log10(range_[0]), np.log10(range_[1]), 2*nhist+1)
  ticks2 = [0.5, 1.0, 2.0, 5.0]
  ticks = [0.4, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 4.0, 5.0, 7.0]

  combo_file = 'mipsgal-arcfit.tab'
  tab = Table.read(combo_file, format='ascii.tab')

  for col in ['Rc', 'Rc_sigma', 'R90p', 'R90p_sigma', 'R90n', 'R90n_sigma']:
      tab[col] /= tab['R0_fit']

  tab['R90'] = 0.5*(tab['R90p'] + tab['R90n'])

  tab['R90_sigma'] = np.sqrt( 0.5*(tab['R90n_sigma']**2 + tab['R90p_sigma']**2) )
  tab['R90_asym'] =  0.5*np.abs(tab['R90p'] - tab['R90n'])

  tab['Rcp'] = tab['Rc'] + 0.3*tab['Rc_sigma']
  tab['Rcn'] = tab['Rc'] - 0.3*tab['Rc_sigma']

  otab = Table.read('../LL-shapes-2017/rsg-arcs-radii.tab', format='ascii.tab')

  fig, ax = plt.subplots(figsize=(6, 6))
  Rc_grid = np.linspace(0.0, 10.0, 2000)
  R90_T0_grid = np.sqrt(2*Rc_grid)
  R90_T1_grid = np.sqrt(2*Rc_grid - 1.0)
  R90_T1_grid[~np.isfinite(R90_T1_grid)] = 0.0 

  ax.fill_between(Rc_grid, R90_T1_grid, R90_T0_grid, color='k', alpha=0.2)
  ax.fill_between(Rc_grid, R90_T0_grid, color='k', alpha=0.1)
  ax.plot(Rc_grid, R90_T0_grid, c='k', lw=0.5)
  ax.axhline(1.0, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.axvline(1.0, ymax=0.7, lw=0.5, alpha=0.5, color='k', zorder=-1)
  ax.plot([0.0, 10.0], [0.0, 10.0], lw=0.5, alpha=0.5, color='k', zorder=-1)

  m5 = tab['Rating'] ==  5
  m4 = tab['Rating'] ==  4
  m3 = tab['Rating'] ==  3
  m2 = tab['Rating'] ==  2
  m1 = tab['Rating'] ==  1

  mgood = m5 | m4 | m3

  R0_median = np.nanmedian(tab['R0_fit'][mgood])

  myes = tab['R0'] >= R0_median
  mno = tab['R0'] < R0_median

  masks = mgood, 
  shades = True, 
  alphas = 0.5, 
  cmaps = 'Purples', 
  gammas = 0.5, 
  lss = None, 

  # m = m5 | m4 | m3
  # sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
  #             n_levels=30, cmap='Cyans',
  #             shade=True, shade_lowest=False, ax=ax, alpha=0.8)

  for m, alpha, cmap, shade, gamma, ls in zip(
          masks, alphas, cmaps, shades, gammas, lss):
      sns.kdeplot(tab['Rc'][m].data, tab['R90'][m].data,
                  n_levels=8, cmap=cmap, linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  levels=[0.5, 1.0, 2.0, 4.0, 8.0, 12.0, 16.0],
                  bw=(0.045, 0.03),
                  shade=shade, shade_lowest=False, ax=ax, alpha=alpha)
    
      sns.kdeplot(otab['Rc out'].data, otab['R90'].data, 
                  n_levels=6, cmap='Reds_d', linewidths=1, norm=PowerNorm(gamma),
                  linestyles=ls, 
                  #levels=[0.05, 0.1, 0.3, 0.7, 0.9, 1.0, 1.2, 1.4, 1.6],
                  bw=(0.03, 0.02),
                  shade=False, shade_lowest=False, ax=ax, alpha=alpha)

  # masks5 = m5, 
  # colors = 'purple', 
  # alphas = 0.8, 
  # labels = 'MIPSGAL',

  ax.plot(tab['Rc'][m5], tab['R90'][m5], 
          'o', ms=4, alpha=0.5, c='purple', label='MIPSGAL arcs')
  ax.plot(otab['Rc out'], otab['R90'], 
          'o', ms=6, alpha=0.8, c='r', mec='w', mew=1, label='Herschel arcs')

  ax.legend(frameon=True, loc='lower right', title='')

  Rmax = 4.0

  #ax.legend(frameon=True, loc='upper right')
  ax.set(
      xlim=range_, ylim=range_,
      xlabel=r'Planitude: $\Pi = R_c/R_0$',
      ylabel=r'Alatude: $\Lambda = R_{90}/R_0$',
      xscale='log', yscale='log')
  ax.xaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_locator(mticker.FixedLocator(ticks))
  ax.yaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))
  ax.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  ## Histograms of marginal distributions
  subwin_w = 0.2
  subwin_h = 0.1
  subwin_x0 = 0.17
  subwin_y0 = 0.75
  subwin_xmargin = 0.06
  subwin_ymargin = 0.02


  colors = 'purple', 'r'
  alphas = 0.8, 0.8
  labels = 'MIPSGAL', 'Herschel'

  with sns.plotting_context(
          rc={'axes.labelsize': 9,
              'xtick.labelsize': 9,
              'ytick.labelsize': 9,}):

      ax_y_Rc = fig.add_axes((subwin_x0, subwin_y0 + subwin_h + subwin_ymargin,
                              subwin_w, subwin_h))
      ax_n_Rc = fig.add_axes((subwin_x0, subwin_y0,
                              subwin_w, subwin_h))
      ax_y_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0 + subwin_h + subwin_ymargin,
                               subwin_w, subwin_h))
      ax_n_R90 = fig.add_axes((subwin_x0 + subwin_w + subwin_xmargin,
                               subwin_y0,
                               subwin_w, subwin_h))

      # Back to the original masks that include 5, 4, 3-star sources
      yq0, dyq = 0.1, 0.05
      datasets = tab['Rc'][m], otab['Rc out']
      for data, c, axx in zip(datasets, colors, [ax_y_Rc, ax_n_Rc]):
          sns.distplot(data, bins=bins_, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.3f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      #
      ax_n_Rc.set(xlabel=r'$\Pi$')
      ax_y_Rc.set(xlabel='_nolabel_')
      ax_y_Rc.tick_params(labelbottom='off') 

      # Back to the original masks that include 5, 4, 3-star sources
      datasets = tab['R90'][m], otab['R90']
      for data, c, axx in zip(datasets, colors, [ax_y_R90, ax_n_R90]):
          sns.distplot(data, bins=binsx, hist_kws={'range': range_},
                       color=c, kde=False, ax=axx)
          q10, q25, q50, q75, q90 = np.nanpercentile(data,
                                                     [10, 25, 50, 75, 90])
          axx.axvspan(q10, q25, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q75, q90, yq0 - dyq/4, yq0 + dyq/4, color='k', alpha=0.7)
          axx.axvspan(q25, q75, yq0 - dyq, yq0 + dyq, color='w', alpha=0.7)
          axx.axvline(q50, yq0 - dyq, yq0 + dyq, color='k', lw=2)
          axx.annotate(s=f'{q50:.2f}', xy=(q50, 0.0), xycoords='data',
                       xytext=(0.0, 8), textcoords='offset points',
                       fontsize=8, ha='center', va='bottom'
          )
          axx.text(1.0, 0.4, fr'$N = {len(data)}$',
                   fontsize=8, ha='right', va='top',
                   transform=axx.transAxes)
          # Calculate K-S statistic
          if c != colors[0]:
              KS, pKS = ks_2samp(data, datasets[0])
              AD, levelsAD, pAD = anderson_ksamp([data, datasets[0]],
                                                 midrank=False)
              axx.text(1.0, 0.9, fr'A-D $p = {pAD:.5f}$',
                       fontsize=8, ha='right', va='top',
                       transform=axx.transAxes)
              # axx.text(1.0, 0.9, fr'K-S $p = {pKS:.2f}$',
              #          fontsize=8, ha='right', va='top',
              #          transform=axx.transAxes)
      ax_n_R90.set(xlabel=r'$\Lambda$')
      ax_y_R90.set(xlabel='_nolabel_')
      ax_y_R90.tick_params(labelbottom='off') 

      for axx in ax_y_Rc, ax_n_Rc, ax_y_R90, ax_n_R90:
          axx.set(
              xlim=range_,
              xscale='log',
          )
          axx.xaxis.set_major_locator(mticker.FixedLocator(ticks2))
          axx.xaxis.set_major_formatter(mticker.FormatStrFormatter('%0g'))

  sns.despine()
  fig.tight_layout(pad=1.0)
  fig.savefig(figfile)


#+END_SRC

#+RESULTS:
[[file:mipsgal-Rc-R90-vs-Herschel.pdf]]


*** Where the figures are suposed to be (but they aren't)
http://iopscience.iop.org/0067-0049/227/2/18/suppdata/
http://iopscience.iop.org/0067-0049/227/2/18/media

** Tracing the shapes
*** OB stars
*** RSG stars (and AGB)
:PROPERTIES:
:ID:       94EECFDB-B61E-4242-89C2-09BD3B36D587
:END:
**** \alpha Orionis (Betelgeuse)
+ Press release image
  + [[file:RSG/Betelgeuse_Herschel_large.jpg]]
  + http://herschel.cf.ac.uk/results/betelgeuse
+ Original data from http://archives.esac.esa.int/hsa/whsa/
  + Use the most processed version: https://www.cosmos.esa.int/web/herschel/user-provided-data-products
  + [[file:RSG/AlphaOri-160_10_AFGL190.mod.fits]]
+ Put crosses on to trace the outer arc
  + file:RSG/Betelgeuse_Herschel-arcs.reg
+ Fit circle to the arc

#+BEGIN_SRC sh :results verbatim
cd RSG
python ../../read-shapes-LL/find-xy-shell.py alphaori --pa0 45
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
cd RSG
python ../../read-shapes-LL/fit-circle-shell.py alphaori --debug --thmax 75
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 115
    # variables        = 2
    chi-square         = 4833.978
    reduced chi-square = 42.779
    Akaike info crit   = 433.927
    Bayesian info crit = 439.417
[[Variables]]
    xc:  -136.600747 +/- 4.042615 (2.96%) (init=-328.3531)
    yc:  -68.7003769 +/- 2.189979 (3.19%) (init=-161.0606)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.788 
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.79302917,  7.40696111)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.75476522,  7.38787767)>
Separation star->center in arcsec:  152.90622356827168
sqrt(xc**2 + yc**2) =  152.903583849
#+end_example
**** Sources from Cox et al
+ From Fig 1, these look like good candidates
+ These are the ones that look like they will give a good chance of measuring R_c and R_90
  + Constitute 7 out of 22 "Type I" morphologies, which are the ones with bowshocks
  + So this is about 15% of the total sample
| Name      |       IRAS | Arc | PA (pm) | PA (R_0) |
|-----------+------------+-----+---------+---------|
| \alpha Ori     | 05524+0723 |  70 |    47.7 |      54 |
| UU Aur    | 06331+3829 |  70 |   170.4 |     200 |
| R Leo     | 09448+1139 |  70 |   112.3 |     117 |
| R Hya     | 13269-2301 |  70 |   313.7 |     284 |
| V1943 Sgr | 20038-2722 | 160 |     155 |     135 |
| X Pav     | 20075-6005 |  70 |    84.9 |      88 |
| \mu Cep     | 21419+5832 |  70 |   216.3 |      85 |
+ Position angles:
  + The PA (pm) column is the PA from proper motion
  + The PA (R_0) column is \theta in Cox et al table, which is PA of measured R_0
  + They are roughly similar, except for in \mu Cep
+ Arc tracing
  + Done at 70 micron in most of them, since higher resolution and arc is generally more prominent
  + Exception is V1943 Sgr, which was better at 160 micron because the arc is incomplete (and smaller radius) in 70 micron





#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py alphaori --pa0 45
python $D/find-xy-shell.py uuaur --pa0 200
python $D/find-xy-shell.py rleo --pa0 120
python $D/find-xy-shell.py rhya --pa0 280
python $D/find-xy-shell.py v1943sgr --pa0 135
python $D/find-xy-shell.py xpav --pa0 90
python $D/find-xy-shell.py mucep --pa0 90
#+END_SRC

#+RESULTS:

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/fit-circle-shell.py uuaur --debug --thmax 75 --savefig
python $D/fit-circle-shell.py rleo --debug --thmax 75 --savefig
python $D/fit-circle-shell.py rhya --debug --thmax 75 --savefig
python $D/fit-circle-shell.py v1943sgr --debug --thmax 75 --savefig
python $D/fit-circle-shell.py xpav --debug --thmax 75 --savefig
python $D/fit-circle-shell.py mucep --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 30
    # variables        = 2
    chi-square         = 41.623
    reduced chi-square = 1.487
    Akaike info crit   = 13.824
    Bayesian info crit = 16.626
[[Variables]]
    xc:   16.8594638 +/- 1.325922 (7.86%) (init= 60.40364)
    yc:   27.9451035 +/- 1.085789 (3.89%) (init= 49.65105)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.871 
outer : 16.8594638507 27.9451035068 110.880506704
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.13680833,  38.44531944)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.14278787,  38.45308197)>
Separation star->center in arcsec:  32.636478940017064
sqrt(xc**2 + yc**2) =  32.6369473348
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 25
    # variables        = 2
    chi-square         = 113.231
    reduced chi-square = 4.923
    Akaike info crit   = 41.764
    Bayesian info crit = 44.202
[[Variables]]
    xc:  -27.6306523 +/- 2.819767 (10.21%) (init=-80.22768)
    yc:   10.1887863 +/- 1.194150 (11.72%) (init= 24.41952)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.694 
outer : -27.6306523697 10.188786316 115.4680875
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.88944583,  11.42896667)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.88161538,  11.43179689)>
Separation star->center in arcsec:  29.44922227126463
sqrt(xc**2 + yc**2) =  29.4493517241
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 23
    # variables        = 2
    chi-square         = 1421.187
    reduced chi-square = 67.676
    Akaike info crit   = 98.846
    Bayesian info crit = 101.117
[[Variables]]
    xc:   140.492937 +/- 25.44561 (18.11%) (init= 74.84915)
    yc:  -44.3774797 +/- 16.61982 (37.45%) (init=-50.84217)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.938 
outer : 140.492937587 -44.3774797556 233.715250577
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.4279125, -23.28123333)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.47039763, -23.29356041)>
Separation star->center in arcsec:  147.32887879730998
sqrt(xc**2 + yc**2) =  147.335081435
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 9
    # variables        = 2
    chi-square         = 107.967
    reduced chi-square = 15.424
    Akaike info crit   = 26.361
    Bayesian info crit = 26.756
[[Variables]]
    xc:  -9.00521997 +/- 4.329462 (48.08%) (init=-21.26717)
    yc:   9.55461819 +/- 8.053743 (84.29%) (init= 43.25624)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.805 
outer : -9.00521997279 9.55461819706 66.2326613809
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.73027917, -27.22538889)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.72746606, -27.22273483)>
Separation star->center in arcsec:  13.129609599812916
sqrt(xc**2 + yc**2) =  13.1295360028
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 20
    # variables        = 2
    chi-square         = 15.131
    reduced chi-square = 0.841
    Akaike info crit   = -1.580
    Bayesian info crit = 0.412
[[Variables]]
    xc:  -23.6800578 +/- 1.490004 (6.29%) (init=-47.41168)
    yc:  -5.37155279 +/- 0.439924 (8.19%) (init=-3.641001)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.393 
outer : -23.6800577954 -5.37155279834 72.1185290177
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.94182917, -59.9371)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.92869854, -59.9385921)>
Separation star->center in arcsec:  24.281134357013805
sqrt(xc**2 + yc**2) =  24.2816539111
[[Fit Statistics]]
    # function evals   = 15
    # data points      = 22
    # variables        = 2
    chi-square         = 502.755
    reduced chi-square = 25.138
    Akaike info crit   = 72.839
    Bayesian info crit = 75.021
[[Variables]]
    xc:  -24.0294996 +/- 7.512966 (31.27%) (init=-32.43941)
    yc:   12.9462552 +/- 2.468645 (19.07%) (init=-7.011985)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.545 
outer : -24.0294996661 12.9462552934 92.6235883967
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.8768,  58.78037778)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.86392212,  58.78397396)>
Separation star->center in arcsec:  27.29400267199457
sqrt(xc**2 + yc**2) =  27.2950981006
#+end_example
**** Tweaking the circle fits
+ Turns out that things can be improved by considering more points when determining the minimum radius from the source
  + This is now an argument =--window= to [[file:~/Work/Bowshocks/Jorge/bowshock-shape/read-shapes-LL/find-xy-shell.py::parser.add_argument("--window",%20type=int,%20default=3,][find-xy-shell.py]]
  + It needs to be determined on a source-by-source basis, depending on how densely spaced the points are 


#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py mucep --pa0 90 --window 45
python $D/fit-circle-shell.py mucep --debug --thmax 120 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
Warning: Closest point of outer arc is at one end, using all points in parabola fit
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 40
    # variables        = 2
    chi-square         = 2119.452
    reduced chi-square = 55.775
    Akaike info crit   = 162.801
    Bayesian info crit = 166.179
[[Variables]]
    xc:  -41.7900811 +/- 3.362566 (8.05%) (init=-68.72503)
    yc:  -0.16878389 +/- 1.684986 (998.31%) (init=-10.39162)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.137 
outer : -41.790081096 -0.168783895798 108.666039258
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.8768,  58.78037778)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 325.85440388,  58.78033089)>
Separation star->center in arcsec:  41.79044995674801
sqrt(xc**2 + yc**2) =  41.790421941
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py alphaori --pa0 80 --debug --window 21
python $D/fit-circle-shell.py alphaori --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
Shape: (point)
RA, Dec: 5:55:10.327 +7:24:25.06
Params:  point=circle color=red text={alpha orionis}

Shape: (point)
RA, Dec: 5:54:42.930 +7:31:27.97
Params:  point=x

Shape: (point)
RA, Dec: 5:54:46.199 +7:31:36.66
Params:  point=x

Shape: (point)
RA, Dec: 5:54:46.977 +7:31:40.72
Params:  point=x

Shape: (point)
RA, Dec: 5:54:47.911 +7:31:44.19
Params:  point=x

Shape: (point)
RA, Dec: 5:54:51.685 +7:31:55.20
Params:  point=x

Shape: (point)
RA, Dec: 5:54:52.814 +7:31:56.94
Params:  point=x

Shape: (point)
RA, Dec: 5:54:54.930 +7:32:04.31
Params:  point=x

Shape: (point)
RA, Dec: 5:54:56.844 +7:32:12.02
Params:  point=x

Shape: (point)
RA, Dec: 5:54:58.714 +7:32:09.34
Params:  point=x

Shape: (point)
RA, Dec: 5:54:59.659 +7:32:09.34
Params:  point=x

Shape: (point)
RA, Dec: 5:55:00.921 +7:32:06.67
Params:  point=x

Shape: (point)
RA, Dec: 5:55:02.227 +7:32:08.34
Params:  point=x

Shape: (point)
RA, Dec: 5:55:03.330 +7:32:04.99
Params:  point=x

Shape: (point)
RA, Dec: 5:55:04.074 +7:32:01.31
Params:  point=x

Shape: (point)
RA, Dec: 5:55:04.659 +7:32:00.31
Params:  point=x

Shape: (point)
RA, Dec: 5:55:05.267 +7:32:03.66
Params:  point=x

Shape: (point)
RA, Dec: 5:55:06.101 +7:31:56.96
Params:  point=x

Shape: (point)
RA, Dec: 5:55:07.024 +7:31:54.62
Params:  point=x

Shape: (point)
RA, Dec: 5:55:07.925 +7:31:50.60
Params:  point=x

Shape: (point)
RA, Dec: 5:55:08.533 +7:31:47.92
Params:  point=x

Shape: (point)
RA, Dec: 5:55:09.862 +7:31:41.22
Params:  point=x

Shape: (point)
RA, Dec: 5:55:13.510 +7:31:27.78
Params:  point=x

Shape: (point)
RA, Dec: 5:55:14.456 +7:31:22.62
Params:  point=x

Shape: (point)
RA, Dec: 5:55:15.221 +7:31:22.62
Params:  point=x

Shape: (point)
RA, Dec: 5:55:15.559 +7:31:18.60
Params:  point=x

Shape: (point)
RA, Dec: 5:55:16.077 +7:31:12.24
Params:  point=x

Shape: (point)
RA, Dec: 5:55:17.496 +7:31:07.22
Params:  point=x

Shape: (point)
RA, Dec: 5:55:18.847 +7:31:09.89
Params:  point=x

Shape: (point)
RA, Dec: 5:55:19.748 +7:30:57.84
Params:  point=x

Shape: (point)
RA, Dec: 5:55:20.378 +7:30:53.15
Params:  point=x

Shape: (point)
RA, Dec: 5:55:21.099 +7:30:48.79
Params:  point=x

Shape: (point)
RA, Dec: 5:55:21.594 +7:30:37.74
Params:  point=x

Shape: (point)
RA, Dec: 5:55:22.292 +7:30:27.02
Params:  point=x

Shape: (point)
RA, Dec: 5:55:22.932 +7:30:19.52
Params:  point=x

Shape: (point)
RA, Dec: 5:55:23.427 +7:30:14.16
Params:  point=x

Shape: (point)
RA, Dec: 5:55:23.625 +7:30:11.42
Params:  point=x

Shape: (point)
RA, Dec: 5:55:23.406 +7:30:06.94
Params:  point=x

Shape: (point)
RA, Dec: 5:55:24.200 +7:30:03.36
Params:  point=x

Shape: (point)
RA, Dec: 5:55:24.635 +7:29:59.04
Params:  point=x

Shape: (point)
RA, Dec: 5:55:24.951 +7:29:49.68
Params:  point=x

Shape: (point)
RA, Dec: 5:55:25.501 +7:29:45.83
Params:  point=x

Shape: (point)
RA, Dec: 5:55:25.845 +7:29:45.36
Params:  point=x

Shape: (point)
RA, Dec: 5:55:26.048 +7:29:41.41
Params:  point=x

Shape: (point)
RA, Dec: 5:55:26.580 +7:29:34.67
Params:  point=x

Shape: (point)
RA, Dec: 5:55:26.830 +7:29:29.32
Params:  point=x

Shape: (point)
RA, Dec: 5:55:27.836 +7:29:07.41
Params:  point=x

Shape: (point)
RA, Dec: 5:55:27.883 +7:28:58.96
Params:  point=x

Shape: (point)
RA, Dec: 5:55:28.339 +7:28:52.69
Params:  point=x

Shape: (point)
RA, Dec: 5:55:28.695 +7:28:45.46
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.279 +7:28:36.30
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.733 +7:28:27.13
Params:  point=x

Shape: (point)
RA, Dec: 5:55:30.008 +7:28:18.70
Params:  point=x

Shape: (point)
RA, Dec: 5:55:30.494 +7:28:11.94
Params:  point=x

Shape: (point)
RA, Dec: 5:55:30.818 +7:28:04.23
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.196 +7:27:56.27
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.601 +7:27:45.02
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.925 +7:27:37.78
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.087 +7:27:24.92
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.233 +7:27:16.57
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.416 +7:27:05.72
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.637 +7:27:00.87
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.210 +7:26:53.51
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.445 +7:26:41.49
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.679 +7:26:33.74
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.888 +7:26:24.04
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.066 +7:26:13.51
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.316 +7:26:00.95
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.441 +7:25:54.20
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.910 +7:25:42.81
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.128 +7:25:34.90
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.347 +7:25:29.55
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.660 +7:25:21.17
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.879 +7:25:14.43
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.941 +7:25:06.06
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.988 +7:24:59.08
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.165 +7:24:52.40
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.462 +7:24:45.97
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.516 +7:24:36.73
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.651 +7:24:27.89
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.678 +7:24:21.86
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.543 +7:24:16.23
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.543 +7:24:10.61
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.569 +7:24:00.16
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.650 +7:23:50.92
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.650 +7:23:41.67
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.812 +7:23:38.05
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.525 +7:23:30.15
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.511 +7:23:20.65
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.607 +7:23:13.08
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.044 +7:21:34.62
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.613 +7:21:13.77
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.299 +7:20:53.34
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.298 +7:20:41.54
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.831 +7:20:29.73
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.318 +7:20:15.84
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.664 +7:20:04.74
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.290 +7:19:52.93
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.823 +7:19:36.96
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.637 +7:19:27.93
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.936 +7:19:10.57
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.516 +7:18:56.69
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.142 +7:18:47.66
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.733 +7:18:22.39
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.228 +7:17:34.75
Params:  point=x

Shape: (point)
RA, Dec: 5:55:27.967 +7:17:18.09
Params:  point=x

Shape: (point)
RA, Dec: 5:55:26.894 +7:17:01.42
Params:  point=x

Shape: (point)
RA, Dec: 5:55:25.847 +7:16:27.91
Params:  point=x

Shape: (point)
RA, Dec: 5:55:24.110 +7:16:08.75
Params:  point=x

Shape: (point)
RA, Dec: 5:55:22.766 +7:15:34.58
Params:  point=x

Shape: (point)
RA, Dec: 5:55:22.038 +7:15:22.08
Params:  point=x

Shape: (point)
RA, Dec: 5:55:18.509 +7:14:52.09
Params:  point=x

Shape: (point)
RA, Dec: 5:55:17.557 +7:14:45.42
Params:  point=x

Shape: (point)
RA, Dec: 5:55:13.749 +7:14:04.59
Params:  point=x

Shape: (point)
RA, Dec: 5:55:12.797 +7:13:52.09
Params:  point=x

Shape: (point)
RA, Dec: 5:54:41.892 +7:31:16.18
Params:  point=x

Shape: (point)
RA, Dec: 5:54:41.075 +7:31:10.97
Params:  point=x

Shape: (point)
RA, Dec: 5:54:36.134 +7:30:30.44
Params:  point=x

Shape: (point)
RA, Dec: 5:54:34.850 +7:30:17.70
Params:  point=x

Shape: (point)
RA, Dec: 5:54:33.255 +7:29:56.86
Params:  point=x

Shape: (point)
RA, Dec: 5:55:37.292 +7:22:15.68
Params:  point=x

Shape: (point)
RA, Dec: 5:55:37.405 +7:22:34.85
Params:  point=x

Shape: (point)
RA, Dec: 5:55:37.405 +7:22:48.18
Params:  point=x

Shape: (point)
RA, Dec: 5:55:34.208 +7:19:06.53
Params:  point=x

Shape: (point)
RA, Dec: 5:55:33.368 +7:18:51.53
Params:  point=x

Shape: (point)
RA, Dec: 5:55:32.079 +7:18:24.87
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.015 +7:18:06.54
Params:  point=x

Shape: (point)
RA, Dec: 5:55:30.343 +7:18:32.37
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.449 +7:23:00.23
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.495 +7:22:43.57
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.495 +7:22:20.65
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.494 +7:22:05.37
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.587 +7:21:41.07
Params:  point=x

Shape: (point)
RA, Dec: 5:55:36.027 +7:21:04.26
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.798 +7:25:51.07
Params:  point=x

Shape: (point)
RA, Dec: 5:55:35.285 +7:26:09.13
Params:  point=x

Shape: (point)
RA, Dec: 5:55:31.985 +7:27:56.02
Params:  point=x

Shape: (point)
RA, Dec: 5:55:22.306 +7:30:20.84
Params:  point=x

Shape: (point)
RA, Dec: 5:55:21.431 +7:30:28.07
Params:  point=x

Shape: (point)
RA, Dec: 5:55:20.653 +7:30:39.90
Params:  point=x

Shape: (point)
RA, Dec: 5:55:19.880 +7:30:45.15
Params:  point=x

Shape: (point)
RA, Dec: 5:55:19.193 +7:30:50.26
Params:  point=x

Shape: (point)
RA, Dec: 5:55:18.545 +7:30:56.53
Params:  point=x

Shape: (point)
RA, Dec: 5:55:17.669 +7:31:02.32
Params:  point=x

Shape: (point)
RA, Dec: 5:55:14.427 +7:31:31.73
Params:  point=x

Shape: (point)
RA, Dec: 5:55:18.188 +7:31:08.10
Params:  point=x

Shape: (point)
RA, Dec: 5:55:11.054 +7:31:38.97
Params:  point=x

Shape: (point)
RA, Dec: 5:55:01.390 +7:32:16.58
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.437 +7:29:01.98
Params:  point=x

Shape: (point)
RA, Dec: 5:55:29.820 +7:28:54.28
Params:  point=x

{'id': 'alphaori', 'RA': '5:55:10.327', 'Dec': '+7:24:25.06', 'RA_dg': 88.79302916666667, 'Dec_dg': 7.406961111111111, 'PA': 201.33743830817986, 'D': 49411.76370105342}
Finding theta order:
    th = [ 316.07254202  320.26491597  321.44676476  322.80025538  328.37465669
  330.04539051  333.5020746   336.7633965   339.59751837  341.13571782
  343.14296104  345.42615855  347.25277893  348.48073614  349.51092614
  350.68225489  352.08301387  353.76477769  355.4163641   356.5526604
  359.0917082     6.38904855    8.36533254    9.88694909   10.65520345
   11.85977107   14.84717324   17.3785337    19.63055307   21.0634969
   22.65825924   24.20795022   26.17772717   27.87125801   29.1631119
   29.72431208   29.6359899    31.3761735    32.5007643    33.81958034
   35.12541426   35.77187563   36.46498691   37.97758746   38.8897185
   42.68158997   43.62690115   45.02433424   46.36903467   48.28478437
   50.00954696   51.39987081   52.89182147   54.27415357   55.76144928
   57.70423104   59.03413338   60.93277325   62.23276856   63.93579766
   64.84244695   66.42943785   68.35265716   69.66558429   71.2411246
   72.92003883   74.95161667   76.03704386   77.98937783   79.27307048
   80.16238068   81.52379475   82.59212933   83.85105032   84.89991498
   85.9241027    86.91414238   88.27705641   89.57883675   90.46067256
   91.29010742   92.11508709   93.64285899   94.97600429   96.31633295
   96.79754051   98.01337947   99.38298798  100.42596097  114.00746022
  116.94885181  119.67376726  121.02967484  122.83927942  124.92057041
  126.85818196  128.53585661  130.71874046  131.83118094  134.36610624
  136.16527774  137.4499459   141.47419765  145.57211466  148.4192929
  150.94107479  154.17361155  157.54823488  160.76527632  162.20673285
  168.0036386   169.48520796  175.30829403  176.6766715   314.19773287
  313.022509    305.70515388  303.76496266  301.04787662  107.86987222
  105.29509873  103.51666794  131.87324992  134.21133777  138.0577283
  140.88059673  139.82105814  102.30817526  104.60623082  107.71720298
  109.73465218  112.76589524  117.70300204   77.20269743   74.33322326
   56.77436816   26.59730945   24.46013478   22.27708767   20.4937649
   18.89504354   17.33738442   15.36766986    8.13237916   16.17456545
    1.42725037  344.2598304    45.74150788   47.11596179]
    pa_ref = 80.0
    th1 = [  56.07254202   60.26491597   61.44676476   62.80025538   68.37465669
   70.04539051   73.5020746    76.7633965    79.59751837   81.13571782
   83.14296104   85.42615855   87.25277893   88.48073614   89.51092614
   90.68225489   92.08301387   93.76477769   95.4163641    96.5526604
   99.0917082   106.38904855  108.36533254  109.88694909  110.65520345
  111.85977107  114.84717324  117.3785337   119.63055307  121.0634969
  122.65825924  124.20795022  126.17772717  127.87125801  129.1631119
  129.72431208  129.6359899   131.3761735   132.5007643   133.81958034
  135.12541426  135.77187563  136.46498691  137.97758746  138.8897185
  142.68158997  143.62690115  145.02433424  146.36903467  148.28478437
  150.00954696  151.39987081  152.89182147  154.27415357  155.76144928
  157.70423104  159.03413338  160.93277325  162.23276856  163.93579766
  164.84244695  166.42943785  168.35265716  169.66558429  171.2411246
  172.92003883  174.95161667  176.03704386  177.98937783  179.27307048
  180.16238068  181.52379475  182.59212933  183.85105032  184.89991498
  185.9241027   186.91414238  188.27705641  189.57883675  190.46067256
  191.29010742  192.11508709  193.64285899  194.97600429  196.31633295
  196.79754051  198.01337947  199.38298798  200.42596097  214.00746022
  216.94885181  219.67376726  221.02967484  222.83927942  224.92057041
  226.85818196  228.53585661  230.71874046  231.83118094  234.36610624
  236.16527774  237.4499459   241.47419765  245.57211466  248.4192929
  250.94107479  254.17361155  257.54823488  260.76527632  262.20673285
  268.0036386   269.48520796  275.30829403  276.6766715    54.19773287
   53.022509     45.70515388   43.76496266   41.04787662  207.86987222
  205.29509873  203.51666794  231.87324992  234.21133777  238.0577283
  240.88059673  239.82105814  202.30817526  204.60623082  207.71720298
  209.73465218  212.76589524  217.70300204  177.20269743  174.33322326
  156.77436816  126.59730945  124.46013478  122.27708767  120.4937649
  118.89504354  117.33738442  115.36766986  108.13237916  116.17456545
  101.42725037   84.2598304   145.74150788  147.11596179]
    order = [118 117 116 115 114   0   1   2   3   4   5   6   7   8   9  10 146  11
  12  13  14  15  16  17  18  19  20 145  21 143  22  23  24  25  26 142
 144 141  27 140  28 139  29 138  30  31 137  32 136  33  34  36  35  37
  38  39  40  41  42  43  44  45  46  47 147  48 148  49  50  51  52  53
  54 135  55  56  57  58  59  60  61  62  63  64  65 134  66  67 133  68
  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86
  87  88 127 121 128 120 129 119 130 131  89  90 132  91  92  93  94  95
  96  97  98 122 123  99 100 101 124 126 125 102 103 104 105 106 107 108
 109 110 111 112 113]
outer
x: [-551.32398992 -527.59662491 -508.497484   -435.00671996 -422.8557039
 -407.41658973 -358.80180588 -347.23145294 -333.34145788 -277.21751705
 -260.42833353 -228.96112679 -200.4979994  -172.69059173 -158.63801198
 -139.87173621 -132.8966411  -120.45076091 -104.04886108  -92.98543019
  -84.28622332  -75.24477401  -62.84303821  -49.11757333  -35.7192593
  -26.67796031   -6.91488546   10.81102997   47.33391161   60.97032649
   61.40193636   72.77817305   77.80473566   85.5082267   106.61051071
  109.18354185  116.90120728  122.21106702  126.70107501  131.84809494
  140.1009372   142.06507409  149.47019673  153.56106516  160.19275961
  167.55519063  165.13218093  177.93658716  178.14548732  187.45519261
  194.81724656  194.505837    197.76215711  206.31436785  212.78411886
  217.48486616  225.66489551  230.78086818  233.80043395  241.71329578
  245.43210949  260.39693318  261.09732585  267.88014041  284.20826663
  273.17593773  289.90574639  281.86304739  288.61682715  292.7083447
  299.937731    304.75797492  310.38144842  322.11617574  316.40720669
  321.22751659  323.63958163  325.81278274  328.53683832  331.82486113
  340.34888631  343.84675858  347.32887179  350.43960838  353.0894798
  371.22168677  356.81076523  358.67153623  378.85629729  365.65007063
  368.89446753  372.15316928  376.81079558  380.06988524  380.99410829
  381.69488809  384.32929625  388.74862166  389.55412156  391.56439113
  391.96750054  389.96077766  389.96215853  390.35147734  391.55863621
  391.56091672  393.97160322  389.70433782  389.49841153  390.92831525
  388.58112601  402.80527711  389.2694825   402.80865232  389.27508959
  401.1325114   389.26394973  390.6533905   382.57707214  376.17025266
  382.33145403  371.50375256  371.49162323  364.5467983   356.91798616
  347.1907357   341.62916426  334.68477483  331.91943039  355.29690638
  342.80276268  321.4937176   315.24778976  309.68520336  323.63047984
  297.80054015  307.80360391  288.72668383  281.22154479  262.46228171
  246.49987535  230.9264151   205.08355289  185.08949697  174.25837631
  121.74951781  107.58404547   50.92142918   36.75537848]
y: [ 331.89620198  352.72812355  365.46187241  405.96994884  411.17665036
  422.96259716  431.6407984   435.69821157  439.16521722  450.16436014
  451.90149932  459.26661933  466.9727454   464.28945487  464.28797871
  461.61620245  471.52559999  463.28459972  459.93343217  456.25274096
  455.25225206  458.60179489  451.90125188  449.56076473  445.54040441
  442.86022558  436.16001515  433.91003704  422.72070995  426.67117799
  417.56119459  417.56167825  413.54191798  407.18231639  402.16360054
  397.26377619  403.04432923  391.47473073  404.83508561  385.20550579
  392.78621723  380.09639172  388.09707615  374.8474675   383.73812735
  372.68889031  363.01863396  361.97002469  355.79004743  354.47112482
  349.11201497  341.89197546  346.37238051  338.31347304  333.99433048
  324.63496882  320.7861152   320.31685406  316.3672971   309.62848611
  304.27905799  282.37144678  273.92155994  267.65269281  276.9455466
  260.42359669  269.24657846  251.26511833  242.09633334  233.66708227
  226.90843406  219.19935237  211.24044244  210.99278775  199.9916313
  192.75259934  179.8930852   171.54352737  160.69408552  155.844769
  148.48657475  136.46732454  128.71808048  119.01876074  108.48934374
  104.11348585   95.93017083   89.18058733   86.05528224   77.79217581
   69.88292315   64.53368179   56.15477712   49.41555102   41.04576783
   34.06593216   27.38656432   20.95763735   11.71782919    2.87831853
   -3.15158575   -8.78208373  -14.40208691  -24.85199774  -34.09170622
  -43.3417115   -46.96111739  -54.86217553  -64.36223199  -71.93188538
  -84.7824694   -96.82893401 -101.44231125 -110.15894206 -124.36232416
 -129.32937878 -139.64233642 -163.94201081 -170.39397843 -191.24551906
 -200.75405576 -211.67662741 -223.47663694 -235.28824954 -249.17998595
 -260.28214277 -272.09335158 -288.06483372 -297.09541654 -318.49038459
 -333.49312903 -314.45756236 -328.33881617 -337.36991051 -360.15714942
 -352.66218124 -378.49029106 -362.64385408 -410.28521118 -426.94841274
 -443.62096284 -477.13329968 -496.29683169 -530.46927896 -542.97049856
 -572.96536376 -579.63638017 -620.46918948 -632.96957779]
R: [ 643.51630186  634.6458286   626.20449649  595.01466013  589.80775183
  587.26964521  561.29538992  557.13787654  551.34618486  528.67523387
  521.57250886  513.17543317  508.19582123  495.36525754  490.64176954
  482.34180925  489.89581409  478.68675159  471.55585832  465.63167188
  462.98896364  464.73366813  456.24991935  452.23601935  446.96992901
  443.66303989  436.21482604  434.04469656  425.36254867  431.00542322
  422.05159521  423.8566003   420.79745106  416.06381195  416.05451877
  411.99460395  419.65536287  410.10731486  424.19878471  407.1451852
  417.02432189  405.77795932  415.88541719  405.08224427  415.83250308
  408.62176994  398.81219362  403.34070936  397.89743968  400.98532089
  399.79114366  393.34799289  398.85297638  396.25954174  396.01678504
  390.75251757  392.20960821  394.79449859  393.38392136  392.80417102
  390.92539633  384.10961556  378.42414638  378.67893207  396.8288984
  377.41958437  395.65017604  377.59891045  376.70984527  374.53768888
  376.09849764  375.40082493  375.44529302  385.06725017  374.31293463
  374.62071748  370.2757093   368.21345871  365.73083444  366.59968697
  371.32954002  369.93772996  370.41286347  370.099155    369.3807229
  385.54527446  369.48142018  369.59227273  388.5068926   373.83364852
  375.45539165  377.70699952  380.9720917   383.26885387  383.1987286
  383.21205008  385.30381761  389.31313028  389.73031848  391.57496999
  391.98017038  390.05965327  390.22801692  391.14178714  393.03995983
  393.95235176  396.76059619  393.54711182  394.78033068  397.49106128
  397.72271573  414.2800185   402.27014868  417.60005136  408.65765996
  421.46575177  413.55338794  423.65912526  418.80702479  421.99396625
  431.83275888  427.57693198  433.52950694  433.88354258  435.29428464
  433.9218833   436.74394998  441.58266149  445.46177704  477.1498892
  478.25871786  449.71298511  455.1785882   457.95565473  484.20022694
  461.5796527   487.85034489  463.54467192  497.41281826  501.1700275
  507.50541595  530.0784799   537.00075308  561.83251758  570.24814249
  585.75784515  589.53597011  622.5552241   634.0358383 ]
th: [ 301.04787662  303.76496266  305.70515388  313.022509    314.19773287
  316.07254202  320.26491597  321.44676476  322.80025538  328.37465669
  330.04539051  333.5020746   336.7633965   339.59751837  341.13571782
  343.14296104  344.2598304   345.42615855  347.25277893  348.48073614
  349.51092614  350.68225489  352.08301387  353.76477769  355.4163641
  356.5526604   359.0917082     1.42725037    6.38904855    8.13237916
    8.36533254    9.88694909   10.65520345   11.85977107   14.84717324
   15.36766986   16.17456545   17.33738442   17.3785337    18.89504354
   19.63055307   20.4937649    21.0634969    22.27708767   22.65825924
   24.20795022   24.46013478   26.17772717   26.59730945   27.87125801
   29.1631119    29.6359899    29.72431208   31.3761735    32.5007643
   33.81958034   35.12541426   35.77187563   36.46498691   37.97758746
   38.8897185    42.68158997   43.62690115   45.02433424   45.74150788
   46.36903467   47.11596179   48.28478437   50.00954696   51.39987081
   52.89182147   54.27415357   55.76144928   56.77436816   57.70423104
   59.03413338   60.93277325   62.23276856   63.93579766   64.84244695
   66.42943785   68.35265716   69.66558429   71.2411246    72.92003883
   74.33322326   74.95161667   76.03704386   77.20269743   77.98937783
   79.27307048   80.16238068   81.52379475   82.59212933   83.85105032
   84.89991498   85.9241027    86.91414238   88.27705641   89.57883675
   90.46067256   91.29010742   92.11508709   93.64285899   94.97600429
   96.31633295   96.79754051   98.01337947   99.38298798  100.42596097
  102.30817526  103.51666794  104.60623082  105.29509873  107.71720298
  107.86987222  109.73465218  112.76589524  114.00746022  116.94885181
  117.70300204  119.67376726  121.02967484  122.83927942  124.92057041
  126.85818196  128.53585661  130.71874046  131.83118094  131.87324992
  134.21133777  134.36610624  136.16527774  137.4499459   138.0577283
  139.82105814  140.88059673  141.47419765  145.57211466  148.4192929
  150.94107479  154.17361155  157.54823488  160.76527632  162.20673285
  168.0036386   169.48520796  175.30829403  176.6766715 ]
R0 = 370.02 arcsec, PA0 = 64.35 deg
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 115
    # variables        = 2
    chi-square         = 4833.978
    reduced chi-square = 42.779
    Akaike info crit   = 433.927
    Bayesian info crit = 439.417
[[Variables]]
    xc:  -136.600747 +/- 4.042615 (2.96%) (init=-333.5485)
    yc:  -68.7003770 +/- 2.189979 (3.19%) (init=-160.1986)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.788 
outer : -136.60074705 -68.7003769989 529.321849766
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.79302917,  7.40696111)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 88.75476522,  7.38787767)>
Separation star->center in arcsec:  152.90622337363095
sqrt(xc**2 + yc**2) =  152.903583654
#+end_example


#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py rhya --pa0 270 --debug --window 21
python $D/fit-circle-shell.py rhya --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
Shape: (point)
RA, Dec: 13:29:45.837 -23:19:24.70
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:45.049 -23:19:20.33
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:44.383 -23:19:15.64
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:43.777 -23:19:13.14
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:42.990 -23:19:09.80
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:42.323 -23:19:08.13
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:41.778 -23:19:05.50
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:41.172 -23:18:59.66
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:40.627 -23:18:52.99
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:40.143 -23:18:47.15
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:39.476 -23:18:38.80
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:38.805 -23:18:30.97
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:38.205 -23:18:20.44
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:37.495 -23:18:11.26
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:37.076 -23:17:59.64
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:36.592 -23:17:44.62
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:36.388 -23:17:32.87
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:35.921 -23:17:19.52
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:35.796 -23:17:08.16
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:35.811 -23:16:54.42
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:35.964 -23:16:43.64
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:35.964 -23:16:33.62
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:36.468 -23:16:14.61
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:37.405 -23:15:58.40
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:37.912 -23:15:41.89
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:38.555 -23:15:30.73
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:39.442 -23:15:22.21
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:39.235 -23:15:11.02
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:41.048 -23:14:58.00
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:41.807 -23:14:53.52
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:43.107 -23:14:50.26
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:43.292 -23:14:16.98
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:43.897 -23:14:06.97
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:45.047 -23:14:00.29
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:46.197 -23:13:52.78
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:47.529 -23:13:51.11
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:44.456 -23:14:31.70
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:50.738 -23:13:49.43
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:52.736 -23:13:53.60
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:47.049 -23:19:28.87
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:48.260 -23:19:31.37
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:49.411 -23:19:35.54
Params:  point=x color=red

Shape: (point)
RA, Dec: 13:29:42.699 -23:16:52.44
Params:  point=circle color=red text={R Hya}

{'id': 'rhya', 'RA': '13:29:42.699', 'Dec': '-23:16:52.44', 'RA_dg': 202.42791249999996, 'Dec_dg': -23.281233333333333, 'PA': 252.55227315072341, 'D': 409057.32620308804}
Finding theta order:
    th = [ 164.15198899  167.6540255   170.79888422  173.97550461  178.32847134
  182.18592397  185.44639358  189.38824449  193.32031828  197.06347413
  202.65711199  208.56459854  215.1259578   222.28674729  229.05661324
  238.19004218  245.05815927  253.82384503  260.60941577  268.79916756
  275.41147761  281.45854208  293.77367857  306.52666754  316.92045782
  325.04857442  333.55113673  334.79269905  348.75455788  354.09789165
    2.63507735    3.00958224    5.69877592   10.64728226   15.02279768
   20.16136936    9.76293851   31.19580381   37.72805252  159.04208028
  154.26874853  150.45527673]
    pa_ref = 270.0
    th1 = [  74.15198899   77.6540255    80.79888422   83.97550461   88.32847134
   92.18592397   95.44639358   99.38824449  103.32031828  107.06347413
  112.65711199  118.56459854  125.1259578   132.28674729  139.05661324
  148.19004218  155.05815927  163.82384503  170.60941577  178.79916756
  185.41147761  191.45854208  203.77367857  216.52666754  226.92045782
  235.04857442  243.55113673  244.79269905  258.75455788  264.09789165
  272.63507735  273.00958224  275.69877592  280.64728226  285.02279768
  290.16136936  279.76293851  301.19580381  307.72805252   69.04208028
   64.26874853   60.45527673]
    order = [41 40 39  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
 22 23 24 25 26 27 28 29 30 31 32 36 33 34 35 37 38]
outer
x: [  92.45073492   76.59758895   59.91750635   43.22362601   32.36980513
   23.19629188   14.84901024    4.00843425   -5.17930082  -12.68660174
  -21.03439431  -28.54215595  -35.20976851  -44.39869431  -53.64298549
  -61.9098297   -71.69224036  -77.4664193   -84.13698275  -86.94965107
  -93.38633379  -95.11082058  -94.90686823  -92.8008321   -92.80277161
  -85.86146932  -72.95233242  -65.96804611  -57.1084067   -44.8854691
  -47.73929723  -22.75396027  -12.29359299    5.62311661    8.17338074
   16.512503     24.21617136   32.36385343   48.21572819   66.57597962
  110.80873074  138.34775059]
y: [-163.1089234  -158.93612533 -156.43374801 -152.2619504  -147.89109383
 -143.20056169 -140.70023017 -137.36001677 -135.690028   -133.06016801
 -127.22046183 -120.55085031 -114.71129394 -106.36205734  -98.53300311
  -88.0039998   -78.8253634   -67.20626172  -52.18738588  -40.4378874
  -27.08909769  -15.72943617   -1.98939499    8.79101791   18.81101806
   37.8223123    54.03445071   70.54546284   81.70659992   90.22789971
  101.41762431  114.43946034  118.91984247  122.17996704  155.45993038
  165.46971588  140.73938885  172.14890861  179.65757776  181.32538182
  182.99720679  178.82005719]
R: [ 187.48775768  176.43095694  167.51604425  158.27818355  151.39213956
  145.06711835  141.48161674  137.41849131  135.78883922  133.66360078
  128.94763143  123.88366388  119.99336963  115.25680586  112.18878106
  107.59893584  106.55146758  102.55597365   99.00785379   95.89298493
   97.23593241   96.40271445   94.92771635   93.21628846   94.69006716
   93.82280757   90.7841653    96.58387771   99.68620059  100.77588612
  112.09181513  116.679616    119.55359201  122.30929559  155.67464183
  166.29158015  142.80755767  175.16468179  186.0150577   193.16121545
  213.93118637  226.09005495]
th: [ 150.45527673  154.26874853  159.04208028  164.15198899  167.6540255
  170.79888422  173.97550461  178.32847134  182.18592397  185.44639358
  189.38824449  193.32031828  197.06347413  202.65711199  208.56459854
  215.1259578   222.28674729  229.05661324  238.19004218  245.05815927
  253.82384503  260.60941577  268.79916756  275.41147761  281.45854208
  293.77367857  306.52666754  316.92045782  325.04857442  333.55113673
  334.79269905  348.75455788  354.09789165    2.63507735    3.00958224
    5.69877592    9.76293851   10.64728226   15.02279768   20.16136936
   31.19580381   37.72805252]
R0 = 89.16 arcsec, PA0 = 278.45 deg
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 18
    # variables        = 2
    chi-square         = 125.331
    reduced chi-square = 7.833
    Akaike info crit   = 38.931
    Bayesian info crit = 40.711
[[Variables]]
    xc:   38.9756059 +/- 4.863278 (12.48%) (init= 88.19226)
    yc:  -5.54525832 +/- 1.447171 (26.10%) (init=-13.09802)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.442 
outer : 38.9756059731 -5.54525832839 131.984502472
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.4279125, -23.28123333)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 202.43969874, -23.28277368)>
Separation star->center in arcsec:  39.367882559289804
sqrt(xc**2 + yc**2) =  39.3681057571
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py rleo --pa0 110 --window 11
python $D/fit-circle-shell.py rleo --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 25
    # variables        = 2
    chi-square         = 156.658
    reduced chi-square = 6.811
    Akaike info crit   = 49.880
    Bayesian info crit = 52.317
[[Variables]]
    xc:  -33.5833621 +/- 3.456322 (10.29%) (init=-78.70752)
    yc:   11.7291278 +/- 1.700196 (14.50%) (init= 31.53638)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.777 
outer : -33.5833621544 11.7291278377 120.974540737
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.88944583,  11.42896667)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 146.8799284,  11.43222476)>
Separation star->center in arcsec:  35.57248496601508
sqrt(xc**2 + yc**2) =  35.572667224
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py uuaur --pa0 200 --window 21
python $D/fit-circle-shell.py uuaur --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 29
    # variables        = 2
    chi-square         = 53.205
    reduced chi-square = 1.971
    Akaike info crit   = 21.599
    Bayesian info crit = 24.333
[[Variables]]
    xc:   10.1339429 +/- 0.934877 (9.23%) (init= 42.63907)
    yc:   21.4239469 +/- 1.324563 (6.18%) (init= 65.49364)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.816 
outer : 10.1339429826 21.4239469575 102.466573548
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.13680833,  38.44531944)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 99.14040253,  38.45127054)>
Separation star->center in arcsec:  23.69965896671891
sqrt(xc**2 + yc**2) =  23.6998376284
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py v1943sgr --pa0 135 --window 7
python $D/fit-circle-shell.py v1943sgr --debug --thmax 90 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 13
    # variables        = 2
    chi-square         = 123.877
    reduced chi-square = 11.262
    Akaike info crit   = 33.306
    Bayesian info crit = 34.436
[[Variables]]
    xc:  -11.1924048 +/- 2.970779 (26.54%) (init=-37.98777)
    yc:   14.5174673 +/- 2.603421 (17.93%) (init= 36.41604)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.765 
outer : -11.1924048335 14.5174673531 70.7516159596
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.73027917, -27.22538889)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 301.72678282, -27.22135626)>
Separation star->center in arcsec:  18.331157090297058
sqrt(xc**2 + yc**2) =  18.3310333671
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py xpav --pa0 80 --window 11
python $D/fit-circle-shell.py xpav --debug --thmax 75 --savefig
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 20
    # variables        = 2
    chi-square         = 17.630
    reduced chi-square = 0.979
    Akaike info crit   = 1.478
    Bayesian info crit = 3.469
[[Variables]]
    xc:  -24.2910307 +/- 1.661214 (6.84%) (init=-47.10938)
    yc:  -4.97046042 +/- 0.573811 (11.54%) (init=-8.877447)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.629 
outer : -24.2910307221 -4.97046042789 72.6204375663
#### Checking offset of outer arc center ####
Star coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.94182917, -59.9371)>
Arc center coords:  <SkyCoord (ICRS): (ra, dec) in deg
    ( 302.92835975, -59.93848068)>
Separation star->center in arcsec:  24.79385171499403
sqrt(xc**2 + yc**2) =  24.7943471462
#+end_example
**** DONE Circle fits to second batch of sources
CLOSED: [2017-07-05 Wed 19:07]
:PROPERTIES:
:ID:       4BC292AA-F2EB-4031-94AB-E6A36B22FD21
:END:

#+name: second-batch-sources
| name   | pa0 |
|--------+-----|
| cwleo  |  80 |
| epaqr  |  10 |
| khicyg | 200 |
| rcas   |  80 |
| rtvir  | 100 |
| waql   |  80 |
| wpic   | 350 |
| rscl   | 190 |
| tetaps | 260 |

#+BEGIN_SRC python :var tab=second-batch-sources :return _ :results raw drawer
  _ = ', '.join(["'" + row[0] + "'" for row in tab])
#+END_SRC

#+RESULTS:
:RESULTS:
'cwleo', 'epaqr', 'khicyg', 'rcas', 'rtvir', 'waql', 'wpic', 'rscl', 'tetaps'
:END:


#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py cwleo --pa0 80 --window 11
python $D/fit-circle-shell.py cwleo --thmax 75 --savefig
open cwleo-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 13
    # variables        = 2
    chi-square         = 606.068
    reduced chi-square = 55.097
    Akaike info crit   = 53.947
    Bayesian info crit = 55.076
[[Variables]]
    xc:  -249.427556 +/- 18.29556 (7.34%) (init=-466.9935)
    yc:  -19.7220640 +/- 4.619262 (23.42%) (init=-34.60173)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.149 
outer : -249.427556586 -19.7220640281 717.946479807
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py epaqr --pa0 10 --window 5
python $D/fit-circle-shell.py epaqr --thmax 75 --savefig
open epaqr-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 12
    # data points      = 10
    # variables        = 2
    chi-square         = 9.772
    reduced chi-square = 1.221
    Akaike info crit   = 3.769
    Bayesian info crit = 4.374
[[Variables]]
    xc:  -26.5151362 +/- 3.360498 (12.67%) (init=-23.48984)
    yc:  -24.6657349 +/- 3.051297 (12.37%) (init=-20.85778)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.916 
outer : -26.5151362653 -24.6657349165 68.4954872991
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py khicyg --pa0 200 --window 9
python $D/fit-circle-shell.py khicyg --thmax 75 --savefig
open khicyg-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 11
    # variables        = 2
    chi-square         = 1515.748
    reduced chi-square = 168.416
    Akaike info crit   = 58.183
    Bayesian info crit = 58.979
[[Variables]]
    xc:   84.7730499 +/- 20.95704 (24.72%) (init= 207.1589)
    yc:   101.484979 +/- 18.45505 (18.19%) (init= 196.5163)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.872 
outer : 84.7730499542 101.484979909 419.999889947
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py rcas --pa0 80 --window 9
python $D/fit-circle-shell.py rcas --thmax 75 --savefig
open rcas-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 15
    # data points      = 13
    # variables        = 2
    chi-square         = 259.387
    reduced chi-square = 23.581
    Akaike info crit   = 42.914
    Bayesian info crit = 44.044
[[Variables]]
    xc:  -56.2346587 +/- 12.86917 (22.88%) (init=-79.01164)
    yc:  -11.1884093 +/- 4.998666 (44.68%) (init=-30.77708)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.796 
outer : -56.2346587335 -11.1884093561 140.089904897
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py rtvir --pa0 100 --window 11
python $D/fit-circle-shell.py rtvir --thmax 75 --savefig
open rtvir-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
Warning: Closest point of outer arc is at one end, using all points in parabola fit
[[Fit Statistics]]
    # function evals   = 22
    # data points      = 11
    # variables        = 2
    chi-square         = 86.559
    reduced chi-square = 9.618
    Akaike info crit   = 26.692
    Bayesian info crit = 27.488
[[Variables]]
    xc:  -4.42029111 +/- 4.240483 (95.93%) (init=-85.26845)
    yc:   4.60132551 +/- 1.878071 (40.82%) (init= 17.32993)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.577 
outer : -4.42029111933 4.60132550992 97.9470021696
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py waql --pa0 80 --window 9
python $D/fit-circle-shell.py waql --thmax 75 --savefig
open waql-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 21
    # data points      = 13
    # variables        = 2
    chi-square         = 12.812
    reduced chi-square = 1.165
    Akaike info crit   = 3.810
    Bayesian info crit = 4.940
[[Variables]]
    xc:  -12.0949132 +/- 1.682015 (13.91%) (init=-40.87123)
    yc:   0.66101057 +/- 0.652962 (98.78%) (init= 9.197393)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.541 
outer : -12.0949132709 0.661010578663 53.8154713214
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py wpic --pa0 350 --window 9
python $D/fit-circle-shell.py wpic --thmax 75 --savefig
open wpic-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 15
    # data points      = 12
    # variables        = 2
    chi-square         = 9.998
    reduced chi-square = 1.000
    Akaike info crit   = 1.810
    Bayesian info crit = 2.780
[[Variables]]
    xc:   4.01965136 +/- 1.164850 (28.98%) (init= 8.129169)
    yc:  -15.8942974 +/- 2.565151 (16.14%) (init=-26.84568)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    = -0.808 
outer : 4.01965136134 -15.8942973988 44.9133508674
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py rscl --pa0 190 --window 13
python $D/fit-circle-shell.py rscl --thmax 75 --savefig
open rscl-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
Warning: Closest point of outer arc is at one end, using all points in parabola fit
[[Fit Statistics]]
    # function evals   = 19
    # data points      = 11
    # variables        = 2
    chi-square         = 4.567
    reduced chi-square = 0.507
    Akaike info crit   = -5.670
    Bayesian info crit = -4.874
[[Variables]]
    xc:   8.07007150 +/- 1.108187 (13.73%) (init= 39.06783)
    yc:   6.43189082 +/- 0.741708 (11.53%) (init= 27.66114)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.803 
outer : 8.07007150822 6.43189082349 58.9608685659
#+end_example

#+BEGIN_SRC sh :results verbatim
cd RSG
D=../../read-shapes-LL
python $D/find-xy-shell.py tetaps --pa0 260 --window 9
python $D/fit-circle-shell.py tetaps --thmax 75 --savefig
open tetaps-arcfits.pdf
#+END_SRC

#+RESULTS:
#+begin_example
[[Fit Statistics]]
    # function evals   = 18
    # data points      = 11
    # variables        = 2
    chi-square         = 5.727
    reduced chi-square = 0.636
    Akaike info crit   = -3.179
    Bayesian info crit = -2.383
[[Variables]]
    xc:   23.7470520 +/- 1.527059 (6.43%) (init= 43.90069)
    yc:   18.9336158 +/- 1.182626 (6.25%) (init= 36.10765)
[[Correlations]] (unreported correlations are <  0.100)
    C(xc, yc)                    =  0.872 
outer : 23.7470520056 18.9336158538 87.2483463678
#+end_example

**** Make figures of the RSG sources


#+BEGIN_SRC python :eval no :tangle rsg_plot.py
  import json
  import glob
  import numpy as np
  import matplotlib.pyplot as plt
  import matplotlib.patches
  from astropy.io import fits
  from astropy.wcs import WCS
  from astropy.visualization.lupton_rgb import LinearMapping
  from reproject import reproject_interp

  def plot_rsg_image_fit(source='AlphaOri', batch=1, 
                         pmin=1, pmax=99,
                         pmin160=1, pmax160=99,
                         extra='', extra160='',
                         window_factor=1.5,
                         show160=False,
                         label=r'$\alpha$ Ori'):
      jsonfile = f'RSG/{source.lower()}-arcdata.json'
      with open(jsonfile) as f:
          arcdata = json.load(f)

      fits_pattern = (f'RSG/MESS_PPHOT/Batch{batch:02d}/'
                      + f'{source.upper()}*{extra}_70_*pixfrac*.fits')
      fitsfile = glob.glob(fits_pattern)[0]
      hdulist = fits.open(fitsfile)
      hdu = hdulist['image']
      hdu160 = fits.open(fitsfile.replace(f'{extra}_70',
                                          f'{extra160}_160'))['image']

      # Fix the unit keywords
      for k in 'CUNIT1', 'CUNIT2':
          hdu.header[k] = 'deg'
          hdu160.header[k] = 'deg'

      # Reproject the 160 image onto the same grid as 70
      hdu160_remap, mask = reproject_interp(hdu160, hdu.header)

      w = WCS(hdu.header)
      xpix_arcsec, ypix_arcsec = 3600*w.wcs.cdelt

      # Find plot window limits
      xrpix, yrpix = w.wcs.crpix
      window_size = window_factor*arcdata['outer']['Rc']
      x1, x2 = xrpix + window_size/xpix_arcsec, xrpix - window_size/xpix_arcsec
      y1, y2 = yrpix - window_size/ypix_arcsec, yrpix + window_size/ypix_arcsec

      # Two axes side by side
      fig, (axim, ax) = plt.subplots(1, 2, figsize=(10, 5),
                                     sharex=True, sharey=True,
                                     subplot_kw=dict(projection=w))

      # Brightness limits for images
      vmin, vmax = np.percentile(hdu.data, [pmin, pmax])
      vmin160, vmax160 = np.percentile(hdu160.data, [pmin160, pmax160])

      # Make an RGB image from the 80 and 160 bands
      red = (hdu160_remap - vmin160)/(vmax160 - vmin160)
      blue = (hdu.data - vmin)/(vmax - vmin)
      green = (red + blue)/2.0
      rgbmap = LinearMapping(minimum=0.0, maximum=1.0)
      rgbim = rgbmap.make_rgb_image(red, green, blue)

      axim.imshow(rgbim)
      # axim.imshow(hdu.data, origin='lower',
      #             vmin=vmin, vmax=vmax, cmap='gray', alpha=1.0)
      if show160:
          ax.imshow(hdu160_remap, origin='lower',
                    vmin=vmin160, vmax=vmax160, cmap='gray_r', alpha=0.6)
      else:
          ax.imshow(hdu.data, origin='lower',
                    vmin=vmin, vmax=vmax, cmap='gray_r', alpha=0.6)
      bmax = hdu.data.max()
      axim.contour(hdu.data, levels=[0.05*bmax, 0.2*bmax], colors='r')
      ax.contour(hdu.data, levels=[0.05*bmax, 0.2*bmax], colors='r')

      # Star position
      [x0], [y0] = w.all_world2pix([arcdata['star']['RA_dg']],
                                   [arcdata['star']['Dec_dg']], 0)

      # Plot circle fit
      xc0 = x0 + arcdata['outer']['xc']/xpix_arcsec
      yc0 = y0 + arcdata['outer']['yc']/ypix_arcsec
      ax.scatter(xc0, yc0, marker='o', s=30, edgecolor='k', facecolor='m',
                 zorder=5)
      circ = matplotlib.patches.Circle((xc0, yc0),
                                       radius=arcdata['outer']['Rc']/ypix_arcsec,
                                       edgecolor='m', lw=2, alpha=0.5, facecolor='none',
      )
      ax.add_patch(circ)

      # Plot fitted PA axis
      cvec = np.array([(xc0 - x0), (yc0 - y0)])
      cvec /= np.sqrt((xc0 - x0)**2 + (yc0 - y0)**2)
      cvec *= 1.2*arcdata['outer']['Rc']/ypix_arcsec
      ax.plot([xc0 + cvec[0], xc0 - cvec[0]],
              [yc0 + cvec[1], yc0 - cvec[1]],
              c='m', lw=1.5, alpha=0.6)

      # Plot central star
      ax.scatter(x0, y0, s=150, marker='*', edgecolor='k', facecolor='orange', zorder=6)

      # Plot arc points
      xp = x0 + arcdata['outer']['x']/xpix_arcsec
      yp = y0 + arcdata['outer']['y']/ypix_arcsec
      ax.scatter(xp, yp, marker='o', s=10, c='r', alpha=0.3, zorder=10)

      # Add label with source name and R0
      R0_arcmin = arcdata['outer']['R0']/60
      s = rf"{label}    $R_0 = {R0_arcmin:.2f}'$"
      whitebox = {'fc': 'white', 'alpha': 0.5}
      ax.text(0.05, 0.05, s,
              ha='left', va='baseline', bbox=whitebox,
              transform=ax.transAxes)

      ax.set(xlim=[x1, x2], ylim=[y1, y2])
      axim.set(xlim=[x1, x2], ylim=[y1, y2])
      axim.coords['ra'].set_axislabel('Right Ascension')
      axim.coords['dec'].set_axislabel('Declination')
      ax.coords['dec'].set_ticklabel_visible(False)
      figfile = f'RSG/{source.lower()}-imageplot.pdf'
      fig.savefig(figfile)
      plt.close(fig)
      return figfile

#+END_SRC

#+BEGIN_SRC python :results silent
  from rsg_plot import plot_rsg_image_fit

  plot_rsg_image_fit(pmin=3, pmin160=3, pmax=98, pmax160=98)
  plot_rsg_image_fit('MUCep', label=r'$\mu$ Cep',
                     pmin=5, pmax=99.9, pmin160=3, pmax160=99.5)
  plot_rsg_image_fit('RHYA', label='R Hya',
                     pmin=7, pmax=98, pmin160=12, pmax160=95)
  plot_rsg_image_fit('RLEO', label='R Leo',
                     pmin=5, pmin160=10, pmax160=98)
  plot_rsg_image_fit('UUAUR', label='UU Aur',
                     pmin=10, pmax=95, pmin160=10, pmax160=95)
  plot_rsg_image_fit('V1943SGR', label='V1943 Sgr',
                     pmin=10, pmax=98, pmin160=10, pmax160=98)
  plot_rsg_image_fit('XPAV', label='X Pav',
                     pmin=3, pmin160=10, pmax160=98)
#+END_SRC


#+BEGIN_SRC sh :results silent
open RSG/*-imageplot.pdf
#+END_SRC


#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('CWLEO', label='CW Leo', batch=2,
                         extra160='-1', show160=True, 
                         pmin=50, pmin160=20, pmax=80, pmax160=80)
#+END_SRC

#+RESULTS:
[[file:RSG/cwleo-imageplot.pdf]]

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('EPAQR', label='EP Aqr', batch=2,
                         pmin=5, pmin160=5, pmax=99.5, pmax160=99)
#+END_SRC

#+RESULTS:
[[file:RSG/epaqr-imageplot.pdf]]

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('KHICYG', label=r'$\chi$ Cyg', batch=2, show160=False,
                         pmin=55, pmin160=5, pmax=90
, pmax160=97)
#+END_SRC

#+RESULTS:
[[file:RSG/khicyg-imageplot.pdf]]

Very faint!

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('RCAS', label='R Cas', batch=2,
                         pmin=5, pmin160=5, pmax=98, pmax160=98)
#+END_SRC

#+RESULTS:
[[file:RSG/rcas-imageplot.pdf]]

Could go on the first panel

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('RTVIR', label='RT Vir', batch=2,
                         pmin=15, pmin160=10, pmax=97, pmax160=97)
#+END_SRC

#+RESULTS:
[[file:RSG/rtvir-imageplot.pdf]]

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('WAQL', label='W Aql', batch=2,
                         pmin=10, pmin160=10, pmax=99.5, pmax160=99)
#+END_SRC

#+RESULTS:
[[file:RSG/waql-imageplot.pdf]]

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('WPIC', label='W Pic', batch=2,
                         pmin=15, pmin160=15, pmax=95, pmax160=98)
#+END_SRC

#+RESULTS:
[[file:RSG/wpic-imageplot.pdf]]


#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('RSCL', label='R Scl', batch=2,
                         pmin=5, pmin160=5, pmax=99, pmax160=98)
#+END_SRC

#+RESULTS:
[[file:RSG/rscl-imageplot.pdf]]

#+BEGIN_SRC python :results file :return _
  from rsg_plot import plot_rsg_image_fit
  _ = plot_rsg_image_fit('TETAPS', label=r'$\theta$ Aps', batch=2,
                         pmin=5, pmin160=5, pmax=99, pmax160=98)
#+END_SRC

#+RESULTS:
[[file:RSG/tetaps-imageplot.pdf]]



**** Re-do the arc tracing for Herschel sources
+ [X] alpha ori - no change
+ [X] mu cep - moved inwards, made red
+ [X] r hya - moved inwards, made red
+ [X] r leo - moved about a bit, made red
+ [X] uu aur - ditto
+ [X] v 1943 sgr - ditto
+ [X] x pav - ditto
**** Reorganize data storage
+ [2017-07-05 Wed 11:54]
  + Moved the fits files back onto internal disk
  + They are now at [[file:RSG/MESS_PPHOT/]]
    + Original sources [[file:RSG/MESS_PPHOT/Batch01/]]
    + New sources [[file:RSG/MESS_PPHOT/Batch02/]]
**** DONE Add some more Type I sources?
CLOSED: [2017-07-05 Wed 19:07]
+ Checkbox status means:
  + [ ] Got [[file:RSG/wget-scripts/][wget script]]
  + [-] Downloaded data
  + [X] Traced shell and saved ds9 backup OR cancelled and moved to the "no" list
    + Examples:
      + [[file:RSG/cwleo-forma.reg]]
      + [[file:RSG/cwleo.bck]]
+ If we use criterion that we must be able to see the shell at theta=90, then we could also argue for
  - [X] W Pic - although gets a bit speckly around the edge
    - Actually fine
  - [X] Chi Cyg - although so big it may not fit on image
    - Just about traceable
  - [X] RT Vir - which has a very pointy shell
    - Actually, that was an artefact of the way that Cox displayed the figure
    - In reality, it has a very nice faint outer shell
    - But there is a brighter, two-headed inner shell that we are ignoring
  - [X] R Cas - faint around the edge
    - This one has a beautifully clear shell, although it has some
      undulations
  - [X] EP Aqr - although multiple shells?
    + Fitting may be hairy where there are two shells
    + Currently I only trace the outer shell, but maybe it would be better to trace the inner shell too, and let the fitting split the difference
  - [X] CW Leo - although again very big, and only at 160 micron
    + Was a bit touch and go finding the side of the shell
  - [X] W Aql - although maybe faint at sides
    + Actually, it is fine
  - [X] R Scl - small and diffuse sides
    + probably best contender of this lot
    + yeah, it was fine
  - [X] Theta Aps - originally looked too faint at sides
    - But turned out to be fine
+ Ones we definitely can't do
  - [X] Omicron Cet 
    - Too many shells! and too asymmetrical
  - [X] X Her - with a two-headed appearance
    - Again, too many shells, and too irregular 
  - TX Psc - one-sided and pointy
  - T Mic - very irregular, multiple strands
  - W Ori - too faint full stop
  - NML Tau - even smaller and diffuser
* Comments on the Cox sources and other cool stars 
** H I observations
+ Matthews:2013a have 21 cm observations of AGB shells
+ These do not overlap with the Cox sources
+ But they are similar shapes
+ Partial list
  + RX Lep
    - O-rich AGB @ 149 pc
    - has closed bow shock and wake (maybe)
    - R_0 = 3 arcmin = 0.13 pc
  + IK Tau is the same as NML Tau, which I skip in Cox list (too small and diffuse), and which has no obvious H I bow
  + Y UMa
    - O-rich Semi-reg var @ 385 pc
    - Shows sort-of bow, but star is on top of apex
  + R Peg
    - O-rich Mira @ 400 pc
    - Little bow embedded in bigger structure
  + Y CVn
    - Looks like bow, but pointing wrong way
  + Several others, none look convincing
** Cox sources - what are they?
| Fig |   | Name      | Type  | R_0 (pc) | V_w (km/s) |  t (1000 y) |
|-----+---+-----------+-------+---------+-----------+-------------|
|   8 | a | \alpha Ori     | RSG   |    0.19 |        14 |        13.3 |
|   8 | b | \mu Cep     | RSG   |   0.094 |        35 |         2.6 |
|   8 | c | R Hya     | AGB   |   0.053 |      12.5 |         4.1 |
|   8 | d | R Leo     | AGB   |   0.026 |       9.0 |         2.8 |
|   8 | e | UU Aur    | C-AGB |   0.131 |        11 |        11.6 |
|   8 | f | V1934 Sgr | AGB   |    0.06 |       5.4 |        10.9 |
|   8 | g | X Pav     | AGB   |   0.061 |        11 |         5.4 |
|   8 | h | R Cas     | AGB   |    0.06 |      13.5 |         4.3 |
|-----+---+-----------+-------+---------+-----------+-------------|
|   9 | a | CW Leo    | C-AGB |    0.23 |      14.5 |        15.5 |
|   9 | b | EP Aqr    | AGB   |    0.07 |      11.5 |         6.0 |
|   9 | c | \chi Cyg     | S-RSG |    0.29 |       8.5 |        33.4 |
|   9 | d | RT Vir    | AGB   |     0.1 |       8.9 |        11.0 |
|   9 | e | W Aql     | S-AGB |    0.13 |        20 |         6.4 |
|   9 | f | W Pic     | C-AGB |   0.085 |         7 |        11.9 |
|   9 | g | R ScI     | C-AGB |   0.095 |        17 |         5.5 |
|   9 | h | \theta Aps     | AGB   |   0.041 |       4.5 |         8.9 |
|-----+---+-----------+-------+---------+-----------+-------------|
|     |   |           |       |         |           | 9.6 +/- 1.9 |
#+TBLFM: $7=$5 $pc / $6 $km $yr 1e3 ;f1::@18$7=vmeane(@I..@III);f1

So only 3 out of 16 are supergiants
** CW Leo GALEX observations
+ From circle fits of Matthews:2015a
  + R_0 = 1280/2 - 110 = 530 arcsec = 0.33 pc
    + I found 7.8 arcmin = 468 arcsec
  + \Pi = (1280/2) / (1280/2 - 110) = 1.21
  + R_90+ = 11 arcmin
  + R_90- = 13 arcmin
  + \Lambda = 12 60 / 530 = 1.36  
* Bow shock shapes from simulations
** Meyer:2016a
+ Fig 2 gives axis ratio that is 1/\Lambda
  + Full range is 0.52 \to 0.64 so \Lambda = 1.56 \to 1.92
  + Complete table
    | M_* | n_ism |   R_0 |   1/\Lambda |               \Lambda |
    |----+------+------+-------+-----------------|
    | 10 | 0.79 | 0.03 | 0.585 |            1.71 |
    | 10 | 0.79 | 0.06 | 0.586 |            1.71 |
    | 10 |   10 | 0.08 | 0.566 |            1.77 |
    | 10 |  0.1 | 0.09 | 0.566 |            1.77 |
    | 10 | 0.79 | 0.13 | 0.595 |            1.68 |
    | 20 |   10 | 0.14 | 0.580 |            1.72 |
    | 10 |   10 | 0.15 | 0.580 |            1.72 |
    | 10 |  0.1 | 0.15 | 0.595 |            1.68 |
    | 40 |   10 | 0.30 | 0.520 |            1.92 |
    | 10 | 0.01 | 0.33 | 0.563 |            1.78 |
    | 20 | 0.79 | 0.40 | 0.563 |            1.78 |
    | 10 |   10 | 0.30 | 0.590 |            1.69 |
    | 20 |   10 | 0.30 | 0.620 |            1.61 |
    | 10 |  0.1 | 0.40 | 0.630 |            1.59 |
    | 40 |   10 | 0.60 | 0.570 |            1.75 |
    |----+------+------+-------+-----------------|
    | 20 | 0.79 | 0.60 | 0.581 |            1.72 |
    | 10 | 0.01 | 0.60 | 0.586 |            1.71 |
    | 20 |  0.1 |  1.0 |  0.58 |            1.72 |
    | 20 | 0.79 |  1.2 | 0.592 |            1.69 |
    | 10 | 0.01 |  1.2 | 0.612 |            1.63 |
    | 40 |   10 |  1.4 |  0.64 |            1.56 |
    | 40 | 0.79 |  1.6 | 0.585 |            1.71 |
    | 20 |  0.1 |  2.0 |  0.60 |            1.67 |
    | 40 | 0.79 |  2.7 | 0.595 |            1.68 |
    | 20 | 0.01 |  4.0 | 0.560 |            1.79 |
    | 20 |  0.1 |  4.3 | 0.620 |            1.61 |
    | 40 |  0.1 |  5.0 | 0.590 |            1.69 |
    | 40 | 0.79 |  6.0 | 0.598 |            1.67 |
    | 20 | 0.01 |  8.0 | 0.580 |            1.72 |
    |----+------+------+-------+-----------------|
    |    |      |      |       | 1.725 +/- 0.020 |
    |    |      |      |       | 1.684 +/- 0.015 |
    |----+------+------+-------+-----------------|
    |    |      |      |       | 1.705 +/- 0.013 |
    #+TBLFM: $5=1/$-1;f2::@31$5=vmeane(@I..@II);f3::@32$5=vmeane(@II..@III);f3::@33$5=vmeane(@I..@III);f3
** van-Marle:2014a
+ Fig 2
  + t = 2e4 yr
    + B = 0 : \Lambda = 1.38
    + B = 3 \micro{}G
  + t = 5e4 yr
    + B = 0
    + B = 3 \micro{}G
  + t = 1e5 yr
    + B = 0
    + B = 3 \micro{}G
+ Fig 3: t = 1e5 yr
  + 1.4 \micro{}G - \Lambda = 1.62
  + 5.0 \micro{}G - \Lambda = 1.54

* Convert images to FITS
+ This has not been necessary yet, but may be needed for the O star arcs
#+BEGIN_SRC sh
python ~/Work/Image2FITS/image2fits.py RSG/Betelgeuse_Herschel_large.jpg
#+END_SRC

#+RESULTS:


* DONE Testing the angle functions in =find-xy-shell.py=
CLOSED: [2017-02-28 Tue 10:28]
+ There was a problem with the order of angles in \alpha Ori
  + Turns out it was simply due to failing to convert input degrees to radians for internal use
  + *Fixed* [2017-02-28 Tue]
+ This is the function that is used for sorting the angles:
#+name: find-th-order
#+BEGIN_SRC python
import numpy as np
def canonicalize(th, unit="radians"):
    """Fold an angle theta into the canonical range [-pi:pi]"""
    if unit == "radians":
        return ((th + np.pi) % (2*np.pi)) - np.pi
    elif unit == "degrees":
        return ((th + 180.0) % (360.0)) - 180.0
    else:
        raise NotImplementedError

def find_th_order(th, pa_ref, debug=True): 
    """Returns a sort order for a collection of angles theta
    
    Takes care to account for the wrap-around of angles by shifting
    the star-th1C vector to be at pi, so that all points are (with
    luck) in the range [0, 2 pi]

    """
    th1 = (canonicalize(th - pa_ref) + np.pi) % (2*np.pi)
    if debug: 
        print("Finding theta order:") 
        print("    th =", np.degrees(th)) 
        print("    pa_ref =", np.degrees(pa_ref)) 
        print("    th1 =", np.degrees(th1)) 
        print("    order =", th1.argsort()) 
    return th1.argsort()
#+END_SRC


#+BEGIN_SRC python :noweb yes :results output verbatim
<<find-th-order>>
th0 = np.radians(45.0)
th = np.radians([180, 45, 15, 90, 120, 310])
order = find_th_order(th, pa_ref=th0)

print(np.degrees(th[order]))
print(np.degrees(canonicalize(th[order] - th0)))

#+END_SRC

#+RESULTS:
: Finding theta order:
:     th = [ 180.   45.   15.   90.  120.  310.]
:     pa_ref = 45.0
:     th1 = [ 315.  180.  150.  225.  255.   85.]
:     order = [5 2 1 3 4 0]
: [ 310.   15.   45.   90.  120.  180.]
: [ -95.  -30.    0.   45.   75.  135.]

